@inproceedings{1190226,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {},
 year = {2003},
 publisher = {IEEE},
 title = {2003 IEEE International Symposium on Performance Analysis of Systems and Software. ISPASS (Cat. No.03EX654)},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190226},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190226},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190226.pdf?arnumber=1190226},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Web enabled applications,  digital simulation,  e-commerce,  electronic commerce,  emerging workloads,  energy efficient solutions,  multimedia systems,  multimedia systems,  performance analysis,  simulation tools,  software performance evaluation, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01190226.png" border="0"> },
}

@inproceedings{842290,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Barisone, A. and Bellotti, F. and Berta, R. and de Gloria, A.},
 year = {2000},
 pages = {116--122},
 publisher = {IEEE},
 title = {Invocation profile characterization of Java applications},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842290},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842290},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842290.pdf?arnumber=842290},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Algorithm design and analysis, Application software, Benchmark testing, Costs, Dispatching, Graphics, Ink, Java, Java, Java Virtual Machine, Java applications, Java code execution, Joining processes, Virtual machining, automatic inlining, automatic programming, direct cost, dynamic dispatching, dynamic message dispatching, indirect cost, invocation profile characterization, multiplatform, object oriented languages features, object oriented technology, performance cost, performance costs, polymorphism, program diagnostics, reengineering, remote procedure calls, software layer, statically resolved function call, systems re-engineering, virtual invocation, virtual invocations, virtual machines, },
 abstract = {Low performance of Java code execution (J. Gosling et al., 1996) has risen in the computer science community the awareness of the need for reengineering. This is mainly due to the software layer called Java Virtual Machine (T. Lindholm and F. Yellin, 1997), which allows Java applications to be multiplatform, but also to object oriented languages features, that impose a higher performance cost than procedural languages (B. Calder et al., 1994). Dynamic message dispatching (also called virtual invocation), for instance, is the mechanism that allows polymorphism, one of the most interesting features of object oriented technology. Comparing this mechanism with a statically resolved function call, two kinds of overhead can be singled out (a direct cost and an indirect cost) (K. Driesen and U. Holzle, 1996), that make the utilization of virtual invocations time-consuming. The authors present an analysis of the invocation profile of Java applications, assessing the actual necessity for dynamic dispatching, analyzing the related performance costs and determining rules for an algorithm for the automatic inlining of methods },
}

@inproceedings{842275,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Kalamatianos, J. and Kaeli, D.R.},
 year = {2000},
 pages = {13--20},
 publisher = {IEEE},
 title = {Accurate simulation and evaluation of code reordering},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842275},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842275},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842275.pdf?arnumber=842275},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Computational modeling, Costs, Data structures, Out of order, Petroleum, Statistics, accurate code reordering evaluation, accurate code reordering simulation, block/procedure reordering algorithms, code granularity, code placement, compile-time approach, graph models, memory hierarchy, out-of-order superscalar processor, profile-guided approach, program layout, storage management, virtual machines, },
 abstract = {The need for bridging the ever growing gap between memory and processor performance has motivated research for exploiting the memory hierarchy effectively. An important software solution called code reordering produces a new program layout to better utilize the available memory hierarchy. Many algorithms have been proposed. They differ based on: 1) the code granularity assumed by the reordering algorithm, and 2) the models used to guide code placement. In this paper we present a framework that provides accurate simulation and evaluation of code reordering algorithms on an out-of-order superscalar processor. Our approach allows both profile-guided and compile-time approaches to be simulated. Using a single simulation pass, different graph models are constructed and utilized during code placement. Various combinations of basic block/procedure reordering algorithms can be employed. We discuss the necessary modifications made to a detailed simulator of a processor in order to accurately simulate the optimized code layout },
}

@inproceedings{4211013,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {vii--vii},
 publisher = {IEEE},
 title = {Reviewer Listings},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363727},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211013},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211013.pdf?arnumber=4211013},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {IEEE, },
 abstract = {},
}

@inproceedings{5452017,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Ladas, N. and Sazeides, Y. and Desmet, V.},
 year = {2010},
 pages = {223--234},
 publisher = {IEEE},
 title = {Performance-effective operation below Vcc-min},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452017},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452017},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452017.pdf?arnumber=5452017},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Circuit faults, Clocks, Costs, Degradation, Dynamic voltage scaling, Frequency, Low voltage, Manufacturing processes, Performance loss, Threshold voltage, arrays, block-disabled cache, cache storage, cache techniques, continuous circuit miniaturization, dynamic voltage scaling, fault diagnosis, probability, probability analysis, probability theory, random fault distribution, },
 abstract = {Continuous circuit miniaturization and increased process variability point to a future with diminishing returns from dynamic voltage scaling. Operation below Vcc-min has been proposed recently as a mean to reverse this trend. The goal of this paper is to minimize the performance loss due to reduced cache capacity when operating below Vcc-min. A simple method is proposed: disable faulty blocks at low voltage. The method is based on observations regarding the distributions of faults in an array according to probability theory. The key lesson, from the probability analysis, is that as the number of uniformly distributed random faulty cells in an array increases the faults increasingly occur in already faulty blocks. The probability analysis is also shown to be useful for obtaining insight about the reliability implications of other cache techniques. For one configuration used in this paper, block disabling is shown to have on the average 6.6\% and up to 29\% better performance than a previously proposed scheme for low voltage cache operation. Furthermore, block-disabling is simple and less costly to implement and does not degrade performance at or above Vcc-min operation. Finally, it is shown that a victim-cache enables higher and more deterministic performance for a block-disabled cache. },
}

@inproceedings{1430580,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Lepak, K.M. and Lipasti, M.H.},
 year = {2005},
 pages = {258--268},
 publisher = {IEEE},
 title = {Reaping the Benefit of Temporal Silence to Improve Communication Performance},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430580},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430580},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430580.pdf?arnumber=1430580},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Atomic measurements, Coherence, Delay, Frequency, MESTI protocol, Microarchitecture, Out of order, Pressing, Protocols, Read-write memory, Robustness, benchmark testing, cache storage, coherence protocol enhancement, common datapath issues, communication misses, execution-driven simulation, load value prediction, microarchitecture, parallel programming, performance evaluation, protocols, remote caches, shared memory systems, shared-memory multiprocessors, speculative lock elision, temporally silent stores, },
 abstract = {Communication misses - those serviced by dirty data in remote caches - are a pressing performance limiter in shared-memory multiprocessors. Recent research has indicated that temporally silent stores can be exploited to substantially reduce such misses, either with coherence protocol enhancements (MESTI); by employing speculation to create atomic silent store-pairs that achieve speculative lock elision (SLE); or by employing load value prediction (LVP). We evaluate all three approaches utilizing full-system, execution-driven simulation, with scientific and commercial workloads, to measure performance. Our studies indicate that accurate detection of elision idioms for SLE is vitally important for delivering robust performance and appears difficult for existing commercial codes. Furthermore, common datapath issues in out-of-order cores cause barriers to speculation and therefore may cause SLE failures unless SLE-specific speculation mechanisms are added to the microarchitecture. We also propose novel prediction and silence detection mechanisms that enable the MESTI protocol to deliver robust performance for all workloads. Finally, we conduct a detailed execution-driven performance evaluation of load value prediction (LVP), another simple method for capturing the benefit of temporally silent stores. We show that while theoretically LVP can capture the greatest fraction of communication misses among all approaches, it is usually not the most effective at delivering performance. This occurs because attempting to hide latency by speculating at the consumer, i.e. predicting load values, is fundamentally less effective than eliminating the latency at the source, by removing the invalidation effect of stores. Applying each method, we observe performance changes in application benchmarks ranging from 1\% to 14\% for an enhanced version of MESTI, -1.0\% to 9\% for LVP, -3\% to 9\% for enhanced SLE, and 2\% to 21\% for combined techniques },
}

@inproceedings{1620791,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Joshi, A. and Yi, J.J. and Bell, R.H., Jr. and Eeckhout, L. and John, L. and Lilja, D.},
 year = {2006},
 pages = { 70-- 79},
 publisher = {IEEE},
 title = {Evaluating the efficacy of statistical simulation for design space exploration},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620791},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620791},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620791.pdf?arnumber=1620791},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { Plackett & Burman design,  computer architecture,  cycle-accurate simulation,  design space exploration,  microarchitectures,  microprocessor chips,  microprocessor design space,  performance evaluation,  performance evaluation,  processor performance bottlenecks,  statistical analysis,  statistical simulation,  superscalar microprocessors, Analytical models, Cities and towns, Computational modeling, Computer architecture, Computer networks, Computer simulation, Microarchitecture, Microprocessors, Space exploration, Stress, },
 abstract = {Recent research has proposed statistical simulation as a technique for fast performance evaluation of superscalar microprocessors. The idea in statistical simulation is to measure a program's key performance characteristics, generate a synthetic trace with these characteristics, and simulate the synthetic trace. Due to the probabilistic nature of statistical simulation the performance estimate quickly converges to a solution, making it an attractive technique to efficiently cull a large microprocessor design space. In this paper, we evaluate the efficacy of statistical simulation in exploring the design space. Specifically, we characterize the following aspects of statistical simulation: (i) fidelity of performance bottlenecks, with respect to cycle-accurate simulation of the program, (ii) ability' to track design changes, and (Hi) trade-off between accuracy and complexity in statistical simulation models. In our characterization experiments, we use the Plackett \& Burman (P\&B) design to systematically stress statistical simulation by creating different performance bottlenecks. The key results from this paper are: (1) Synthetic traces stress at least the same 10 most significant processor performance bottlenecks as the original workload, (2) Statistical simulation can effectively track design changes to identify feasible design points in a large design space of aggressive microarchitectures, (3) Our evaluation of 4 statistical simulation models shows that although a very detailed model is needed to achieve a good absolute accuracy in performance estimation, a simple model is sufficient to achieve good relative accuracy, and (4) The P\&B design technique can be used to quickly identify areas to focus on to improve the accuracy of the statistical simulation model. },
}

@inproceedings{842279,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Cargill, D.A. and Radaideh, M.},
 year = {2000},
 pages = {40--45},
 publisher = {IEEE},
 title = {A practitioner report on the evaluation of the performance of the C, C++ and Java compilers on the OS/390 platform},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842279},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842279},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842279.pdf?arnumber=842279},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {C compilers, C language, C++ compilers, C++ language, Costs, IBM VisualAge for Java Enterprise Edition, Java, Java, Java compilers, Lotus Domino Server, OS/390 POSIX compliant system, Runtime, SAP R/3 AppServer, Sliding mode control, Unix, compute-intensive benchmarks, machine native object code, performance analysis, performance evaluation, platform-independent byte-code translation, program compilers, server applications, software performance evaluation, },
 abstract = {The performance of C, C++ and Java<sup>TM</sup> applications on the OS/390(R) platform is becoming an increasingly important issue as customers consolidate their server applications written in these languages on an OS/390 POSIX compliant system. With applications that run on multiple platforms such as the Lotus(R) Domino<sup>TM</sup> Server and SAP R/3 AppServer, customers have the ability to compare actual applications instead of benchmarks across these platforms. The code generated by the C, C++ and Java compilers is critical for the performance of many of these applications. However, doing performance measurements and analysis on these large applications can be extremely difficult, so we use industry standard compute-intensive benchmarks to measure and analyze the performance of the code generated by the C, C++ and Java compilers. This paper briefly describes the activities performed by the authors to evaluate the performance of the code generated by the C, C++, and Java compilers on the OS/390 platform. It particularly describes the performance objectives, the benchmarks used, the performance evaluation methodology, performance analysis, and some normalized results. The term Java compiler in this paper refers to the IBM VisualAge(R) for Java, Enterprise Edition for OS/390 compiler that takes the platform-independent byte-code and translates it into machine native object code that can then be bound into executable modules, as is done for other high-level languages. The resulting code is executed under the VisualAge for Java, Enterprise Edition run-time library rather than in a Java virtual machine (JVM) },
}

@inproceedings{4211009,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {ii--ii},
 publisher = {IEEE},
 title = {Breaker Pages},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363723},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211009},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211009.pdf?arnumber=4211009},
 isbn = {1-4244-1082-7},
 language = {English},
 abstract = {},
}

@inproceedings{4211008,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {C1--C1},
 publisher = {IEEE},
 title = {Covers},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363722},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211008},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211008.pdf?arnumber=4211008},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {application characterization, memory systems, performance models, performance prediction, phase classification, power aware computing, prefetching, real systems evaluation, simulation methodology, simulation sampling, simulators, software reliability, storage management, system power, system reliability, virtual machines, },
 abstract = {The following topics are dealt with: simulators; simulation methodology; application characterization; simulation sampling; prefetching; performance models; phase classification; system power; system reliability; performance prediction; real systems evaluation; and memory systems },
}

@inproceedings{842278,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Fatoohi, R. and Gunwani, V. and Qi Wang and Zheng, C.},
 year = {2000},
 pages = {34--39},
 publisher = {IEEE},
 title = {Performance evaluation of middleware bridging technologies},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842278},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842278},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842278.pdf?arnumber=842278},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Bridges, Computer architecture, DCOM-CORBA bridges, Distributed computing, Environmental management, IONA OrbixCOMet, Inprise DCE-CORBA bridge, Java, Middleware, Object oriented modeling, Operating systems, Sun, Technology management, Visual Edge ObjectBridge, client-server systems, distributed object management, language mappings, middleware bridging technologies, performance evaluation, software performance evaluation, },
 abstract = {This paper provides a state-of-the-art study of bridging between different middleware technologies. Two DCOM-CORBA bridges, IONA OrbixCOMet and Visual Edge ObjectBridge, as well as a DCE-CORBA bridge by Inprise are tested and evaluated. Several configurations, depending on the number of machines and location of the bridge, are employed and two languages (C++ and Java) are used. The results show that the three bridges perform reasonably well for different configurations and language mappings },
}

@inproceedings{1620803,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Xiaoning Ding and Nikolopoulos, D.S. and Song Jiang and Xiaodong Zhang},
 year = {2006},
 pages = { 189-- 198},
 publisher = {IEEE},
 title = {MESA: reducing cache conflicts by integrating static and run-time methods},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620803},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620803},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620803.pdf?arnumber=1620803},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { Multicoloring with Embedded Skewed Associativity,  cache conflict reduction,  cache management,  cache storage,  dynamic page coloring,  multigrained cache indexing,  page remapping,  run-time method,  static skewed associativity,  storage management,  trigger remapping,  virtual memory, Costs, Educational institutions, Hardware, Heuristic algorithms, Indexing, Laboratories, Memory management, Out of order, Runtime, Sampling methods, },
 abstract = {The paper proposes MESA (Multicoloring with Embedded Skewed Associativity), a novel cache indexing scheme that integrates dynamic page coloring with static skewed associativity to reduce conflicts in L2/L3 caches with a small degree of associativity. MESA associates multiple cache pages (colors) with each virtual memory page and uses two-level skewed associativity, first to map a page to a different color in each bank of the cache, and then to disperse the lines of a page across the banks and within the colors of the page. MESA is a multi-grained cache indexing scheme that combines the best of two worlds, page coloring and skewed associativity. We also propose a novel cache management scheme based on page remapping, which uses cache miss imbalance between colors in each bank as the metric to track conflicts and trigger remapping. We evaluate MESA using 24 benchmarks from multiple application domains and with various degrees of sensitivity to conflict misses, on both an in-order issue processor (using complete system simulation) and an out-of-order issue processor (using SimpleScalar). MESA outperforms skewed associativity, prime modulo hashing, and dynamic page coloring schemes proposed earlier. Compared to a 4-way associative cache, MESA can provide as much as 76\% improvement in IPC. },
}

@inproceedings{842302,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {},
 year = {2000},
 pages = {207--207},
 publisher = {IEEE},
 title = {Author Index},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842302},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842302},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842302.pdf?arnumber=842302},
 isbn = {0-7803-6418-X},
 language = {English},
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00842302.png" border="0"> },
}

@inproceedings{842301,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Kant, K. and Sundaram, C.R.M.},
 year = {2000},
 pages = {201--206},
 publisher = {IEEE},
 title = {A server performance model for static Web workloads},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842301},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842301},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842301.pdf?arnumber=842301},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Bandwidth, Current measurement, DMA transfers, Delay, Filtering, PCI bus based I/O subsystem, Pipelines, Predictive models, SPECweb96, Service oriented architecture, Traffic control, Web server, Web server, Web transaction level, architectural details, bypass I/O-memory path, cache sizes, default solution technique, distributed memories, file servers, higher level caches, information resources, input-output programs, low level features, memory latencies, memory pipeline, multilevel cache hierarchy, multiprocessing systems, multiprocessor system, performance evaluation, performance impact, processor bus, processor speeds, queueing theory, queuing network model, sector prefetching, server performance model, simple hybrid approach, static Web workloads, symmetric multiprocessors, transaction processing, },
 abstract = {The paper describes a queuing network model for a multiprocessor system running a static Web workload such as SPECweb96. The model includes architectural details of the Web server in terms of multilevel cache hierarchy, processor bus, memory pipeline, PCI bus based I/O subsystem, and bypass I/O-memory path for DMA transfers. The model is based on detailed measurements from a baseline system and a few of its variants. The model operates at the Web transaction level, and does not explicitly model the CPU core or the caching hierarchy. Yet, the model predicts the performance impact of low level features such as number of processors, processor speeds, cache sizes and latencies, memory latencies, higher level caches, sector prefetching, etc. The model shows an excellent match with measured results. Because of many features that are difficult to handle analytically, the default solution technique is simulation. However, the paper also proposes a simple hybrid approach that can significantly speed up the solution without affecting the accuracy appreciably. The model has also been extended to handle clusters of symmetric multiprocessor systems with both centralized and distributed memories },
}

@inproceedings{842300,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Eden, A.N. and Joh, B.W. and Mudge, T.},
 year = {2000},
 pages = {193--200},
 publisher = {IEEE},
 title = {Web latency reduction via client-side prefetching},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842300},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842300},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842300.pdf?arnumber=842300},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Application specific processors, Data mining, Databases, Delay, Filtering, Prefetching, Protocols, WWW, Web browsers, Web latency reduction, Web pages, Web server, World Wide Web, caching techniques, client-server systems, client-side prefetching, dynamically generated Web pages, heterogeneous environment, heterogeneous environments, homogeneous environment, information resources, information retrieval, internal latency, latency reduction technique, network traffic, online front-ends, performance evaluation, proxy caching, },
 abstract = {The rapid growth of the WWW has inspired numerous techniques to reduce Web latency. While some of these techniques have not been implemented because they either increase network traffic or require cooperation between tiers, recent studies cast a shadow on techniques already in use (e.g. proxy caching) as a result of the increasingly dynamic aspects of the WWW. In particular, the proliferation of dynamically generated Web pages (i.e. cgi, ASP), which are either linked to a database, or extract information from cookies, reduces the effectiveness of caching techniques. Most techniques attempt to improve on part of the overall latency, and often neglect to address the internal latency, which can be a serious bottleneck in heterogeneous environments. We propose a client-side prefetching mechanism, where the decision of what to prefetch is left to the user. We found it has the potential of reducing latency by up to 81\% in a homogeneous environment and 63\% in a heterogeneous environment. In data taken on the client, the technique depicted the potential to decrease latency by three-fold. Client-side prefetching does not increase network traffic, it attempts to improve on all parts of latency, and it can be implemented on the client side, without the cooperation of any other tier. Moreover, it can work seamlessly with any other latency reduction technique. We advocate the inclusion of a suitable mechanism in future Web browsers to support client-side prefetching },
}

@inproceedings{1620801,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Al-Sukhni, H.F. and Holt, J.C. and Connors, D.A.},
 year = {2006},
 pages = { 166-- 176},
 publisher = {IEEE},
 title = {Improved stride prefetching using extrinsic stream characteristics},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620801},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620801},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620801.pdf?arnumber=1620801},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { extrinsic stream characteristics,  memory access,  memory latency,  prefetch ahead distance,  regular stream metrics,  software metrics,  software-based code optimization,  storage management,  stream affinity,  stream density,  stride prefetching, Atherosclerosis, Delay, Hardware, Instruments, Modems, Monitoring, Prefetching, Runtime, Software tools, Water pollution, },
 abstract = {Stride-based prefetching mechanisms exploit regular streams of memory accesses to hide memory latency. While these mechanisms are effective, they can be improved by studying the properties of regular streams. As evidence of this, the establishment of metrics to quantify intrinsic characteristics of regular streams has been shown to enable software-based code optimizations. In this paper we extend previously identified regular stream metrics to quantify extrinsic characteristics of regular streams, and show how these new metrics can be employed to improve the efficiency of stride prefetching. The extrinsic metrics we introduce are stream affinity and stream density. Stream affinity enables prefetching for short streams that were previously ignored by stride prefetching mechanisms. Stream density enables a prioritization mechanism that dynamically selects amongst available streams in favor of those that promise more miss coverage, and provides thrashing control amongst several coexisting streams. Finally, we show that using intrinsic and extrinsic stream metrics in combination allows a novel hardware technique for controlling prefetch ahead distance (PAD) which dynamically adjusts the prefetch launch time to better enable timely prefetches while minimizing cache pollution. For a representative set of SPEC2K traces, our techniques consistently outperform our implementation of the closest previously reported stride-based prefetching technique. },
}

@inproceedings{5452079,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Skaletsky, A. and Devor, T. and Chachmon, N. and Cohn, R. and Hazelwood, K. and Vladimirov, V. and Bach, M.},
 year = {2010},
 pages = {2--12},
 publisher = {IEEE},
 title = {Dynamic program analysis of Microsoft Windows applications},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452079},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452079},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452079.pdf?arnumber=5452079},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {API, Analytical models, Application software, Instruments, Kernel, Microsoft Windows, Observability, Open source software, Performance analysis, Robustness, Runtime, Software systems, Unix, Unix, application program interfaces, cache modeling, cache storage, dynamic program analysis, process-level instrumentation system, program diagnostics, program tracing, software instrumentation, software system, },
 abstract = {Software instrumentation is a powerful and flexible technique for analyzing the dynamic behavior of programs. By inserting extra code in an application, it is possible to study the performance and correctness of programs and systems. Pin is a software system that performs run-time binary instrumentation of unmodified applications. Pin provides an API for writing custom instrumentation, enabling its use in a wide variety of performance analysis tasks such as workload characterization, program tracing, cache modeling, and simulation. Most of the prior work on instrumentation systems has focused on executing Unix applications, despite the ubiquity and importance of Windows applications. This paper identifies the Windows-specific obstacles for implementing a process-level instrumentation system, describes a comprehensive, robust solution, and discusses some of the alternatives. The challenges lie in managing the kernel/application transitions, injecting the runtime agent into the process, and isolating the instrumentation from the application. We examine Pin's overhead on typical Windows applications being instrumented with simple tools up to commercial program analysis products. The biggest factor affecting performance is the type of analysis performed by the tool. While the proprietary nature of Windows makes measurement and analysis difficult, Pin opens the door to understanding program behavior. },
}

@inproceedings{5452075,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Zaparanuks, D. and Hauswirth, M.},
 year = {2010},
 pages = {23--32},
 publisher = {IEEE},
 title = {Characterizing the design and performance of interactive java applications},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452075},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452075},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452075.pdf?arnumber=5452075},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Arithmetic, Counting circuits, Hardware, Informatics, Java, Java, Java client-side benchmark suites, Java runtime systems, Optimizing compilers, Technological innovation, architecture-independent dynamic metrics, hardware performance counters, interactive Java applications, software metrics, static metrics, },
 abstract = {When designers of Java runtime systems evaluate the performance of their systems for the purpose of running clientside Java applications, they normally use the Dacapo and SPEC JVM benchmark suites. However, when users of those Java runtime systems run client applications, they usually run interactive applications such as Eclipse or NetBeans. In this paper we study whether this mismatch is a problem: Do the prevalent Java client-side benchmark suites faithfully represent the characteristics of real-world Java client applications? To answer this question we characterize benchmarks and applications using three kinds of metrics: static metrics, architecture-independent dynamic metrics, and hardware performance counters. We find that real-world applications significantly differ from existing benchmarks. Our finding indicates that the current benchmark suites should be augmented to more faithfully represent the large segment of interactive applications. },
}

@inproceedings{5452076,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Ganesan, K. and Jungho Jo and John, L.K.},
 year = {2010},
 pages = {33--44},
 publisher = {IEEE},
 title = {Synthesizing memory-level parallelism aware miniature clones for SPEC CPU2006 and ImplantBench workloads},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452076},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452076},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452076.pdf?arnumber=5452076},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Character generation, Cloning, Computational modeling, Computer aided instruction, Computer applications, Computer simulation, Microarchitecture, Parallel processing, SPEC CPU2006, Time sharing computer systems, implantbench workloads, instruction per cycle, memory-level parallelism aware miniature clones, microarchitecture-independent metrics, multiprocessing programs, synthetic clones, },
 abstract = {We generate and provide miniature synthetic benchmark clones for modern workloads to solve two pre-silicon design challenges, namely: 1) huge simulation time (weeks to months) when using complete runs of modern workloads like SPEC CPU2006 having trillions of instructions on pre-silicon design models 2) unavailability of access to their specific target applications for computer architects, as some of them are proprietary in nature and vendors hesitate to share them. We first provide a detailed characterization of the SPEC CPU2006 and the ImplantBench suites based on microarchitecture-independent metrics. Our metrics include the Memory Level Parallelism (MLP) of these workloads to estimate the burstiness of accesses to the main memory. Secondly, our proposed framework, that uses this characterized information (including MLP) to generate synthetic clones is explained and evaluated. We provide the synthetic clones generated for CPU2006 workloads for download and use. The efficacy of the synthetic clones for CPU2006 and ImplantBench is demonstrated by comparing their performance and power characteristics with their original counterparts. We show that the synthetic clones generated using our MLP-aware methodology have an error of only 2.8\% in terms of Instruction Per Cycle (IPC) as compared to an error of 15.3\% when using the previous MLP-unaware approaches for CPU2006. We also evaluate their effectiveness in assessing the change in performance and power consumption for various microarchitecture design changes. For CPU2006, with synthetics limited to 1 million dynamic instructions, the average correlation coefficient for assessing design changes for IPC is 0.95 (0.98 for power-per-cycle). For ImplantBench, we have an average error of 2.9\% in assessing the IPC and the correlation coefficient for assessing design changes is 0.94 (0.97 for power-per-cycle). },
}

@inproceedings{1430581,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Asadi, G.-H. and Vilas Sridharan and Tahoori, M.B. and Kaeli, D.},
 year = {2005},
 pages = {269--279},
 publisher = {IEEE},
 title = {Balancing Performance and Reliability in the Memory Hierarchy},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430581},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430581},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430581.pdf?arnumber=1430581},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Cache memory, Computer errors, Error analysis, Error correction codes, Hardware, Protection, Read-write memory, Redundancy, Reliability engineering, SPEC2000 benchmark suite, Single event upset, benchmark testing, cache memories, cache storage, cosmic-ray induced soft errors, error analysis, mean-time-to-failure, microprocessor chips, microprocessor-based systems, performance evaluation, reliability, unprotected first-level caches, },
 abstract = {Cosmic-ray induced soft errors in cache memories are becoming a major threat to the reliability of microprocessor-based systems. In this paper, we present a new method to accurately estimate the reliability of cache memories. We have measured the MTTF (mean-time-to-failure) of unprotected first-level (L1) caches for twenty programs taken from SPEC2000 benchmark suite. Our results show that a 16 KB first-level cache possesses a MTTF of at least 400 years (for a raw error rate of 0.002 FIT/bit.) However, this MTTF is significantly reduced for higher error rates and larger cache sizes. Our results show that for selected programs, a 64 KB first-level cache is more than 10 times as vulnerable to soft errors versus a 16 KB cache memory. Our work also illustrates that the reliability of cache memories is highly application-dependent. Finally, we present three different techniques to reduce the susceptibility of first-level caches to soft errors by two orders of magnitude. Our analysis shows how to achieve a balance between performance and reliability },
}

@inproceedings{1430582,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Balaji, P. and Narravula, S. and Vaidyanathan, K. and Jin, H.-W. and Panda, D.K.},
 year = {2005},
 pages = {280--289},
 publisher = {IEEE},
 title = {On the provision of prioritization and soft qos in dynamically reconfigurable shared data-centers over infiniband},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430582},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430582},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430582.pdf?arnumber=1430582},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computer architecture, Computer science, Data engineering, Internet, Internet, Network interfaces, Operating systems, Personal communication networks, Quality of service, Web services, Web sites, Workstations, dynamic reconfigurable shared data-centers, multiple independent services, performance evaluation, quality of service, reconfigurable architectures, soft QoS, workstation clusters, },
 abstract = {In the past few years several researchers have proposed and configured data-centers providing multiple independent services, known as shared data-centers. For example, several ISPs and other Web service providers host multiple unrelated Web-sites on their data-centers allowing potential differentiation in the service provided to each of them. Such differentiation becomes essential in several scenarios in a shared data-center environment. In this paper, we extend our previously proposed scheme on dynamic re-configurability to allow service differentiation in the shared data-center environment. In particular, we point out the issues associated with the basic dynamic configurability scheme and propose two extensions to it, namely (i) dynamic reconfiguration with prioritization and (ii) dynamic reconfiguration with prioritization and QoS. Our experimental results show that our extensions can allow the dynamic reconfigurability scheme to attain a performance improvement of up to five times for high priority Web sites irrespective of any background low priority requests. Also, these extensions are able to significantly improve the performance of low priority requests when there are minimal or no high priority requests in the system. Further, they can achieve a similar performance as a static scheme with up to 43\% lesser nodes in some cases },
}

@inproceedings{4211014,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {ix--xii},
 publisher = {IEEE},
 title = {Table of Contents},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363728},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211014},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211014.pdf?arnumber=4211014},
 isbn = {1-4244-1082-7},
 language = {English},
 abstract = {},
}

@inproceedings{1620805,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Pereira, A. and Silva, L. and Meira, W., Jr. and Santos, W.},
 year = {2006},
 pages = { 211-- 220},
 publisher = {IEEE},
 title = {Assessing the impact of reactive workloads on the performance of Web applications},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620805},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620805},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620805.pdf?arnumber=1620805},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { Internet,  Web application performance,  Web services,  Web systems,  reactive workload,  software performance evaluation,  systems analysis,  systems design,  systems performance evaluation,  user behavior, Delay, Scalability, Throughput, Web services, },
 abstract = {Designing systems with better performance and scalability is a real need to fulfill the user demands and generate profitable Web services. Being able to mimic user behavior and the workload they generate on the servers is fundamental to evaluate the performance of systems and their improvements. One aspect that is usually neglected by workload generators is the user reactivity, that is, how the users react to variable server response time. Further, it is not clear how the reactivity-related changes in the user generated workload affect the server and how these dependences converge. This paper addresses this problem by proposing, implementing, and validating a workload generator that accounts for reactivity while interacting with servers. Our workload generator is used, for instance, to generate workloads based on a TPC-W benchmark. These workloads are used to assess the impacts of reactivity on the performance of a Web application. The results show significant changes in terms of throughput and response time for the experiments, raising the possibility of improving the performance of Web systems considering user reactivity. },
}

@inproceedings{1620810,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {},
 year = {2006},
 pages = { ii-- ii},
 publisher = {IEEE},
 title = {Copyright},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620810},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620810},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620810.pdf?arnumber=1620810},
 isbn = {1-4244-0186-0},
 language = {English},
 abstract = {},
}

@inproceedings{1430553,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Levy, M.},
 year = {2005},
 pages = {1--1},
 publisher = {IEEE},
 title = {Keynote Talk #1- EEMBC and the Purposes of Embedded Processor Benchmarking},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430553},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430553},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430553.pdf?arnumber=1430553},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Embedded Microprocessor Consortium, benchmark testing, cache size, computer architecture, computer architecture, embedded processor benchmarking, embedded systems, microprocessor chips, power consumption, processor performance prediction, },
 abstract = {Summary form only given. Embedded processor benchmarking serves many purposes, from providing a framework to guide architectural choices in the development stage to giving original equipment manufacturers an objective means of predicting processor performance in specific application scenarios. Creating embedded processor benchmarks is a comparatively simple task. More difficult is winning acceptance from the diverse audiences who could be expected to rely on them. The Embedded Microprocessor Consortium (EEMBC), in its seventh year, represents a model that has succeeded relatively well in both tasks. In this presentation, the author describes the structure of EEMBC in its technical and political aspects, review its accomplishments since 1997 in developing various benchmark suites, and discuss the application of various metrics (such as architectural efficiency, power consumption, bus speed, and cache size) beyond raw performance in evaluating the suitability of a given processor for a particular application or system },
}

@inproceedings{4211015,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Newell, Don},
 year = {2007},
 pages = {xiii--xiii},
 publisher = {IEEE},
 title = {Workloads, Scalability, and QoS Considerations in CMP Platforms},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363729},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211015},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211015.pdf?arnumber=4211015},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Acceleration, Digital TV, Engineering profession, Large-scale systems, Quality of service, Scalability, Streaming media, Strontium, Systems engineering and theory, TV broadcasting, },
 abstract = {We have entered the CMP era and are continuously accelerating the pace at which more cores are integrated on the same die. It is now possible to imagine building a 32-core CMP platform in the near future. To make best use of these cores, the workload scenarios are also evolving rapidly. For example, consolidation via virtualization is a rapidly growing phenomenon in the server marketplace. In this talk, we will start by describing our vision of large-scale CMP platforms and future workload scenarios over the next decade. We will then re-visit the typical performance requirements and behavior of these platforms. Based on analysis of several commercial server workloads running individually, we will demonstrate platform scalability considerations. Based on simultaneous execution of heterogeneous workloads, we will show platform quality of service considerations. The intent is to describe the opportunities and challenges that 2015 CMP platforms will face and discuss potential solutions that need further research. },
}

@inproceedings{4211016,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Barnes, Leslie},
 year = {2007},
 pages = {xiv--xiv},
 publisher = {IEEE},
 title = {Performance Modeling and Analysis for AMD's High Performance Microprocessors},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363730},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211016},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211016.pdf?arnumber=4211016},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Analytical models, Buildings, Chemistry, Computational modeling, Computer simulation, Discrete event simulation, Microprocessors, Performance analysis, Power system management, Power system modeling, },
 abstract = {This talk will cover performance modeling and analysis at AMD, directed at our X86-64 processor development. Topics covered will include benchmark analysis and workload development for simulation, and simulation tools and methodologies used for power/performance analysis of our next generation of microprocessors. },
}

@inproceedings{4211017,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Seongbeom Kim and Fang Liu and Yan Solihin and Iyer, R. and Li Zhao and Cohen, W.},
 year = {2007},
 pages = {1--11},
 publisher = {IEEE},
 title = {Accelerating Full-System Simulation through Characterizing and Predicting Operating System Performance},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363731},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211017},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211017.pdf?arnumber=4211017},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Acceleration, Application software, Computational modeling, Computer simulation, Emulation, Hardware, Linux, OS service performance behavior, Operating systems, Predictive models, Software libraries, Switches, computer hardware complexity, cycle-accurate processor system simulation overheads, full-system simulation acceleration, memory hierarchy model, operating system performance characterization, operating system performance prediction, operating systems (computers), processor hierarchy model, software complexity, software libraries, software performance evaluation, system libraries, virtual machines, },
 abstract = {The ongoing trend of increasing computer hardware and software complexity has resulted in the increase in complexity and overheads of cycle-accurate processor system simulation, especially in full-system simulation which not only simulates user applications, but also the operating system (OS) and system libraries. This paper seeks to address how to accelerate full-system simulation through studying, characterizing, and predicting the performance behavior of OS services. Through studying the performance behavior of OS services, we found that each OS service exhibits multiple but limited behavior points that are repeated frequently. OS services also exhibit application-specific performance behavior and largely irregular patterns of occurrences. We exploit the observation to speed up full system simulation. A simulation run is divided into two non-overlapping periods: a learning period in which performance behavior of instances of an OS service are characterized and recorded, and a prediction period in which detailed simulation is replaced with a much faster emulation mode. During a prediction period, the behavior signature of an instance of an OS service is obtained through emulation while performance of the instance is predicted based on its signature and records of the OS service's past performance behavior. Statistically-rigorous algorithms are used to determine when to switch between learning and prediction periods. We test our simulation acceleration method with a set of OS-intensive applications and a recent version of Linux OS running on top of a detailed processor and memory hierarchy model implemented on Simics, a popular full-system simulator. On average, the method needs the learning periods to cover only 11\% of OS service invocations in order to produce highly accurate performance estimates. This leads to an estimated simulation speedup of 4.9times, with an average performance prediction error of only 3.2\%, and a worst case error of 4.2\% },
}

@inproceedings{4211010,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {iii--iii},
 publisher = {IEEE},
 title = {Commentary},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363724},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211010},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211010.pdf?arnumber=4211010},
 isbn = {1-4244-1082-7},
 language = {English},
 abstract = {},
}

@inproceedings{1430556,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Loh, G.H.},
 year = {2005},
 pages = {21--31},
 publisher = {IEEE},
 title = {Simulation Differences Between Academia and Industry: A Branch Prediction Case Study},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430556},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430556},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430556.pdf?arnumber=1430556},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computational modeling, Computer aided software engineering, Computer architecture, Computer industry, Educational institutions, Hardware, Industrial relations, Microarchitecture, Power system modeling, Predictive models, SPEC CPU benchmark suite, academia simulation, benchmark testing, branch predictor, computer architecture, industrial simulation, instruction set architecture, instruction sets, microarchitecture, microprocessor chips, operating system, parallel architectures, },
 abstract = {Computer architecture research in academia and industry is heavily reliant on simulation studies. While microprocessor companies have the resources to develop highly detailed simulation infrastructures that they correlate against their own silicon, academic researchers tend to use free, widely available simulators. The differences in instruction set architectures, operating systems, simulator models and benchmarks create disconnect between academic and industrial research studies. This paper presents a comparative study to find correlations and differences between the same microarchitecture studies conducted in two different frameworks. Due to the limited availability of industrial simulation frameworks, this research is limited to a case study of branch predictors. Encouragingly, our simulations indicate that several recently proposed branch predictors behave similarly in both environments when evaluated with the SPEC CPU benchmark suite. Unfortunately, we also present results that show that conclusions drawn from studies based on SPEC CPU do not necessarily hold when other applications are considered },
}

@inproceedings{1430555,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Aashish Phansalkar and Ajay Joshi and Eeckhout, L. and John, L.K.},
 year = {2005},
 pages = {10--20},
 publisher = {IEEE},
 title = {Measuring Program Similarity: Experiments with SPEC CPU Benchmark Suites},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430555},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430555},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430555.pdf?arnumber=1430555},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Accuracy, Area measurement, Character generation, Data analysis, ILP, L1 data cache miss-rate, Microarchitecture, Microprocessors, Performance analysis, Process design, SPEC CPU benchmark suite, Space exploration, Time measurement, benchmark testing, branch prediction, cache storage, data locality, instruction level parallelism, instruction sets, microarchitecture-independent characteristics, microprocessor chips, parallel architectures, program similarity measurement, superscalar processor, },
 abstract = {It is essential that a subset of benchmark programs used to evaluate an architectural enhancement, is well distributed within the target workload space rather than clustered in specific areas. Past efforts for identifying subsets have primarily relied on using microarchitecture-dependent metrics of program performance, such as cycles per instruction and cache miss-rate. The shortcoming of this technique is that the results could be biased by the idiosyncrasies of the chosen configurations. The objective of this paper is to present a methodology to measure similarity of programs based on their inherent microarchitecture-independent characteristics which will make the results applicable to any microarchitecture. We apply our methodology to the SPEC CPU2000 benchmark suite and demonstrate that a subset of 8 programs can be used to effectively represent the entire suite. We validate the usefulness of this subset by using it to estimate the average IPC and L1 data cache miss-rate of the entire suite. The average IPC of 8-way and 16-way issue superscalar processor configurations could be estimated with 3.9\% and 4.4\% error respectively. This methodology is applicable not only to find subsets from a benchmark suite, but also to identify programs for a benchmark suite from a list of potential candidates. Studying the four generations of SPEC CPU benchmark suites, we find that other than a dramatic increase in the dynamic instruction count and increasingly poor temporal data locality, the inherent program characteristics have more or less remained the same },
}

@inproceedings{842274,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Zingirian, N. and Maresca, H.},
 year = {2000},
 pages = {7--12},
 publisher = {IEEE},
 title = {Extracting fine-grain profiles of in-order executions of instruction level parallel programs},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842274},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842274},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842274.pdf?arnumber=842274},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Counting circuits, Electronic mail, Feedback, Hazards, Logic, Optimizing compilers, Performance analysis, Processor scheduling, Runtime, Statistics, bubbles, efficiency analysis, fine-grain in-order execution profile extraction, instruction level parallel programs, optimising compilers, optimizing compilers, parallel programming, performance evaluation, profile-driven code optimization, program instruction scheduling, software performance evaluation, target processor functional model, },
 abstract = {Optimizing compilers targeted to instruction level parallel (ILP) architectures schedule program instructions in such a way so as to minimize the number of execution stalls, called bubbles, that occur during program execution because of hazards. These bubbles are estimated by compilers on the basis of the target processor functional model. Unfortunately, these functional models are often inaccurate, especially in retargetable compilers, and thus lead the compiler to imprecise estimations. This paper presents a technique that ``detects" the bubbles by observing program execution in a set of preliminary runs, instead of estimating them. The applications of this technique range from performance evaluation of programs and efficiency analysis of functional models to novel techniques of profile-driven code optimization. The paper presents the technique and shows its applicability in a case study and a set of experiments },
}

@inproceedings{1430559,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Sheaffer, J.W. and Skadron, K. and Luebke, D.P.},
 year = {2005},
 pages = {54--65},
 publisher = {IEEE},
 title = {Studying Thermal Management for Graphics-Processor Architectures},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430559},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430559},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430559.pdf?arnumber=1430559},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Clocks, Computer architecture, Dynamic voltage scaling, Energy management, Engines, Graphics, Hardware, Parallel processing, Qsilver, Temperature, Thermal management, clock gating, computer architecture, computer graphic equipment, dynamic voltage scaling, fetch gating, graphics-processor architecture, multiple clock domain, permuted floor-planning, thermal management, },
 abstract = {We have previously presented Qsilver, a flexible simulation system for graphics architectures. In this paper we describe our extensions to this system, which we use - instrumented with a power model and HotSpot - to analyze the application of standard CPU static and runtime thermal management techniques on the GPU. We describe experiments implementing clock gating, fetch gating, dynamic voltage scaling, multiple clock domains and permuted floor-planning on the GPU using our simulation environment, and demonstrate that these techniques are beneficial in the GPU domain. Further, we show that the inherent parallelism of GPU workloads enables significant thermal gains on chips designed employing static floorplan repartitioning },
}

@inproceedings{1430558,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Zhu, Y.K. and Albonesi, D.H. and Buyuktosunoglu, A.},
 year = {2005},
 pages = {42--53},
 publisher = {IEEE},
 title = {A High Performance, Energy Efficient GALS ProcessorMicroarchitecture with Reduced Implementation Complexity},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430558},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430558},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430558.pdf?arnumber=1430558},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Clocks, Costs, Degradation, Energy efficiency, Frequency synchronization, L2 cache, Merging, Microprocessors, Processor scheduling, Synchronous generators, Voltage, benchmark suite, benchmark testing, cache storage, clocks, computer architecture, energy efficient GALS processor, globally asynchronous locally synchronous approach, microarchitecture, microprocessor chip, microprocessor chips, multiple clock domain processor, reorder buffer, synchronisation, synchronization channels, },
 abstract = {As the costs and challenges of global clock distribution grow with each new microprocessor generation, a globally asynchronous, locally synchronous (GALS) approach becomes an attractive alternative. One proposed GALS approach, called a multiple clock domain (MCD) processor, achieves impressive energy savings for a relatively low performance cost. However, the approach requires separating the processor into four domains, including separating the integer and memory domains which complicates load scheduling, and the implementation of 32 voltage and frequency levels in each domain. In addition, the hardware-based control algorithm, though effective overall, produces a significant performance degradation for some applications. In this paper, we devise modifications to the MCD design that retain many of its benefits while greatly reducing the implementation complexity. We first determine that the synchronization channels that are most responsible for the MCD performance degradation are those involving cache access, and propose merging the integer and memory domains to virtually eliminate this overhead. We further propose significantly reducing the number of voltage levels, separating the reorder buffer into its own domain to permit front-end frequency scaling, separating the L2 cache to permit standard power optimizations to be used, and a new online algorithm that provides consistent results across our benchmark suite. The overall result is a significant reduction in the performance degradation of the original MCD approach and greater energy savings, with a greatly simplified microarchitecture that is much easier to implement },
}

@inproceedings{4211018,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Over, A. and Clarke, B. and Strazdins, P.},
 year = {2007},
 pages = {12--22},
 publisher = {IEEE},
 title = {A Comparison of Two Approaches to Parallel Simulation of Multiprocessors},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363732},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211018},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211018.pdf?arnumber=4211018},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Analytical models, Computational modeling, Computer simulation, Discrete event simulation, Multicore processing, Multiprocessing systems, NAS parallel benchmarks, Power system modeling, Process design, Protocols, Sparc Sulima, UltraSPARC IIICu-based multiprocessor systems, Yarn, careful locking, discrete event simulation, interconnect model, load-balancing, multiprocessing systems, parallel discrete event simulation, parallel simulation, resource allocation, serial simulation, simulation time quantum, speedup analysis, },
 abstract = {The design trend towards CMPs has made the simulation of multiprocessor systems a necessity and has also made multiprocessor systems widely available. While a serial multiprocessor simulation necessarily imposes a linear slowdown, running such a simulation in parallel may help mitigate this effect. In this paper we document our experiences with two different methods of parallelizing Sparc Sulima, a simulator of UltraSPARC IIICu-based multiprocessor systems. In the first approach, a simple interconnect model within the simulator is parallelized non-deterministically using careful locking. In the second, a detailed interconnect model is parallelized while preserving determinism using parallel discrete event simulation (PDES) techniques. While both approaches demonstrate a threefold speedup using 4 threads on workloads from the NAS parallel benchmarks, speedup proved constrained by load-balancing between simulated processors. A theoretical model is developed to help understand why observed speedup is less than ideal. An analysis of the related speed-accuracy tradeoff in the first approach with respect to the simulation time quantum is also given; the results show that, for both serial and parallel simulation, a quantum in the order of a few hundreds of cycles represents a `sweet-spot', but parallel simulation is significantly more accurate for a given quantum size. As with the speedup analysis, these effects are workload dependent },
}

@inproceedings{4211019,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Yourst, M.T.},
 year = {2007},
 pages = {23--34},
 publisher = {IEEE},
 title = {PTLsim: A Cycle Accurate Full System x86-64 Microarchitectural Simulator},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363733},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211019},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211019.pdf?arnumber=4211019},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {AMD Athlon 64 machine, Computational modeling, Computer simulation, Hardware, Microarchitecture, Microprocessors, Out of order, PTLsim, Pipelines, SMP, SMT, Surface-mount technology, Virtual machine monitors, Virtual machining, Xen hypervisor, benchmark testing, client-server networked benchmark, computer architecture, cycle accurate full system, full-speed native execution, fullsystem, microarchitectural simulators, microoperation level, multiprocessing systems, multiprocessor capable simulation, simulation, superscalar x86-64 processor core, virtual machine, virtual machines, x86 ISA, x86-64, x86-64 microarchitectural simulator, },
 abstract = {In this paper, we introduce PTLsim, a cycle accurate full system x86-64 microprocessor simulator and virtual machine. PTLsim models a modern superscalar out of order x86-64 processor core at a configurable level of detail ranging from RTL-level models of all key pipeline structures, caches and devices up to full-speed native execution on the host CPU. Unlike other microarchitectural simulators, PTLsim targets the real commercially available x86 ISA, rather than a discontinued architecture with limited tools and an uncertain future. PTLsim supports several flavors: a single threaded userspace version and a full system version providing an SMT model and the infrastructure for multi-core support. We first describe what it takes to perform cycle accurate modeling of a complete x86 machine at the muop (micro-operation) level, along with the challenges and requirements for effective full system multi-processor capable simulation. We then describe the internal architecture of full system PTLsim and how it interacts with the Xen hypervisor and PTLsim's native mode co-simulation technology. We experimentally evaluate PTLsim's real world accuracy by configuring it like an AMD Athlon 64 machine before running a demanding full system client-server networked benchmark inside PTLsim. We compare the statistics generated by our model with the actual numbers from the real processor to demonstrate PTLsim is accurate to within 5\% across all major parameters. We provide a discussion of prior simulation tools, along with their strengths and weaknesses. We describe why PTLsim's x86 focus is highly relevant, and we use our full system simulation results to demonstrate the pitfalls of userspace only simulation. Finally, we conclude by detailing future work },
}

@inproceedings{1291342,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Chase, C. and Ullah, N.},
 year = {2004},
 pages = { iii-- iii},
 publisher = {IEEE},
 title = {General Chairs' Message},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291342},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291342},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291342.pdf?arnumber=1291342},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{5452060,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {McCurdy, C. and Vetter, J.},
 year = {2010},
 pages = {87--96},
 publisher = {IEEE},
 title = {Memphis: Finding and fixing NUMA-related performance problems on multi-core platforms},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452060},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452060},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452060.pdf?arnumber=5452060},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Automatic control, CADCAM, Computer aided manufacturing, Counting circuits, Delay, Hardware, Laboratories, Memphis, NUMA related performance problems, Programming profession, Sampling methods, Sockets, data-centric toolset, hardware performance counters, instruction based sampling, micro-processor design, multi-core platforms, multiprocessing programs, non-uniform memory access, performance evaluation, problematic memory accesses, },
 abstract = {Until recently, most high-end scientific applications have been immune to performance problems caused by Non-Uniform Memory Access (NUMA). However, current trends in micro-processor design are pushing NUMA to smaller and smaller scales. This paper examines the current state of NUMA and makes several contributions. First, we summarize the performance problems that NUMA can present for multi-threaded applications and describe methods of addressing them. Second, we demonstrate that NUMA can indeed be a significant problem for scientific applications, showing that it can mean the difference between an application scaling perfectly and failing to scale at all. Third, we describe, in increasing order of usefulness, three methods of using hardware performance counters to aid in finding NUMA-related problems. Finally, we introduce Memphis, a data-centric toolset that uses Instruction Based Sampling to help pinpoint problematic memory accesses, and demonstrate how we used it to improve the performance of several production-level codes - HYCOM, XGC1 and CAM - by 13\%, 23\% and 24\% respectively. },
}

@inproceedings{4919626,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {iii--iv},
 publisher = {IEEE},
 title = {Message from the program chair},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919626},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919626},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919626.pdf?arnumber=4919626},
 isbn = {978-1-4244-4184-6},
 language = {English},
 abstract = {},
}

@inproceedings{4510743,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Ying Zhang and Xuejun Yang and Guibin Wang and Rogers, I. and Gen Li and Yu Deng and Xiaobo Yan},
 year = {2008},
 pages = {105--114},
 publisher = {IEEE},
 title = {Scientific Computing Applications on a Stream Processor},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510743},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510743},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510743.pdf?arnumber=4510743},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Application software, Computer architecture, FORTRAN, FORTRAN, Kernel, Optimizing compilers, Page description languages, Performance analysis, Programming profession, Resource management, Scientific computing, Streaming media, parallel programming, scientific computing, stream processor architecture, stream programming model, },
 abstract = {Stream processors, developed for the stream programming model, perform well on media applications. In this paper we examine the applicability of a stream processor to scientific computing applications. Eight scientific applications, each having different performance characteristics, are mapped to a stream processor. Due to the novelty of the stream programming model, we show how to map programs in a traditional language, such as FORTRAN. In a stream processor system, the management of system resources is the programmers' responsibility. We present several optimizations, which enable mapped programs to exploit various aspects of the stream processor architecture. Finally, we analyze the performance of the stream processor and the presented optimizations on a set of scientific computing applications. The stream programs are from 1.67 to 32.5 times faster than the corresponding FORTRAN programs on an Itanium 2 processor, with the optimizations playing an important role in realizing the performance improvement. },
}

@inproceedings{4510751,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Jun Yang and Xiuyi Zhou and Chrobak, M. and Youtao Zhang and Lingling Jin},
 year = {2008},
 pages = {191--201},
 publisher = {IEEE},
 title = {Dynamic Thermal Management through Task Scheduling},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510751},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510751},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510751.pdf?arnumber=4510751},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Dynamic scheduling, Energy consumption, Hardware, Linux, Linux kernel, Microprocessors, Power generation, Processor scheduling, Scheduling algorithm, Temperature measurement, Temperature sensors, Thermal management, dynamic thermal management, frequency scaling, heat generation speed on-die, heuristic algorithm, microprocessor chips, microprocessors, power aware computing, power consumption, processor scheduling, task analysis, task scheduling, thermal management (packaging), thermal-aware job scheduling, voltage scaling, },
 abstract = {The evolution of microprocessors has been hindered by their increasing power consumption and the heat generation speed on-die. High temperature impairs the processor's reliability and reduces its lifetime. While hardware level dynamic thermal management (DTM) techniques, such as voltage and frequency scaling, can effectively lower the chip temperature when it surpasses the thermal threshold, they inevitably come at the cost of performance degradation. We propose an OS level technique that performs thermal- aware job scheduling to reduce the number of thermal trespasses. Our scheduler reduces the amount of hardware DTMs and achieves higher performance while keeping the temperature low. Our methods leverage the natural discrepancies in thermal behavior among different workloads, and schedule them to keep the chip temperature below a given budget. We develop a heuristic algorithm based on the observation that there is a difference in the resulting temperature when a hot and a cool job are executed in a different order. To evaluate our scheduling algorithms, we developed a lightweight runtime temperature monitor to enable informed scheduling decisions. We have implemented our scheduling algorithm and the entire temperature monitoring framework in the Linux kernel. Our proposed scheduler can remove 10.5-73.6\% of the hardware DTMs in various combinations of workloads in a medium thermal environment. As a result, the CPU throughput was improved by up to 7.6\% (4.1\% on average) even under a severe thermal environment. },
}

@inproceedings{4510750,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Ould-Ahmed-Vall, E.-M. and Doshi, K.A. and Yount, C. and Woodlee, J.},
 year = {2008},
 pages = {179--190},
 publisher = {IEEE},
 title = {Characterization of SPEC CPU2006 and SPEC OMP2001: Regression Models and their Transferability},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510750},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510750},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510750.pdf?arnumber=4510750},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Design engineering, Design optimization, Hardware, Microarchitecture, Performance analysis, Regression tree analysis, SPEC CPU2006, SPEC OMP2001, Software design, Software performance, Statistical analysis, Testing, mathematics computing, microarchitectural events, model transferability, regression analysis, software performance evaluation, statistical regression models, workload execution, workload identification, },
 abstract = {Analysis of workload execution and identification of software and hardware performance barriers provide critical engineering benefits; these include guidance on software optimization, hardware design tradeoffs, configuration tuning, and comparative assessments for platform selection. This paper uses Model trees to build statistical regression models for the SPEC1 CPU2006 and the SPEC OMP2001 suites. These models link performance to key microarchitectural events. The models provide detailed recipes for identifying the key performance factors for each suite and for determining the contribution of each factor to performance. The paper discusses how the models can be used to understand the behaviors of the two suites on a modern processor. These models are applied to obtain a detailed performance characterization of each benchmark suite and its member workloads and to identify the commonalities and distinctions among the performance factors that affect each of the member workloads within the two suites. This paper also addresses the issue of model transferability. It explores the question: How useful is an existing performance model (built on a given suite of workloads) to study the performance of different workloads or suites of workloads? A performance model built using data from workload suite P is considered transferable to workload suite Q if it can be used to accurately study the performance of workload suite Q. Statistical methodologies to assess model transferability are discussed. In particular, the paper explores the use of two-sample hypothesis tests and prediction accuracy analysis techniques to assess model transferability. It is found that a model trained using only 10\% of the SPEC CPU2006 data is transferable to the remaining data. This finding holds also for SPEC OMP2001. In contrast, it is found that the SPEC CPU2006 model is not transferable to SPEC OMP2001 and vice versa. },
}

@inproceedings{4510753,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Biberstein, M. and Shvadron, U. and Turek, J. and Mendelson, B. and Chang, M.S.},
 year = {2008},
 pages = {213--222},
 publisher = {IEEE},
 title = {Trace-based Performance Analysis on Cell BE},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510753},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510753},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510753.pdf?arnumber=4510753},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Application software, Computer architecture, Debugging, Multicore processing, Performance analysis, Program processors, Programming profession, Runtime, Timing, Visualization, analysis tools, compiler, multicore architectures, performance debugging tool, performance evaluation, program compilers, program debugging, program execution, programming models, programming systems, software infrastructure, software performance evaluation, software tools, trace-based performance analysis, },
 abstract = {The transition to multicore architectures creates significant challenges for programming systems. Taking advantage of specialized processing cores such as those in the Cell BE processor and managing all the required data movement inside the processor cannot be done efficiently without help from the software infrastructure. Alongside new programming models and compiler support for multicores, programmers need performance evaluation and analysis tools. In this paper, we present tools that help analyze the performance of applications executing on the Cell platform. The performance debugging tool (PDT) provides a means for recording significant events during program execution, maintaining the sequential order of events, and preserving important runtime information such as core assignment and relative timing of events. The trace analyzer (TA) reads and visualizes the PDT traces. We describe the architecture of the PDT and present several important use cases demonstrating the usage of PDT and TA to understand the performance of several workloads. We also discuss the overhead of tracing and its impact on the benchmark execution and performance analysis. },
}

@inproceedings{4510752,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Ramachandran, P. and Adve, S.V. and Bose, P. and Rivers, J.A.},
 year = {2008},
 pages = {202--212},
 publisher = {IEEE},
 title = {Metrics for Architecture-Level Lifetime Reliability Analysis},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510752},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510752},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510752.pdf?arnumber=4510752},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Accelerated aging, Computer science, Electric breakdown, Electromigration, Failure analysis, MTTF metric, Microarchitecture, Negative bias temperature instability, Niobium compounds, Process design, Rivers, architecture-level lifetime reliability analysis, integrated circuit reliability, mean time to failure, microarchitectural enhancements, microprocessor chips, nTTF metric, processor lifetime reliability, relative vulnerability factor, reliability metric, reliability-aware design, },
 abstract = {This work concerns metrics for evaluating microarchitectural enhancements to improve processor lifetime reliability. A commonly reported reliability metric is mean time to failure (MTTF). Although the MTTF metric is simpler to evaluate, it does not provide information on the reliability characteristics during the relatively short operational life of commodity processors. An alternate metric is nTTF, which represents the time to failure of n\% of the processor population. nTTF is a more informative metric for the (short) portion of the lifetime that is relevant to the end- user, but determining it requires knowledge of the distribution of processor failure times which is generally hard to obtain. The goals of this paper are (1) to determine if the choice of metric has a quantitative impact on architecture-level reliability analysis and modern superscalar processor designs and (2) to build a fundamental understanding of why and when MTTF- and nTTF- driven analysis result in different designs. We show through an in- depth analysis that, in general, the nTTF metric differs significantly from the MTTF metric, and using MTTF as a proxy for nTTF leads to sub-optimal designs. Additionally, our analysis introduces the concept of relative vulnerability factor (RVF) for different processor components to guide reliability-aware design. We show that the difference between nTTF- and MTTF-driven design largely occurs because the relative vulnerabilities of the processor components change over the processor lifetime, making the optimal design choice dependent on the amount of time the processor is expected to be used. },
}

@inproceedings{4919639,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Kulkarni, M. and Burtscher, M. and Cascaval, C. and Pingali, K.},
 year = {2009},
 pages = {65--76},
 publisher = {IEEE},
 title = {Lonestar: A suite of parallel irregular programs},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919639},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919639},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919639.pdf?arnumber=4919639},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Buildings, Clustering algorithms, Computational modeling, Concurrent computing, Data mining, Lonestar, Machine learning, Machine learning algorithms, Parallel processing, Parallel programming, Sparse matrices, amorphous data-parallelism, data mining, data mining, design automation, graph theory, parallel irregular programming, parallel programming, sparse graph, survey propagation, },
 abstract = {Until recently, parallel programming has largely focused on the exploitation of data-parallelism in dense matrix programs. However, many important application domains, including meshing, clustering, simulation, and machine learning, have very different algorithmic foundations: they require building, computing with, and modifying large sparse graphs. In the parallel programming literature, these types of applications are usually classified as irregular applications, and relatively little attention has been paid to them. To study and understand the patterns of parallelism and locality in sparse graph computations better, we are in the process of building the Lonestar benchmark suite. In this paper, we characterize the first five programs from this suite, which target domains like data mining, survey propagation, and design automation. We show that even such irregular applications often expose large amounts of parallelism in the form of amorphous data-parallelism. Our speedup numbers demonstrate that this new type of parallelism can successfully be exploited on modern multi-core machines. },
}

@inproceedings{4510754,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Jizhu Lu and Perrone, M. and Albayraktaroglu, K. and Franklin, M.},
 year = {2008},
 pages = {223--232},
 publisher = {IEEE},
 title = {HMMer-Cell: High Performance Protein Profile Searching on the Cell/B.E. Processor},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510754},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510754},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510754.pdf?arnumber=4510754},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Bioinformatics, Cell/B.E. multiprocessor architecture, Computer applications, Computer architecture, Educational institutions, Engines, HMMer-Cell, Hidden Markov models, Microprocessors, Plan7 Viterbi algorithm, Proteins, Sequences, Viterbi algorithm, biology computing, cellular biophysics, code partitioning, commodity x86 processor, computational complexity, computationally intensive bioinformatics, memory requirement, multiprocessing systems, protein, space complexity, synergistic processing element, task parallelization, },
 abstract = {This paper presents HMMer-Cell, an implementation of the computationally intensive bioinformatics application HMMER on the Cell/B.E. multiprocessor architecture. The core of the HMMER workload is the Plan7 Viterbi algorithm, which has a memory requirement of O(N*M) where N is the length of the HMM and M is the length of the input sequence length. The main challenge in implementing the Plan7 Viterbi algorithm on the novel Cell/B.E. multiprocessor is the limited local storage space of the Cell/B.E. SPEs (synergistic processing element). We describe our approach to modifying the Viterbi algorithm to reduce the space complexity from 0(M*N) to O(N). We then proceed to discuss design considerations such as task parallelization and code partitioning, in addition to other optimizations we used to implement HMMer-Cell. We demonstrate near-linear speedup when processing relatively larger HMM profiles; and compare our results to those obtained on commodity x86 processors. },
}

@inproceedings{4919635,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Zaparanuks, D. and Jovic, M. and Hauswirth, M.},
 year = {2009},
 pages = {23--32},
 publisher = {IEEE},
 title = {Accuracy of performance counter measurements},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919635},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919635},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919635.pdf?arnumber=4919635},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {AMD ATHLON 64 X2, Application software, Core 2 Duo, Costs, Counting circuits, Hardware, Informatics, Kernel, Measurement errors, Microarchitecture, PAPI, Pentium D, Watches, Yarn, clock cycles, hardware performance counters, micro-architectural events, microprocessor chips, perfctr, perfmon2, performance counter measurements, performance evaluation, performance evaluations, retired instructions, software architecture, software infrastructures, user-level code, },
 abstract = {Many experimental performance evaluations depend on accurate measurements of the cost of executing a piece of code. Often these measurements are conducted using infrastructures to access hardware performance counters. Most modern processors provide such counters to count micro-architectural events such as retired instructions or clock cycles. These counters can be difficult to configure, may not be programmable or readable from user-level code, and can not discriminate between events caused by different software threads. Various software infrastructures address this problem, providing access to per-thread counters from application code. This paper constitutes the first comparative study of the accuracy of three commonly used measurement infrastructures (perfctr, perfmon2, and PAPI) on three common processors (Pentium D, Core 2 Duo, and AMD ATHLON 64 X2). },
}

@inproceedings{4919634,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Bin Lin and Mallik, A. and Dinda, P. and Memik, G. and Dick, R.},
 year = {2009},
 pages = {11--22},
 publisher = {IEEE},
 title = {User- and process-driven dynamic voltage and frequency scaling},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919634},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919634},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919634.pdf?arnumber=4919634},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {CPU, DVFS, Dynamic voltage scaling, Energy consumption, Energy management, Feedback, Frequency, Kernel, Manufacturing processes, Power measurement, Stability, Temperature, direct user feedback, dynamic voltage- frequency scaling, encoding, encoding, power aware computing, power management, power reduction techniques, process-driven voltage scaling, processors, program processors, user-driven frequency scaling, workload, },
 abstract = {We describe and evaluate two new, independently-applicable power reduction techniques for power management on processors that support dynamic voltage and frequency scaling (DVFS): user-driven frequency scaling (UDFS) and process-driven voltage scaling (PDVS). In PDVS, a CPU-customized profile is derived offline that encodes the minimum voltage needed to achieve stability at each combination of CPU frequency and temperature. On a typical processor, PDVS reduces the voltage below the worst-case minimum operating voltages given in datasheets. UDFS, on the other hand, dynamically adapts CPU frequency to the individual user and the workload through direct user feedback. Our UDFS algorithms dramatically reduce typical operating frequencies and voltages while maintaining performance at a satisfactory level for each user. We evaluate our techniques independently and together through user studies conducted on a Pentium M laptop running Windows applications. We measure the overall system power and temperature reduction achieved by our methods. Combining PDVS and the best UDFS scheme reduces measured system power by 49.9\% (27.8\% PDVS, 22.1\% UDFS), averaged across all our users and applications, compared to Windows XP DVFS. The average temperature of the CPU is decreased by 13.2degC. User trace-driven simulation to evaluate the CPU only indicates average CPU dynamic power savings of 57.3\% (32.4\% PDVS, 24.9\% UDFS), with a maximum reduction of 83.4\%. In a multitasking environment, the same UDFS+PDVS technique reduces the CPU dynamic power by 75.7\% on average. },
}

@inproceedings{4919637,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Merino, J. and Alvarez, L. and Gil, M. and Navarro, N.},
 year = {2009},
 pages = {43--52},
 publisher = {IEEE},
 title = {Cetra: A trace and analysis framework for the evaluation of Cell BE systems},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919637},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919637},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919637.pdf?arnumber=4919637},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Cetra, Computer architecture, Contracts, Electronic mail, Engines, Gas insulated transmission lines, Kernel, Linux, Linux, Linux, Operating systems, Performance analysis, PowerPC core, Processor scheduling, accelerators, analysis framework, cell broadband engine architecture, computer architecture, consumer-level devices, heterogeneous multiprocessor architecture, high-performance computing systems, multiprocessing systems, multiprogrammed environments, operating system internal algorithms, operating system kernel, operating system kernels, queue-based environment, scheduling, scheduling starvation bug, task scheduling, trace framework, },
 abstract = {The cell broadband engine architecture (CBEA) is an heterogeneous multiprocessor architecture developed by Sony, Toshiba and IBM. The major implementation of this architecture is the cell broadband engine (cell for short), a processor that contains one generic PowerPC core and eight accelerators. The cell is targeted at high-performance computing systems and consumer-level devices that have high computational requirements. The workloads for the former are generally run in a queue-based environment while those for the latter are multiprogrammed. Applications for the cell are composed of multiple parallel tasks: one runs on the PowerPC core and one or more run on the accelerators. The operating system (OS) is in charge of scheduling these tasks on top of the physical processors, and such scheduling decisions become critical in multiprogrammed environments. System developers need a way to analyze how user applications behave in these conditions to be able to tune the OS internal algorithms. This article presents Cetra, a new tool-set that allows system developers to study how cell workloads interact with Linux, the OS kernel. First, we outline the major features of Cetra and provide a detailed description of its internals. Then, we demonstrate the usefulness of Cetra by presenting a case study that shows the features of the tool-set and allows us to compare the results to those provided by other performance analysis tools available in the market. At last, we describe another case study in which we discovered a scheduling starvation bug using Cetra. },
}

@inproceedings{4510741,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Hasan, O. and Tahar, S.},
 year = {2008},
 pages = {85--94},
 publisher = {IEEE},
 title = {Performance Analysis of ARQ Protocols using a Theorem Prover},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510741},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510741},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510741.pdf?arnumber=4510741},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {ARQ protocols, Analytical models, Automatic repeat request, Computational modeling, Computer errors, Computer simulation, Delay, Logic, Performance analysis, Protocols, Random variables, automatic repeat request, automatic-repeat-request protocols, computer networks, geometric random variable, higher-order-logic theorem prover, },
 abstract = {Automatic-repeat-request (ARQ) protocols are widely used in modern data communications to guarantee reliable transmission over imperfect physical links. The behavior of an ARQ protocol largely depends on a number of network parameters and traditionally simulation is used for their performance analysis. However, simulation provides less accurate results and usually requires enormous amount of CPU time in order to attain reasonable estimates. To overcome these limitations, we propose to conduct the performance analysis of ARQ protocols in the environment of a higher-order-logic theorem prover (HOL). We present an approach to formally model the delay characteristics of ARQ protocols as a function of geometric random variable in higher-order-logic. In particular, we develop higher-order-logic models that describe the delay behavior of three basic types of ARQ protocols, i.e., Stop-and-Wait, Go-Back-N and Selective-Repeat. The paper also includes the verification of the average message delay relations for these three protocols in HOL. },
}

@inproceedings{4919631,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {x--xi},
 publisher = {IEEE},
 title = {Table of contents},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919631},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919631},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919631.pdf?arnumber=4919631},
 isbn = {978-1-4244-4184-6},
 language = {English},
 abstract = {},
}

@inproceedings{5452044,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Shaw, D.},
 year = {2010},
 pages = {121--121},
 publisher = {IEEE},
 title = {Using special-purpose hardware to achieve a hundred-fold speedup in molecular dynamics simulations of proteins},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452044},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452044},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452044.pdf?arnumber=5452044},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Anton machine, Biological information theory, Biological system modeling, Computational modeling, Drugs, Hardware, Molecular biophysics, Parallel machines, Pharmaceutical technology, Protein engineering, Target recognition, biological macromolecules, biology computing, hundred-fold speedup, molecular dynamics simulation, parallel machine, parallel machines, proteins simulations, proteomics, special-purpose hardware, },
 abstract = {Summary form only given. Molecular dynamics (MD) simulation has long been recognized as a potentially transformative tool for understanding the behavior of proteins and other biological macromolecules, and for developing a new generation of precisely targeted drugs. Many biologically important phenomena, however, occur over timescales that have previously fallen far outside the reach of MD technology. We have constructed a specialized, massively parallel machine, called Anton, that is capable of performing atomic-level simulations of proteins at a speed roughly two orders of magnitude beyond that of the previous state of the art. The machine has now simulated the behavior of a number of proteins for periods as long as a millisecond -- approximately 100 times the length of the longest such simulation previously published -- revealing aspects of protein dynamics that were previously inaccessible to both computational and experimental study. The speed at which Anton performs these simulations is the result of a tightly coupled codesign process in which novel algorithms and architectural features were developed in concert, guided in large part by an iterative process of performance analysis and optimization. },
}

@inproceedings{4919633,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Wei Huang and Skadron, K. and Gurumurthi, S. and Ribando, R.J. and Stan, M.R.},
 year = {2009},
 pages = {1--10},
 publisher = {IEEE},
 title = {Differentiating the roles of IR measurement and simulation for power and temperature-aware design},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919633},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919633},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919633.pdf?arnumber=4919633},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Cooling, Energy consumption, Energy management, HotSpot thermal model, Infrared imaging, Optical imaging, Packaging, Petroleum, Power measurement, Semiconductor device measurement, Thermal management, bare silicon, cooling configurations, copper heatsink, forced air flow, heat sinks, heat transfer, hot spot identification, infrared imaging, infrared measurement, laminar air flow, laminar flow, package pins, secondary heat transfer, spot location, steady-state thermal responses, temperature sensors, temperature-aware design process, thermal sensor placement, transient response, },
 abstract = {In temperature-aware design, the presence or absence of a heatsink fundamentally changes the thermal behavior with important design implications. In recent years, chip-level infrared (IR) thermal imaging has been gaining popularity in studying thermal phenomena and thermal management, as well as reverse-engineering chip power consumption. Unfortunately, IR thermal imaging needs a peculiar cooling solution, which removes the heatsink and applies an IR-transparent liquid flow over the exposed bare die to carry away the dissipated heat. Because this cooling solution is drastically different from a normal thermal package, its thermal characteristics need to be closely examined. In this paper, we characterize the differences between two cooling configurations-forced air flow over a copper heatsink (AIR-SINK) and laminar oil flow over bare silicon (OIL-SILICON). For the comparison, we modify the HotSpot thermal model by adding the IR-transparent oil flow and the secondary heat transfer path through the package pins, hence modeling what the IR camera actually sees at runtime. We show that OIL-SILICON and AIR-SINK are significantly different in both transient and steady-state thermal responses. OIL-SILICON has a much slower short-term transient response, which makes dynamic thermal management less efficient. In addition, for OIL-SILICON, the direction of oil flow plays an important role by changing hot spot location, thus impacting hot spot identification and thermal sensor placement. These results imply that the power- and temperature-aware design process cannot just rely on IR measurements. Simulation and IR measurement are both needed and are complementary techniques. },
}

@inproceedings{4919632,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {xii--xii},
 publisher = {IEEE},
 title = {Blank page},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919632},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919632},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919632.pdf?arnumber=4919632},
 isbn = {978-1-4244-4184-6},
 language = {English},
 abstract = {},
}

@inproceedings{4919657,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {259--260},
 publisher = {IEEE},
 title = {Author index},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919657},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919657},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919657.pdf?arnumber=4919657},
 isbn = {978-1-4244-4184-6},
 language = {English},
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04919657.png" border="0"> },
}

@inproceedings{4919656,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Dam Sunwoo and Joonsoo Kim and Chiou, D.},
 year = {2009},
 pages = {249--258},
 publisher = {IEEE},
 title = {QUICK: A flexible full-system functional model},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919656},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919656},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919656.pdf?arnumber=4919656},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Algorithms, Analytical models, Computational modeling, Computer aided manufacturing, Costs, Instruction sets, Internet Explorer, Linux, Microarchitecture, Performance analysis, QUICK, Timing, YouTube, complete-and-rollback functional model, complete-and-rollback functional simulator, digital simulation, flexible full-system functional model, functional execution, functional/timing partitioned simulator, on-the-fly modification, rollback capability, simulated machines, },
 abstract = {In this paper, we introduce the concept of full-system complete-and-rollback functional simulators that make efficient functional models in functional/timing partitioned simulators. Complete-and-rollback functional simulators can efficiently drive simulators of resolutions ranging from functional-only to cycle-accurate for a wide range of simulated machines. Complete-and-rollback functional models achieve their capabilities by executing instructions to completion, enabling their execution to be highly optimized, but providing rollback capabilities to enable on-the-fly modifications to the functional execution. We also introduce QUICK, an implementation of a full-system complete-and-rollback functional model that supports the x86 and PowerPC ISAs, boots unmodified Windows XP and Linux, and runs unmodified applications such as YouTube on Internet Explorer while fully supporting rollbacks, including across I/O operations. We present various case studies using QUICK and conduct performance analyses to demonstrate its simulation performance. },
}

@inproceedings{4919655,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Kiyeon Lee and Evans, S. and Sangyeun Cho},
 year = {2009},
 pages = {238--248},
 publisher = {IEEE},
 title = {Accurately approximating superscalar processor performance from traces},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919655},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919655},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919655.pdf?arnumber=4919655},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Computational modeling, Computer errors, Computer science, Computer simulation, Delay, Information filtering, Information filters, L1 cache misses, Multicore processing, Predictive models, Process design, cache storage, configurable multicore processor simulation, independent cache miss model, isolated cache miss model, microprocessor chips, pairwise dependent cache miss model, perfect branch prediction, predetermined processor core design, superscalar processor performance approximation, trace reduction, trace-driven simulation, },
 abstract = {Trace-driven simulation of superscalar processors is particularly complicated. The dynamic nature of superscalar processors combined with the static nature of traces can lead to large inaccuracies in the results, especially when traces contain only a subset of executed instructions for trace reduction. The main problem in the filtered trace simulation is that the trace does not contain enough information with which one can predict the actual penalty of a cache miss. In this paper, we discuss and evaluate three strategies to quantify the impact of a long latency memory access in a superscalar processor when traces have only L1 cache misses. The strategies are based on models about how a cache miss is treated with respect to other cache misses: (1) isolated cache miss model, (2) independent cache miss model, and (3) pairwise dependent cache miss model. Our experimental results demonstrate that the pairwise dependent cache miss model produces reasonably accurate results (4.8\% RMS error) under perfect branch prediction. Our work forms a basis for fast, accurate, and configurable multicore processor simulation using a pre-determined processor core design. },
}

@inproceedings{4919654,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Ringenberg, J. and Mudge, T.},
 year = {2009},
 pages = {227--237},
 publisher = {IEEE},
 title = {SuiteSpecks and SuiteSpots: A methodology for the automatic conversion of benchmarking programs into intrinsically checkpointed assembly code},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919654},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919654},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919654.pdf?arnumber=4919654},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Assembly, Benchmark testing, Checkpointing, Computational modeling, Computer science, Computer simulation, Error analysis, Microarchitecture, Microprocessors, Sampling methods, SuiteSpecks, SuiteSpots, checkpointing, intrinsically checkpointed assembly code, program assemblers, },
 abstract = {This paper introduces a methodology to reduce the overall simulation time of large benchmarking suites. Previous work shows that it is possible to simulate only small sections of a benchmark's dynamic instruction stream in detail without sacrificing accuracy in simulation results with respect to overall behavior. As benchmarking suites increase in size, many such techniques still require a great deal of simulation time to complete. The methods presented in this paper build on this previous work by converting representative sections of a benchmark's execution into intrinsically checkpointed assembly (ITCY) code that can serve as a replacement for the original benchmark. In addition, a methodology is proposed that creates new benchmark binaries that no longer need input files or system calls in order to execute properly. Simulations of the new benchmarks are much faster, require less overhead, and still properly represent the original benchmark's execution profile. Results show that benchmarks created using these techniques can be very portable and accurately predict the performance of the original benchmark. An average error rate of less than 5\% is achieved when compared to the original representative sections. In addition, a speedup of approximately 60times per benchmark is achieved over a standard set of SimPoints when the new benchmarks are executed serially and 1000times when executed in parallel. This translates into a reduction in simulation time from months to minutes and greatly decreases the amount of time necessary to test a new design. },
}

@inproceedings{4919653,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Yu Zhang and Ozisikyilmaz, B. and Memik, G. and Kim, J. and Choudhary, A.},
 year = {2009},
 pages = {218--226},
 publisher = {IEEE},
 title = {Analyzing the impact of on-chip network traffic on program phases for CMPs},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919653},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919653},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919653.pdf?arnumber=4919653},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Data mining, Degradation, Error analysis, Frequency, Information analysis, Manufacturing, Mine-Bench, Network-on-a-chip, Phase detection, SPLASH2, Solid modeling, Telecommunication traffic, chip multiprocessor, error statistics, instruction-based phase detection, microprocessor chips, multiprocessing systems, network routing, onchip network traffic, },
 abstract = {It is known that the execution of programs exhibits repetitive phases; in other words, the execution of programs can be partitioned into segments of execution, during which the application exhibits unique architectural properties. This property has been used for various optimization goals. In addition, phase information is utilized to reduce the run time of the architectural simulation. Conventionally, an application is examined in an architecture-independent manner (such as the number of times a basic block is executed) to extract information about the phases and then only the representative execution intervals are executed to analyze architectural choices. We claim that such approaches are becoming inadequate in the many-core era as application execution is not dominated by the instructions only, but instead the communication structure of the application is becoming as important as the instruction behavior. Hence, we propose to utilize communication behavior to determine the phases of an application. Our results reveal that the inclusion of the communication information can increase the accuracy of the phase detection significantly. Specifically, for SPLASH2 and Mine-Bench applications, the average (geometric mean) CPI error rate with the instruction-based phase detection is 11.01\%, while our phase detection scheme has an average error rate of 3.41\% when compared to the simulations that run the applications to completion. },
}

@inproceedings{4919652,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Uzelac, V. and Milenkovic, A.},
 year = {2009},
 pages = {207--217},
 publisher = {IEEE},
 title = {Experiment flows and microbenchmarks for reverse engineering of branch predictor structures},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919652},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919652},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919652.pdf?arnumber=4919652},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Clocks, Hardware, Hazards, History, Interference, Microprocessors, Optimizing compilers, Pipelines, Program processors, Reverse engineering, architecture-aware compiler optimization, branch address index, branch predictor structure, cache storage, cache-like branch target buffer, experiment flow, microbenchmark, optimising compilers, program path information, program performance improvement, reverse engineering, reverse engineering, software architecture, software performance evaluation, },
 abstract = {Insights into branch predictor organization and operation can be used in architecture-aware compiler optimizations to improve program performance. Unfortunately, such details are rarely publicly disclosed. In this paper we introduce a set of experiment flows and corresponding microbenchmarks for reverse engineering cache-like branch target and outcome predictor structures, indexed by branch address or program path information. The experiment flows are demonstrated on the Intel Pentium M branch predictor. We have been able to determine the size, organization, internal operation, and interactions between various hardware structures used in the Pentium M branch predictor, namely the branch target buffer, indirect branch target buffer, loop branch predictor buffer, global predictor, and bimodal predictor. These findings have been validated using a functional PIN model. },
}

@inproceedings{4919651,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Ranganathan, N. and Burger, D. and Keckler, S.W.},
 year = {2009},
 pages = {195--206},
 publisher = {IEEE},
 title = {Analysis of the TRIPS prototype block predictor},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919651},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919651},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919651.pdf?arnumber=4919651},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Accuracy, Analytical models, Computer architecture, Costs, Delay, History, Performance analysis, Predictive models, Prototypes, SPECfp2000 benchmarks, SPECint2000 benchmarks, TRIPS hyperblock, TRIPS prototype block predictor, TRIPS prototype predictor, Wire, block prediction, block-atomic TRIPS architecture, branch prediction, branch target buffers, correlation-aware hyperblock formation, data flow analysis, distributed processing, perceptron-based analysis, predictor designs, simulation-driven analysis, software architecture, },
 abstract = {This paper analyzes the performance of the TRIPS prototype chip's block predictor. The prototype is the first implementation of the block-atomic TRIPS architecture, wherein the unit of execution is a TRIPS hyperblock. The TRIPS prototype predictor uses a two-step prediction process: it first predicts the exit from the current hyperblock and uses the predicted exit in conjunction with the current hyperblock's address to predict the next hyperblock. SPECint2000 and SPECfp2000 benchmarks record average misprediction rates of 11.5\% and 4.3\%, respectively, on the prototype chip. Simulation-driven analysis identifies short history lengths, inadequate offset bits in the branch target buffers, and aliasing in the exit and target predictors as the main reasons for the predictor inefficiency. If the above issues are addressed, block misprediction rates can be reduced by 15\% for SPECint2000 and 22\% for SPECfp2000. Using a perceptron-based analysis, we show that there is significant loss in correlation in our current hyperblocks. We conclude that while carefully tuned block predictors can achieve relatively lower misprediction rates, new predictor designs and correlation-aware hyperblock formation are necessary to bridge the gap between block prediction accuracies and branch prediction accuracies. },
}

@inproceedings{4919650,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Michaud, P.},
 year = {2009},
 pages = {185--194},
 publisher = {IEEE},
 title = {Online compression of cache-filtered address traces},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919650},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919650},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919650.pdf?arnumber=4919650},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Compressors, Computational modeling, Computer architecture, Computer simulation, Filtering, Hardware, Microarchitecture, Microscopy, Multicore processing, Space exploration, cache filtered address traces, cache storage, cycle accurate simulation, data compression, high compression ratio, lossless compression, online compression, storage allocation, storage space requirement, trace compression, trace compressor, trace driven simulation, },
 abstract = {Trace-driven simulation is potentially much faster than cycle-accurate simulation. However, one drawback is the large amount of storage that may be necessary to store traces. Trace compression techniques are useful for decreasing the storage space requirement. But the compression ratio of existing trace compressors is limited because they implement lossless compression. We propose two new methods for compressing cache filtered address traces. The first method, byte sort, is a lossless compression method that achieves high compression ratios on cache-filtered address traces. The second method is a lossy one, based on the concept of phase. We have combined these two methods in a trace compressor called ATC. Our experimental results show that ATC gives high compression ratio while keeping the memory-locality characteristics of the original trace. },
}

@inproceedings{4211021,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Shuf, Y. and Steiner, I.M.},
 year = {2007},
 pages = {44--53},
 publisher = {IEEE},
 title = {Characterizing a Complex J2EE Workload: A Comprehensive Analysis and Opportunities for Optimizations},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363735},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211021},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211021.pdf?arnumber=4211021},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Hardware, J2EE workload, Java, Java, Java 2 Enterprise Edition, Java benchmarks, Java heap, Java virtual method calls, Monitoring, Performance analysis, Prefetching, Runtime, SPECjAppServer2004, SPECjbb2000, SPECjvm98, Software systems, System performance, Thumb, Yarn, bursty data cache, cache-to-cache modified data transfers, commercial workload, data prefetching, garbage collection, instruction cache, intelligent thread co-scheduling, optimising compilers, optimizations, performance analysis, processor scheduling, software research, storage management, systems research, },
 abstract = {While past studies of relatively simple Java benchmarks like SPECjvm98 and SPECjbb2000 have been integral in advancing the server industry, this paper presents an analysis of a significantly more complex 3-Tier J2EE (Java 2 Enterprise Edition) commercial workload, SPECjAppServer2004. Understanding the nature of such commercial workloads is critical to develop the next generation of servers and identify promising directions for systems and software research. In this study, we validate and disprove several assumptions commonly made about Java workloads. For instance, on a tuned system with an appropriately sized heap, the fraction of CPU time spent on garbage collection for this complex workload is small (\&lt;2\%) compared to commonly studied client-side Java benchmarks. Unlike small benchmarks, this workload has a rather "flat" method profile with no obvious hot spots. Therefore, new performance analysis techniques and tools to identify opportunities for optimizations are needed because the traditional 90/10 rule of thumb does not apply. We evaluate hardware performance monitor data and use insights to motivate future research. We find that this workload has a relatively high CPI and a branch misprediction rate. We observe that almost one half of executed instructions are loads and stores and that the data working set is large. There are very few cache-to-cache "modified data" transfers which limits opportunities for intelligent thread co-scheduling. We note that while using large pages for a Java heap is a simple and effective way to reduce TLB misses and improve performance, there is room to reduce translation misses further by placing executable code into large pages. We use statistical correlation to quantify the relationship between various hardware events and an overall system performance. We find that CPI is strongly correlated with branch mispredictions, translation misses, instruction cache misses, and bursty data cache misses that trigger data prefetching. - We note that target address mispredictions for indirect branches (corresponding to Java virtual method calls) are strongly correlated with instruction cache misses. Our observations can be used by hardware and runtime architects to estimate potential benefits of performance enhancements being considered },
}

@inproceedings{4211020,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Wenlong Li and Li, E. and Jaleel, A. and Jiulong Shan and Yurong Chen and Qigang Wang and Iyer, R. and Illikkal, R. and Yimin Zhang and Dong Liu and Liao, M. and Wei Wei and Du, J.},
 year = {2007},
 pages = {35--43},
 publisher = {IEEE},
 title = {Understanding the Memory Performance of Data-Mining Workloads on Small, Medium, and Large-Scale CMPs Using Hardware-Software Co-simulation},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363734},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211020},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211020.pdf?arnumber=4211020},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Application software, Computational modeling, Computer applications, DRAM caches, Data mining, Field programmable gate arrays, Hardware, Large-scale systems, Medical simulation, Random access memory, System performance, cache design, cache storage, data mining, hardware-software co-simulation, hardware-software codesign, large-scale CMP, medium-scale CMP, memory performance, memory system performance, multi-threading, multicore systems, multithreaded data mining applications, small-scale CMP, terabyte-level workloads, virtual machines, },
 abstract = {With the amount of data continuing to grow, extracting "data of interest" is becoming popular, pervasive, and more important than ever. Data mining, as this process is known as, seeks to draw meaningful conclusions, extract knowledge, and acquire models from vast amounts of data. These compute-intensive data-mining applications, where thread-level parallelism can be effectively exploited, are the design targets of future multi-core systems. As a result, future multi-core systems will be required to process terabyte-level workloads. To understand the memory system performance of data-mining applications, this paper presents the use of hardware-software co-simulation to explore the cache design space of several multi-threaded data mining applications. Our study reveals that the workloads are memory intensive, have large working-set sizes, and exhibit good data locality. We find that large DRAM caches can be useful to address their large working-set sizes },
}

@inproceedings{4211023,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Alvarez, M. and Salami, E. and Ramirez, A. and Valero, M.},
 year = {2007},
 pages = {62--71},
 publisher = {IEEE},
 title = {Performance Impact of Unaligned Memory Operations in SIMD Extensions for Video Codec Applications},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363737},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211023},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211023.pdf?arnumber=4211023},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Application software, Automatic voltage control, Computer architecture, H.264/AVC media codec, Hardware, Instruction sets, Kernel, Memory architecture, Performance analysis, Random access memory, SIMD extensions, Video codecs, auto vectorizing compiler, data level parallelism, memory architecture, memory architecture, multimedia computing, parallel processing, unaligned memory accesses, unaligned memory operations, video codec applications, video codecs, video coding, },
 abstract = {Although SIMD extensions are a cost effective way to exploit the data level parallelism present in most media applications, we will show that they had have a very limited memory architecture with a weak support for unaligned memory accesses. In video codec, and other applications, the overhead for accessing unaligned positions without an efficient architecture support has a big performance penalty and in some cases makes vectorization counter-productive. In this paper we analyze the performance impact of extending the Altivec SIMD ISA with unaligned memory operations. Results show that for several kernels in the H.264/AVC media codec, unaligned access support provides a speedup up to 3.8times compared to the plain SIMD version, translating into an average of 1.2times in the entire application. In addition to providing a significant performance advantage, the use of unaligned memory instructions makes programming SIMD code much easier both for the manual developer and the auto vectorizing compiler },
}

@inproceedings{4211022,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Bhat, M. and Crawford, J. and Morin, R. and Shiv, K.},
 year = {2007},
 pages = {54--61},
 publisher = {IEEE},
 title = {Performance Characterization of Decimal Arithmetic in Commercial Java Workloads},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363736},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211022},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211022.pdf?arnumber=4211022},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Application software, Bidirectional control, BigDecimal class, Costs, Floating-point arithmetic, Hardware, Java, Java, Marketing and sales, Performance analysis, SPECjAppServer2004, SPECjbb2005, Software performance, Telephony, Trade Completion, binary floating-point numbers, commercial Java workloads, decimal arithmetic, decimal math, format conversion, hashing, mathematics computing, mission-critical financial workload, optimized hardware support, performance characterization, scale manipulation, software decimal implementations, special decimal representations, },
 abstract = {Binary floating-point numbers with finite precision cannot represent all decimal numbers with complete accuracy. This can often lead to errors while performing calculations involving floating point numbers. For this reason many commercial applications use special decimal representations for performing these calculations, but their use carries performance costs such as bi-directional conversion. The purpose of this study was to understand the total application performance impact of using these decimal representations in commercial workloads, and provide a foundation of data to justify pursuing optimized hardware support for decimal math. In Java, a popular development environment for commercial applications, the BigDecimal class is used for performing accurate decimal computations. BigDecimal provides operations for arithmetic, scale manipulation, rounding, comparison, hashing, and format conversion. We studied the impact of BigDecimal usage on the performance of server-side Java applications by analyzing its usage on two standard enterprise benchmarks, SPECjbb2005 and SPECjAppServer2004 as well as a real-life mission-critical financial workload, Morgan Stanley's Trade Completion. In this paper, we present detailed performance characteristics and we conclude that, relative to total application performance, the overhead of using software decimal implementations is low, and at least from the point of view of these workloads, there is insufficient performance justification to pursue hardware solutions },
}

@inproceedings{4211025,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Kihm, J.L. and Strom, S.D. and Connors, D.A.},
 year = {2007},
 pages = {84--93},
 publisher = {IEEE},
 title = {Phase-Guided Small-Sample Simulation},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363739},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211025},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211025.pdf?arnumber=4211025},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Acceleration, Application software, Character generation, Computational modeling, Computer simulation, Process design, Robustness, Runtime, Sampling methods, Space exploration, SpedOOO benchmark suite, benchmark evaluation suite, cycle-accurate simulation, design space exploration, digital simulation, execution-aware sampling-based simulation, phase-based simulation, phase-guided small-sample simulation, processor design, sampled simulation, sampling method, sampling methods, },
 abstract = {Detailed cycle-accurate simulation is a critical component of processor design. However, with the increasing complexity of modern processors and application workloads, full detailed simulation is prohibitively slow and thereby severely limits design space exploration. Sampled simulation techniques eliminate the need for full simulation by simulating in detail a very small but representative subset of a target application's overall execution. Two effective and accurate sampling techniques are phase-based simulation and small-sample simulation. Both of these techniques have been adopted by the architecture design and simulation communities for research. However, both techniques were derived using a single benchmark evaluation suite and promote the same sampling method for all applications. Alternatively, an execution-aware sampling-based simulation technique can adapt during execution characteristics of the individual application being simulated and achieve the most efficient and accurate simulation acceleration. To evaluate the impact of application characteristics on simulation approaches, we compare several simulation techniques using the SpedOOO benchmark suite. Our results yield key conclusions about combining the strengths of previous simulation techniques into a single approach: (PGSS) phase-guided small-sample simulation. PGSS adapts sampling to the characteristics of the application, thereby achieving high sampling accuracy and requiring an order of magnitude less detailed simulation time than previous techniques },
}

@inproceedings{4211024,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Falcon, A. and Faraboschi, P. and Ortega, D.},
 year = {2007},
 pages = {72--83},
 publisher = {IEEE},
 title = {Combining Simulation and Virtualization through Dynamic Sampling},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363738},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211024},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211024.pdf?arnumber=4211024},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Acceleration, Code standards, Hardware, Joining processes, Sampling methods, Timing, Velocity measurement, Virtual machining, Virtual manufacturing, Voice mail, code caching, dynamic sampling, fast timing simulation, sampling methods, virtual machines, virtual machines, virtualization, },
 abstract = {The high speed and faithfulness of state-of-the-art virtual machines (VMs) make them the ideal front-end for a system simulation framework. However, VMs only emulate the functional behavior and just provide the minimal timing for the system to run correctly. In a simulation framework supporting the exploration of different configurations, a timing backend is still necessary to accurately determine the performance of the simulated target. As it has been extensively researched, sampling is an excellent approach for fast timing simulation. However, existing sampling mechanisms require capturing information for every instruction and memory access. Hence, coupling a standard sampling technique to a VM implies disabling most of the "tricks" used by a VM to accelerate execution, such as the caching and linking of dynamically compiled code. Without code caching, the performance of a VM is severely impacted. In this paper we present a novel dynamic sampling mechanism that overcomes this problem and enables the use of VMs for timing simulation. By making use of the internal information collected by the VM during functional simulation, we can quickly assess important characteristics of the simulated applications (such as phase changes), and activate or deactivate the timing simulation accordingly. This allows us to run unmodified OS and applications over emulated hardware at near-native speed, yet providing a way to insert timing measurements that yield a final accuracy similar to state-of-the-art sampling methods },
}

@inproceedings{4211027,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Ferdman, M. and Falsafi, B.},
 year = {2007},
 pages = {105--115},
 publisher = {IEEE},
 title = {Last-Touch Correlated Data Streaming},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363741},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211027},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211027.pdf?arnumber=4211027},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Computer architecture, Data structures, Delay, History, Laboratories, Memory, Microarchitecture, Predictive models, Prefetching, Proposals, address-correlating predictor, cache block address identification, correlation data storage, cycle-accurate simulation, last-touch correlated data streaming, last-touch predictor, low-latency lookup, off-chip correlation data lookup, on-chip storage, prediction lookahead, predictor lookahead, prefetch, program active memory footprint, scalable on-chip table, storage management, superscalar processor, table lookup, },
 abstract = {Recent research advocates address-correlating predictors to identify cache block addresses for prefetch. Unfortunately, address-correlating predictors require correlation data storage proportional in size to a program's active memory footprint. As a result, current proposals for this class of predictor are either limited in coverage due to constrained on-chip storage requirements or limited in prediction lookahead due to long off-chip correlation data lookup. In this paper, we propose last-touch correlated data streaming (LT-cords), a practical address-correlating predictor. The key idea of LT-cords is to record correlation data off chip in the order they will be used and stream them into a practically-sized on-chip table shortly before they are needed, thereby obviating the need for scalable on-chip tables and enabling low-latency lookup. We use cycle-accurate simulation of an 8-way out-of-order superscalar processor to show that: (1) LT-cords with 214KB of on-chip storage can achieve the same coverage as a last-touch predictor with unlimited storage, without sacrificing predictor lookahead, and (2) LT-cords improves performance by 60\% on average and 385\% at best in the benchmarks studied },
}

@inproceedings{4211026,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Jiang Lin and Hongzhong Zheng and Zhichun Zhu and Zhao Zhang and David, H.},
 year = {2007},
 pages = {94--104},
 publisher = {IEEE},
 title = {DRAM-Level Prefetching for Fully-Buffered DIMM: Design, Performance and Power Saving},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363740},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211026},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211026.pdf?arnumber=4211026},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Bandwidth, DRAM chip, DRAM chips, DRAM power consumption, DRAM-level prefetching, Energy consumption, Joining processes, L2 cache block, Merging, Multicore processing, Performance gain, Prefetching, Process design, Random access memory, SPEC2000 program, Software performance, channel bandwidth utilization, dual in-line memory module, dynamic random access memory, fully-buffered DIMM, idle memory latency, interconnect structure, memory block, memory controller, multicore processor, power saving, redundant bandwidth, software cache prefetching, storage management, storage management chips, },
 abstract = {We have studied DRAM-level prefetching for the fully buffered DIMM (FB-DIMM) designed for multi-core processors. FB-DIMM has a unique two-level interconnect structure, with FB-DIMM channels at the first-level connecting the memory controller and advanced memory buffers (AMBs); and DDR2 buses at the second-level connecting the AMBs with DRAM chips. We propose an AMB prefetching method that prefetches memory blocks from DRAM chips to AMBs. It utilizes the redundant bandwidth between the DRAM chips and AMBs but does not consume the crucial channel bandwidth. The proposed method fetches K memory blocks of L2 cache block sizes around the demanded block, where K is a small value ranging from two to eight. The method may also reduce the DRAM power consumption by merging some DRAM precharges and activations. Our cycle-accurate simulation shows that the average performance improvement is 16\% for single-core and multi-core workloads constructed from memory-intensive SPEC2000 programs with software cache prefetching enabled; and no workload has negative speedup. We have found that the performance gain comes from the reduction of idle memory latency and the improvement of channel bandwidth utilization. We have also found that there is only a small overlap between the performance gains from the AMB prefetching and the software cache prefetching. The average of estimated power saving is 15\% },
}

@inproceedings{4211029,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Xudong Shi and Feiqi Su and Jih-Kwon Peir and Ye Xia and Zhen Yang},
 year = {2007},
 pages = {126--135},
 publisher = {IEEE},
 title = {Modeling and Single-Pass Simulation of CMP Cache Capacity and Accessibility},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363743},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211029},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211029.pdf?arnumber=4211029},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Analytical models, Cache storage, Computational modeling, Computer simulation, Delay, Information science, Performance loss, Real time systems, Wiring, abstract model, average memory access time, cache storage, chip-multiprocessor, data accessibility, data replication, global stack, multi-threading, multiple cache organization, multiprocessing systems, on-chip cache capacity, on-chip storage space, per-core private stack, reuse distances, shared stack, single simulation pass, single-pass simulation, single-pass stack simulation, },
 abstract = {The future chip-multiprocessors (CMPs) with a large number of cores faces difficult issues in efficient utilizing on-chip storage space. Tradeoffs between data accessibility and effective on-chip capacity have been studied extensively. It requires costly simulations to understand a wide-spectrum of design spaces. In this paper, we first develop an abstract model for understanding the performance impact with respect to the degree of data replication. To overcome the lack of real-time interactions among multiple cores in the abstract model, we propose an efficient single-pass stack simulation method to study the performance of a variety of cache organizations on CMPs. The proposed global stack logically incorporates a shared stack and per-core private stacks to collect shared/private reuse (stack) distances for every memory reference in a single simulation pass. With the collected reuse distances, performance in terms of hits/misses and average memory access times can be calculated for multiple cache organizations. The basic stack simulation results can further derive other CMP cache organizations with various degrees of data replication. We verify both the modeling and the stack results against individual execution-driven simulations that consider realistic cache parameters and delays using a set of commercial multithreaded workloads. We also compare the simulation time saving with the stack simulation. The results show that stack simulation can accurately model the performance of various studied cache organizations with 2-9\% error margins using only about 8\% of the simulation time. The results also show that the effectiveness of various techniques for optimizing the CMP on-chip storage is closely related to the working sets of the workloads as well as the total cache sizes },
}

@inproceedings{4211028,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Ould-Ahmed-Vall, E. and Woodlee, J. and Yount, C. and Doshi, K.A. and Abraham, S.},
 year = {2007},
 pages = {116--125},
 publisher = {IEEE},
 title = {Using Model Trees for Computer Architecture Performance Analysis of Software Applications},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363742},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211028},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211028.pdf?arnumber=4211028},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Application software, Computer architecture, Counting circuits, Frequency estimation, M5' algorithm, Optimization, Performance analysis, Performance gain, Predictive models, Regression tree analysis, SPEC CPU2006 suite, Software performance, computer architecture, computer architecture performance analysis, performance evaluation, performance model tree, prefetching, regression analysis, software application, statistical regression modeling, superscalar machine, tree data structures, tuning software, },
 abstract = {The identification of performance issues on specific computer architectures has a variety of important benefits such as tuning software to improve performance, comparing the performance of various platforms and assisting in the design of new platforms. In order to enable this analysis, most modern micro-processors provide access to hardware-based event counters. Unfortunately, features such as out-of-order execution, pre-fetching and speculation complicate the interpretation of the raw data. Thus, the traditional approach of assigning a uniform estimated penalty to each event does not accurately identify and quantify performance limiters. This paper presents a novel method employing a statistical regression-modeling approach to better achieve this goal. Specifically, a model-tree based approach based on the M5' algorithm is implemented and validated that accounts for event interactions and workload characteristics. Data from a subset of the SPEC CPU2006 suite is used by the algorithm to automatically build a performance-model tree, identifying the unique performance classes (phases) found in the suite and associating with each class a unique, explanatory linear model of performance events. These models can be used to identify performance problems for a given workload and estimate the potential gain from addressing each problem. This information can help orient the performance optimization efforts to focus available time and resources on techniques most likely to impact performance problems with highest potential gain. The model tree exhibits high correlation (more than 0.98) and low relative absolute error (less than 8 \%) between predicted and measured performance, attesting it as a sound approach for performance analysis of modern superscalar machines },
}

@inproceedings{842284,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Hong Liu and Hongdu Fang},
 year = {2000},
 pages = {70--75},
 publisher = {IEEE},
 title = {Real-time image on QoS Web},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842284},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842284},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842284.pdf?arnumber=842284},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Digital images, Electronic commerce, IP networks, Image processing, International collaboration, Internet, Manufacturing processes, QoS Web, Quality of service, Real time systems, Telecommunication traffic, Web and internet services, Web service model, digital images, end-system traffic management, global collaboration, image processing, image processing, image quality, image transmission, information resources, inverse mapping mechanism, quality of service, quality of service, re-negotiation, real-time image transfer, real-time images, real-time systems, timing constraints, },
 abstract = {Digital images have become a dominant information source on the Web. Emerging Web-enabled applications, such as global collaboration in environmental studies, point and click manufacturing, and electronic commerce, to name a few, push for timely processing and transmission of images. This real-time imaging is much more than variations on image processing without regard to time. Its performance requirement on networking is beyond the capability of the current Internet, which provides a best-effort service model compromised with end-system traffic management. For the Web to support real-time images, we need to understand real-time image features, design a new Web service model, and convert a user's application requirement into a system service agreement. This paper presents a Web architecture that provides predictable and different service levels for specific quality of service (QoS) requirements, called QoS Web. We examine the Web image features in depth, which leads to a generic formula describing a user's preferences for image quality and timing constraints. It then maps onto the QoS requirements as resource parameters expected from the Web. The influence of the QoS settings on the perceived image performance is analyzed in theory and tested with experimental simulation. We present a procedure for users to specify their requirements to the QoS Web for real-time image transfer. In addition, an inverse mapping mechanism is included for re-negotiation when there is a shortage of network resources or the user's requirements change },
}

@inproceedings{842285,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Bhargava, R. and John, L.K.},
 year = {2000},
 pages = {76--87},
 publisher = {IEEE},
 title = {Issues in the design of store buffers in dynamically scheduled processors},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842285},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842285},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842285.pdf?arnumber=842285},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Bandwidth, Buffer storage, C benchmarks, C++ benchmarks, Computer architecture, Delay, Dynamic scheduling, Java, Java benchmarks, Laboratories, Microprocessors, Pipelines, Processor scheduling, buffer storage, contention priority, data forwarding, dynamically scheduled processors, latency hiding, load-store ordering, memory access latency, memory bandwidth, processor performance, processor scheduling, store access ordering, store buffer design, store buffer pipeline placement, store entry removal, },
 abstract = {Processor performance can be sensitive to load-store ordering, memory bandwidth, and memory access latency. A store buffer is a mechanism that exists in many current processors to accomplish one or more of the following: store access ordering, latency hiding, and data forwarding. Different policies that govern store buffer behavior can affect overall processor performance. However, the performance impact of various store buffer policies is not clearly analyzed in available literature. In this paper, we look into various store buffer issues such as i) where to place it in the pipeline, ii) when to remove a store entry from the store buffer, iii) when to allow the stores to be retired, and iv) if, when, and how to set the contention priority of memory operations. These issues are explained in detail while design and performance tradeoffs are assessed. Using a variety of C, C++, and Java benchmarks, we establish how these design policies influence performance. We find that the policies for store entry removal and store buffer pipeline placement have a large effect on the overall performance of a microprocessor. In addition, we see that smaller, well-designed store buffers can achieve comparable performance to larger, basic store buffers. Combining these results with an analysis of the benchmarks can help one fully understand the role of the store buffer and the tradeoffs involved },
}

@inproceedings{842282,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Srisa-an, W. and Chang, J.M. and Chia-Tien Dan Lo},
 year = {2000},
 pages = {58--63},
 publisher = {IEEE},
 title = {Do generational schemes improve the garbage collection efficiency? },
 date = {2000},
 doi = {10.1109/ISPASS.2000.842282},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842282},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842282.pdf?arnumber=842282},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Computer science, Human computer interaction, Java, Programming profession, generational garbage collection efficiency, heap size, mathematical model, pause time, residency, storage management, write-barrier overhead, },
 abstract = {Recently, most research efforts on garbage collection have concentrated on reducing pause times. However, very little effort has been spent on the study of garbage collection efficiency, especially generational garbage collection which was introduced as a way to reduce garbage collection pause times. In this paper a detailed study of garbage collection efficiency in generational schemes is presented. The study provides a mathematical model for the efficiency of generation garbage collection. Additionally, important issues such as write-barrier overhead, pause times, residency, and heap size are also addressed. We find that generational garbage collection often has lower garbage collection efficiency than other approaches (e.g. mark-sweep, copying) due to a smaller collected area and write-barrier overhead },
}

@inproceedings{4211041,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {255--255},
 publisher = {IEEE},
 title = {Author Index},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363755},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211041},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211041.pdf?arnumber=4211041},
 isbn = {1-4244-1082-7},
 language = {English},
 abstract = {},
}

@inproceedings{842280,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Weihrauch, M.},
 year = {2000},
 pages = {46--51},
 publisher = {IEEE},
 title = {DB2 for OS/390 V5 vs. V6 outer join performance},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842280},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842280},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842280.pdf?arnumber=842280},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {DB2 UDB for OS/390 V5, DB2 UDB for OS/390 V6, Databases, Magnets, Merging, Null value, Usability, business data processing, business intelligence, data warehouse, data warehouses, optimization techniques, outer join performance, query processing, relational database management system, relational databases, },
 abstract = {The outer join operation is one of the most frequently used operations in a relational database management system. It becomes even more important in data warehouse and business intelligence applications. The processing of outer join of very large relations is a very costly operation. Therefore, a lot of effort has been expended in the development and implementation of optimization techniques to improve the performance of outer join. In this paper, the outer join optimization techniques implemented in DB2 UDB for OS/390 V6 (further reference as DB2 V6) are described and the efficiency is measured in a real world workload },
}

@inproceedings{842281,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Yeddes, M. and Alla, H.},
 year = {2000},
 pages = {52--57},
 publisher = {IEEE},
 title = {Checking order-insensitivity using ternary simulation in synchronous programs},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842281},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842281},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842281.pdf?arnumber=842281},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Analytical models, Automata, Boolean values, Chaos, Chaotic communication, Delay, Distributed computing, Educational institutions, Eichelberger ternary algorithm, Hardware, Switching circuits, Tires, asynchronous distribution schemes, automatic verification, chaotic order, combinational switching circuits, distributed programming, order-insensitive property violation, order-insensitivity checking, sequential switching circuits, state variable computations, synchronous programs, ternary simulation, transition function, virtual machines, weak synchronization, },
 abstract = {In synchronous systems, new asynchronous distribution schemes are introduced. Properties can be established in order to distribute a program with weak synchronization. This paper deals with automatic verification of the order-insensitive property. Order-insensitivity is an important property introduced in synchronous systems by analogy with delay-insensitivity in asynchronous hardware. An algorithm derived from the Eichelberger ternary algorithm in combinational and sequential switching circuits is given. The new ternary algorithm allows exact detection of order-insensitive property violation. Binary analyses which are conceptually simple and natural, can solve the verification of the order-insensitive property. However, this technique is exponential in the number of state variable computations. By analogy with asynchronous systems, ternary techniques are polynomial in the number of state variable computations. Our goal is to verify if a transition function describing a synchronous program is order-insensitive. Thus, the introduction of an uncertain value in addition to Boolean values allows concretization of the insensitivity introduced by the chaotic order of state variables processing in a distributed way (sequential processing) },
}

@inproceedings{1291363,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Bonilla-Lucas, R. and Plachta, P. and Sachedina, A. and Jimenez-Gonzalez, D. and Zuzarte, C. and Larriba-Pey, J.-L.},
 year = {2004},
 pages = { 115-- 122},
 publisher = {IEEE},
 title = {Characterization of the data access behavior for TPC-C traces},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291363},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291363},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291363.pdf?arnumber=1291363},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { DB2 UDB version 8.1 GA,  DB2 UDB version 8.1 fix pack 4,  TPC-C traces,  TPC-C workload reference stream,  buffer pool,  data access behavior characterization,  data handling,  data pages,  index pages,  program diagnostics,  relational databases,  static analysis,  transaction processing, Computer aided instruction, Computer science education, Content addressable storage, Contracts, Data analysis, Data engineering, Transaction databases, },
 abstract = {In this paper, we look into the characteristics of the reference stream of TPC-C workloads from the buffer pool point of view. We analyze a trace coming from DB2 UDB version 8.1 fix pack 4 and compare it to a trace from DB2 UDB version 8.1 GA. We perform three types of analysis. A static analysis of the number of reads and writes for index and data pages. We conclude that index pages receive less references than data pages by are more frequently accessed individually. Then, we analyze how DB2 processes access those pages. Index pages have more references than data pages when accessed by more than one process. Finally, we understand the accesses along the life of a page. We conclude that there is a significant burstiness in the reference stream, where, each burst is caused by one process. },
}

@inproceedings{5452057,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Nellans, D. and Sudan, K. and Balasubramonian, R. and Brunvand, E.},
 year = {2010},
 pages = {111--112},
 publisher = {IEEE},
 title = {Hardware prediction of OS run-length for fine-grained resource customization},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452057},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452057},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452057.pdf?arnumber=5452057},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Computer architecture, Costs, Energy efficiency, Hardware, Instruments, OS run-length predictor, Operating systems, Runtime, Throughput, Yarn, chip multiprocessors, computer architecture, computer architecture, fine-grained resource customization, multiprocessing systems, operating system, operating systems (computers), },
 abstract = {In the past ten years, computer architecture has seen a paradigm shift from emphasizing single thread performance to energy efficient, throughput oriented, chip multiprocessors. Several studies have suggested that it may be worthwhile to off-load execution of the operating system (OS) to one or more of these cores, or reconfigure hardware during OS execution. To be effective, these techniques must balance the cost of off-loading or re-configuration, versus the potential benefits, which are typically unknown at decision time. These decision points are typically implemented by manually instrumenting a few OS routines (out of hundreds). Such a preliminary research effort cannot be sustained across several operating systems and hardware configurations. We argue that decisions made in software are often sub-optimal because they are expensive in terms of run-time overhead and because applications vary in their use of OS features. We propose that these decision mechanisms should be supported through a hardware based OS run-length predictor, that removes the onus from OS developers. Our final design results in a 95\% prediction accuracy for OS intensive applications, while requiring only 2 KB of storage. },
}

@inproceedings{1291361,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Chihaia, I. and Gross, T.},
 year = {2004},
 pages = { 98-- 105},
 publisher = {IEEE},
 title = {Effectiveness of simple memory models for performance prediction},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291361},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291361},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291361.pdf?arnumber=1291361},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { CHARMM,  Chemistry at HARvard Molecular Mechanics,  application execution time estimation,  application performance prediction,  benchmark testing,  continuous accesses,  continuous memory accesses,  irregular application,  memory access types,  memory architecture,  memory system performance,  micro-benchmarking,  performance estimates,  random accesses,  regular application,  simple memory models,  software performance evaluation,  stride memory accesses, Analytical models, Application software, Chemistry, Computational efficiency, Computational modeling, Kernel, Modems, Predictive models, Runtime, Systems engineering and theory, },
 abstract = {Many situations call for an estimation of the execution time of applications, e.g., during design or evaluation of computer systems. In this paper we focus on large applications where the execution times heavily depend on the performance of the memory system. Since such applications are computationally expensive, direct simulation is not an option and an analytical model is called for. This paper addresses this problem by developing and evaluating two simple analytical models. These models focus on an application's interaction with the memory system. Applications are characterized by their memory access types. A regular application has continuous and stride memory accesses. An irregular application has three memory access types: continuous accesses, accesses within the same L1/L2 cache line, and random accesses. The analytical models are combined with results from micro-benchmarking or with appropriate performance estimates of memory accesses to predict application performance, either on real or future machines. We apply these models to executions of CHARMM (Chemistry at HARvard Molecular Mechanics) - a scientific application written in FORTRAN, SMV (Symbolic Model Verifier) - coded in C++. For all three applications, the approaches described here produce results with 5\% accuracy on average (compared to the effective run-time measured on a real SPARC system). },
}

@inproceedings{4211040,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Kalamkar, D.D. and Chaudhuri, M. and Heinrich, M.},
 year = {2007},
 pages = {242--253},
 publisher = {IEEE},
 title = {Simplifying Active Memory Clusters by Leveraging Directory Protocol Threads},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363754},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211040},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211040.pdf?arnumber=4211040},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Active matrix addressing, Assembly systems, Communication system control, Control systems, Hardware, Kernel, Logic, Protocols, Software performance, Yarn, active memory address remapping, active memory architecture, active memory cluster, coherence protocol extension, directory protocol thread, distributed shared memory, distributed shared memory systems, dual-core node, matrix transpose, memory controller, memory protocols, multi-threaded node, multi-threading, multiprocessor architecture, parallel reduction, software protocol, storage management, },
 abstract = {Address re-mapping techniques in so-called active memory systems have been shown to dramatically increase the performance of applications with poor cache and/or communication behavior on shared memory multiprocessors. However, these systems require custom hardware in the memory controller for cache line assembly/disassembly, address translation between re-mapped and normal addresses, and coherence logic. In this paper we make the important observation that on a traditional flexible distributed shared memory (DSM) multiprocessor node, equipped with a coherence protocol thread context as in SMTp or a simple dedicated in-order protocol processing core as in a CMP, the address re-mapping techniques can be implemented in software running on the protocol thread or core without custom hardware in the memory controller while delivering high performance. We implement the active memory address re-mapping techniques of parallel reduction and matrix transpose (two popular kernels in scientific, multimedia, and data mining applications) on these systems, outline the novel coherence protocol extensions needed to make them run efficiently in software protocols, and evaluate these protocols on four different DSM multiprocessor architectures with multi-threaded and/or dual-core nodes. The proposed protocol extensions yield speedup of 1.45 for parallel reduction and 1.29 for matrix transpose on a 16-node DSM multiprocessor when compared to non-active memory baseline systems and achieve performance comparable to the existing active memory architectures that rely on custom hardware in the memory controller },
}

@inproceedings{5452052,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Dube, P. and Tsao, M. and Poff, D. and Li Zhang and Bivens, A.},
 year = {2010},
 pages = {113--114},
 publisher = {IEEE},
 title = {Program behavior characterization in large memory systems},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452052},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452052},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452052.pdf?arnumber=5452052},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Bandwidth, Costs, Delay, Field programmable gate arrays, Memory architecture, Phase change materials, Phase change memory, Prototypes, Random access memory, Solid state circuits, field programmable gate array, field programmable gate arrays, flash technology, large memory systems, memory subsystem, multiprocessing systems, multiprocessor system, parallel memories, phase change memory technology, program behavior characterization, solid state memory, },
 abstract = {As processor performance continues to outgrow memory capacity and bandwidth, system and application performance has become constrained by the memory subsystem. Promising new technologies like Phase Change Memory (PCM) and Flash have emerged which may add capacity at a cost cheaper than conventional DRAM, but at the cost of added latency and poor endurance. It is likely that systems leveraging these new memory technologies in the memory subsystem would require an innovative memory system architecture to gain the benefit of added capacity while mitigating the costs of latency and potential device wear-out. One such proposed architecture is a hierarchical memory sub-system with a faster but costly memory (e.g., DRAM) acting as a cache for a slower but cheaper memory e.g., solid state memory like NAND flash, NOR flash or PCM. The memory subsystem is now a hybrid of two different memory technologies, exploiting the cost effectiveness and non-volatility of solid state memory devices with the speed of traditional DRAM. In order to study the performance tradeoffs with such hierarchical architectures one needs to first study the effect of having a last level cache, which is much larger than the caches in existing systems. Existing tools and methodologies for cache evaluation fall short. We develop a multi-processor system prototype that runs applications with a coherently-attached FPGA which can emulate different memory architectures for long periods of time. The output of the system is not a memory trace, but the performance results of the emulated memory system design which may be used at any time to evaluate the design tradeoffs. The large cache will filter out references going to the solid state memory. Thus the miss ratio of the large cache is an important metric. The sensitivity of the miss ratio to configuration parameters like cache size and line size needs to be evaluated to identify the right set of parameters. },
}

@inproceedings{5452053,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Subotic, V. and Labarta, J. and Valero, M.},
 year = {2010},
 pages = {115--116},
 publisher = {IEEE},
 title = {Simulation environment for studying overlap of communication and computation},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452053},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452053},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452053.pdf?arnumber=5452053},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Computational modeling, Computer applications, Computer networks, Concurrent computing, Costs, Data visualization, Degradation, High performance computing, MPI, Parallel machines, Virtual machining, application program interfaces, digital simulation, message passing, processors, simulation environment, },
 abstract = {Overlapping communication and computation allows both processors and network to be utilized concurrently and leads to two clear benefits: overall speedup and a reduction in network performance requirements. Still, it remains unclear how much overlap can be actually achieved in practice - in real-world applications. This work designs a precise simulation environment that measures how much a scientific MPI application can profit from overlapping communication and computation. The simulation takes into account a wide range of application properties and allows to study overlap on the configurable platform. Additionally, the environment can visualize the simulated time-behaviors, so the non-overlapped and overlapped executions can be compared both quantitatively and qualitatively, providing new insights into the mechanism and potential of overlap. We found that the overlapping potential is very limited by pattern by which an application computes on the communicated data. Finally, we identified as the the biggest benefit of overlap the fact that it can highly relax network constraints without consequently degrading performance. },
}

@inproceedings{1291365,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Wei huang and Srisa-an, W. and Chang, J.M.},
 year = {2004},
 pages = { 133-- 140},
 publisher = {IEEE},
 title = {Dynamic pretenuring schemes for generational garbage collection},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291365},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291365},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291365.pdf?arnumber=1291365},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { dynamic pretenuring scheme,  feedback mechanism,  generational garbage collection,  object lifespan prediction,  object pretenuring,  object-oriented programming,  pretenuring selection,  storage management, Feedback, Information analysis, Java, Performance analysis, Runtime, Virtual machining, Yarn, },
 abstract = {Previous research efforts have shown that pretenuring can potentially reduce the copying cost by creating long lived objects into the mature memory regions directly. To date, researchers often employ profiling and static analysis to accurately select the objects that should be pretenured. However, little research efforts have been spent on dynamic approaches for pretenuring objects. In this paper, we propose a novel approach that dynamically predicts object lifespan to assist with pretenuring selection. The proposed scheme performs dynamic pretenuring selection based on a feedback mechanism that records lifespan of objects from each class during garbage collection invocations. This information is then used to pretenure objects in subsequent allocation requests. We experiment with two approaches, jumpstart feedback and continuous feedback, to collect tenuring information. The experimental results of selected benchmark programs show that our schemes can improve the garbage collection time of IBM's Jikes RVM by up to 37\%, and improve the overall execution time by up to 28\%. },
}

@inproceedings{5452048,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Yan Cui and Yu Chen and Yuanchun Shi and Qingbo Wu},
 year = {2010},
 pages = {117--118},
 publisher = {IEEE},
 title = {Scalability comparison of commodity operating systems on multi-cores},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452048},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452048},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452048.pdf?arnumber=5452048},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {AMD 32-core platform, Data structures, FreeBSD, Kernel, Libraries, Linux, Linux, Operating systems, Performance analysis, Performance evaluation, Protection, Scalability, Solaris, Testing, commodity operating systems, microbenchmarks measurement, microprocessor chips, multicore platform, multiprocessing systems, operating systems (computers), scalability comparison, },
 abstract = {In this paper, we evaluate and compare the parallel scalability of three commodity operating systems (Linux, Solaris and FreeBSD) on an AMD 32-core platform. Measurements of microbenchmarks and a real-life application reveal that no operating system scales totally better than another for microbenchmarks; for the real-life application, Linux and Solaris are competitive in scalability and perform better than FreeBSD. Related kernel source analysis and performance data suggest that synchronization primitives protecting the shared data structure in kernels are the root cause of the poor scalability on multi-cores. },
}

@inproceedings{1291369,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Calder, B. and Citron, D. and Patt, Y. and Smith, J.},
 year = {2004},
 pages = { 169-- 169},
 publisher = {IEEE},
 title = {The future of simulation: A field of dreams},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291369},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291369},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291369.pdf?arnumber=1291369},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = {Computational modeling, Computer architecture, Computer simulation, Costs, Sun, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01291369.png" border="0"> },
}

@inproceedings{1291368,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Kadayif, I. and Nath, P. and Kandemir, M. and Sivasubramaniam, A.},
 year = {2004},
 pages = { 161-- 168},
 publisher = {IEEE},
 title = {Compiler-directed physical address generation for reducing dTLB power},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291368},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291368},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291368.pdf?arnumber=1291368},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { Spec95 array-based code,  Spec95 pointer-based code,  Translation Lookaside Buffer,  address translation,  code transformation,  compiler-directed physical address generation,  dTLB power reduction,  data TLB lookups,  file organisation,  optimisation,  power consumption,  power conversion,  program compilers,  table lookup, Batteries, Chip scale packaging, Circuits, Cooling, Delay, Energy consumption, Frequency, Hardware, Power generation, Voltage, },
 abstract = {Address translation using the Translation Lookaside Buffer (TLB) consumes as much as 16\% of the chip power on some processors because of its high associativity and access frequency. While prior work has looked into optimizing this structure at the circuit and architectural levels, this paper takes a different approach of optimizing its power by reducing the number of data TLB (dTLB) lookups for data references. The main idea is to keep translations in a set of translation registers, and intelligently use them in software to directly generate the physical addresses without going through the dTLB. The software has to work within the confines of the translation registers provided by the hardware, and has to maximize the reuse of such translations to be effective. We propose strategies and code transformations for achieving this in array-based and pointer-based codes, looking to optimize data accesses. Results with a suite of Spec95 array-based and pointer-based codes show dTLB energy savings of up to 73\% and 88\%, respectively, compared to directly using the dTLB for all references. Despite the small increase in instructions executed with our mechanisms, the approach can in fact provide performance benefits in certain cases. },
}

@inproceedings{5452035,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Grant, R.E. and Balaji, P. and Afsahi, A.},
 year = {2010},
 pages = {144--153},
 publisher = {IEEE},
 title = {A study of hardware assisted IP over InfiniBand and its impact on enterprise data center performance},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452035},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452035},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452035.pdf?arnumber=5452035},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Computer science, Convergence, Convergence, Costs, Data Center, Ethernet networking solution, Ethernet networks, Hardware, High-speed networks, IP networks, IPoIB, InfiniBand, InfiniBand adapters, Mathematics, Offloading, Protocols, SDP, Sockets, TCP layer modifications, TCP/IP stack over infiniband, TCPIP, computer centres, enterprise data center, hardware assisted ip over infiniband, kernel-based TCP/IP, local area networks, socket networks, sockets direct protocol, transport protocols, },
 abstract = {High-performance sockets implementations such as the Sockets Direct Protocol (SDP) have traditionally showed major performance advantages compared to the TCP/IP stack over InfiniBand (IPoIB). These stacks bypass the kernel-based TCP/IP and take advantage of network hardware features, providing enhanced performance. SDP has excellent performance but limited utility as only applications relying on the TCP/IP sockets API can use it and other IP stack uses (IPSec, UDP, SCTP) or TCP layer modifications (iSCSI) cannot benefit from it. Recently, newer generations of InfiniBand adapters, such as ConnectX from Mellanox, have provided hardware support for the IP stack itself, such as Large Send Offload and Large Receive Offload. As such high performance socket networks are likely to be deployed or converged with existing Ethernet networking solutions, the performance of such technologies is important to assess. In this paper we take a first look at the performance advantages provided by these offload techniques and compare them to SDP. Our micro-benchmarks and enterprise data-center experiments show that hardware assisted IPoIB can provide competitive performance with SDP and even outperform it in some cases. },
}

@inproceedings{4919628,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {vii--vii},
 publisher = {IEEE},
 title = {ISPASS 2009 reviewers},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919628},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919628},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919628.pdf?arnumber=4919628},
 isbn = {978-1-4244-4184-6},
 language = {English},
 abstract = {},
}

@inproceedings{4919629,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Emer, Joel},
 year = {2009},
 pages = {viii--viii},
 publisher = {IEEE},
 title = {Accelerating architecture research},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919629},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919629},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919629.pdf?arnumber=4919629},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Acceleration, Costs, Fabrication, Field programmable gate arrays, Hardware, Microarchitecture, Moore's Law, Performance analysis, Timing, Writing, },
 abstract = {With the recent demonstration of 32nm processors we have seen Moore's law providing another large increase in the number of transistors. While more transistors provides architects with a great opportunity, I believe we have been observing increasing challenges in finding the most effective uses for these transistors. Design team size, mask costs and fabrication costs are all increasing, thus there is increasing desire to make the right decisions about which research ideas to bring forward to design. Unfortunately, our existing evaluation methodologies are proving increasingly ineffective at providing compelling evidence that a new idea warrants inclusion in future designs. In this talk, I will elaborate on these challenges and discuss some approaches to improve on our ability to prove the merit of architectural ideas. In particular, there is a recent movement toward using field-programmable gate arrays (FPGAs) as the basis for the evaluating future systems. Therefore, I will outline the alternative approaches to using FPGAs with an emphasis on using FPGAs to do performance modeling. But designing hardware models is far more complicated than writing software models, so included in the discussion will be techniques to reduce that complexity. These will include a practical approach to modularizing the model, separation of the functional and timing aspects of the simulation, and additional infrastructure important for performance modeling. },
}

@inproceedings{4510748,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Hoste, K. and Eeckhout, L.},
 year = {2008},
 pages = {157--168},
 publisher = {IEEE},
 title = {Characterizing the Unique and Diverse Behaviors in Existing and Emerging General-Purpose and Domain-Specific Benchmark Suites},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510748},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510748},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510748.pdf?arnumber=4510748},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Aggregates, Application software, BioMetricsWorkload, BioPerf, Biometrics, Computational modeling, Computer simulation, Costs, MediaBench II, Microarchitecture, Microprocessors, Performance analysis, Visualization, benchmark testing, bioinformatics, biometrics, domain-specific benchmark suites, general-purpose workloads, microarchitecture-independent behavior, microprocessor chips, multimedia, next generation microprocessors, phase-level characterization, workload behavior, },
 abstract = {Characterizing and understanding emerging workload behavior is of vital importance to ensure next generation microprocessors perform well on their anticipated future workloads. This paper compares a number of benchmark suites from emerging application domains, such as bio-informatics (BioPerf), biometrics (BioMetricsWorkload) and multimedia (MediaBench II), against general-purpose workloads represented by SPEC CPU2000 and CPU2006. Although these benchmark suites have been characterized before, prior work did not capture the benchmark suites' inherent (microarchitecture-independent) behavior, nor did they provide a phase-level characterization. },
}

@inproceedings{4510749,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Christopoulos, V.N. and Lilja, D.J. and Schrater, P.R. and Georgopoulos, A.},
 year = {2008},
 pages = {169--178},
 publisher = {IEEE},
 title = {Independent Component Analysis and Evolutionary Algorithms for Building Representative Benchmark Subsets},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510749},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510749},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510749.pdf?arnumber=4510749},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Character generation, Computational complexity, Computational modeling, Evolutionary computation, Independent component analysis, Maximum likelihood estimation, Microarchitecture, Principal component analysis, Statistical analysis, System performance, computational complexity, computational complexity, evolutionary algorithms, evolutionary computation, independent component analysis, independent component analysis, representative benchmark subsets, set theory, statistical analysis, },
 abstract = {This work addresses the problem of building representative subsets of benchmarks from an original large set of benchmarks, using statistical analysis techniques. The subsets should be developed in this way to include only the necessary information for evaluating the performance of a computer system or application. The development of representative workloads is not a trivial procedure, since incorrectly selecting benchmarks the representative subset can produce erroneous results. A number of statistical analysis techniques have been developed for identifying representative workloads. The goal of these approaches is to reduce the dimensionality of the original set of benchmarks prior to identifying similar benchmarks. In this work we propose a combination of independent component analysis (ICA) and evolutionary algorithm (EA) as a more efficient way for reducing the computational complexity of the problem and the redundant information of the original set of benchmarks. Experimental results validate that the proposed technique generates more representative workloads than prior techniques. },
}

@inproceedings{4510746,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Salapura, V. and Ganesan, K. and Gara, A. and Gschwind, M. and Sexton, J.C. and Walkup, R.E.},
 year = {2008},
 pages = {139--146},
 publisher = {IEEE},
 title = {Next-Generation Performance Counters: Towards Monitoring Over Thousand Concurrent Events},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510746},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510746},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510746.pdf?arnumber=4510746},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Application software, Blue Gene-PTM supercomputer, Computer architecture, Computerized monitoring, Counting circuits, Hardware, Microprocessors, Multiprocessing systems, Performance analysis, Random access memory, SRAM array, Supercomputers, concurrency control, concurrent event monitoring, event notification, interrupt arming, interrupt triggering protocol, interrupts, microprocessors, per-event thresholding, performance counters, performance monitor architecture, performance tuning, system monitoring, },
 abstract = {We present a novel performance monitor architecture, implemented in the Blue Gene/P<sup>TM</sup> supercomputer. This performance monitor supports the tracking of a large number of concurrent events by using a hybrid counter architecture. The counters have their low order data implemented in registers which are concurrently updated, while the high order counter data is maintained in a dense SRAM array that is updated from the registers on a regular basis. The per formance monitoring architecture includes support for per- event thresholding and fast event notification, using a two- phase interrupt-arming and triggering protocol. A first implementation provides 256 concurrent 64b counters which offers an up to 64x increase in counter number compared to performance monitors typically found in microprocessors today, and thereby dramatically expands the capabilities of counter-based performance tuning. },
}

@inproceedings{4510747,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Najaf-abadi, H.H. and Rotenberg, E.},
 year = {2008},
 pages = {147--156},
 publisher = {IEEE},
 title = {Configurational Workload Characterization},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510747},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510747},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510747.pdf?arnumber=4510747},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Art, C.1.1 [Single Data Stream Architectures]: RISC/CISC, CACTI modeling tool, Clocks, Computer architecture, Costs, Displays, Microarchitecture, Process design, Reduced instruction set computing, Simplescalar timing simulator, Single-instruction-stream, Timing, VLIW, VLIW architectures, architectural configuration, configurational workload characterization, customization, design exploration, design exploration tool, heterogeneous CMP, heterogeneous system, microprocessor chips, single-thread performance, workload characterization, },
 abstract = {Although the best processor design for executing a specific workload does depend on the characteristics of the workload, it can not be determined without factoring-in the effect of the interdependencies between different architectural subcomponents. Consequently, workload characteristics alone do not provide accurate indication of which workloads can perform close-to-optimal on the same architectural configuration. The primary goal of this paper is to demonstrate that, in the design of a heterogeneous CMP, reducing the set of essential benchmarks based on relative similarity in raw workload behavior may direct the design process towards options that result in sub-optimality of the ultimate design. It is shown that the design parameters of the customized processor configurations, what we refer to as the configurational characteristics, can yield a more accurate indication of the best way to partition the workload space for the cores of a heterogeneous system to be customized to. In order to automate the extraction of the configurational- characteristics of workloads, a design exploration tool based on the Simplescalar timing simulator and the CACTI modeling tool is presented. Results from this tool are used to display how a systematic methodology can be employed to determine the optimal set of core configurations for a heterogeneous CMP under different design objectives. In addition, it is shown that reducing the set of workloads based on even a single widely documented benchmark similarity (between bzip and gzip) can lead to a slowdown in the overall performance of a heterogeneous-CMP design. },
}

@inproceedings{4510744,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Marin, G. and Mellor-Crummey, J.},
 year = {2008},
 pages = {115--126},
 publisher = {IEEE},
 title = {Pinpointing and Exploiting Opportunities for Enhancing Data Reuse},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510744},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510744},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510744.pdf?arnumber=4510744},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Computational modeling, Computer science, Instruments, Management training, Memory management, Neutrons, Pattern analysis, Plasma measurements, Plasma simulation, Plasma transport processes, data reuse, data-intensive scientific programs, memory hierarchy utilization, online analysis, software reusability, systems analysis, },
 abstract = {The potential for improving the performance of data-intensive scientific programs by enhancing data reuse in cache is substantial because CPUs are significantly faster than memory. Traditional performance tools typically collect or simulate cache miss counts or rates and attribute them at the function level. While such information identifies program scopes that exhibit a large cache miss rate, it is often insufficient to diagnose the causes for poor data locality and to identify what program transformations would improve memory hierarchy utilization. This paper describes an approach that uses memory reuse distance to identify an application's most significant memory access patterns causing cache misses and provide insight into ways of improving data reuse. Unlike previous approaches, our tool combines (1) analysis and instrumentation of fully optimized binaries, (2) online analysisof reuse patterns, (3) fine-grain attribution of measurements and models to statements, loops and variables, and (4) static analysis of access patterns to quantify spatial reuse. We demonstrate the effectiveness of our approach for understanding reuse patterns in two scientific codes: one for simulating neutron transport and a second for simulating turbulent transport in burning plasmas. Our tools pinpointed opportunities for enhancing data reuse. Using this feedback as a guide, we transformed the codes, reducing their misses at various levels of the memory hierarchy by integer factors and reducing their execution time by as much as 60\% and 33\%, respectively. },
}

@inproceedings{4510745,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Azizi, O. and Collins, J. and Patil, D. and Hong Wang and Horowitz, M.},
 year = {2008},
 pages = {127--138},
 publisher = {IEEE},
 title = {Processor Performance Modeling using Symbolic Simulation},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510745},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510745},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510745.pdf?arnumber=4510745},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Analytical models, Circuit simulation, Computational complexity, Computational modeling, Costs, Delay effects, Design optimization, Engines, Equations, Graphics Media Accelerator X3000, Performance analysis, circuit latencies, circuit simulation, computational complexity, computational complexity, internal functional units, microprocessor chips, multi-dimensional design space, processor performance modeling, symbol manipulation, symbolic simulation, },
 abstract = {We propose a method of analytically characterizing processor performance as a function of circuit latencies. In our approach, we modify traditional simulation to use variables instead of fixed latencies for the internal functional units. The simulation engine then algebraically computes execution times, and the result is a mathematical equation which characterizes the performance space across numerous processor configurations. We discuss the computational complexity issues of this approach and show that instruction chunking and simple equation redundancy checking can make this approach feasible-we can model a large multi-dimensional design space with thousands to millions of design parameter combinations for about 10times the simulation time of a single conventional simulation run. We demonstrate our approach by exploring two different machines: a traditional MlPS-style in-order pipeline and the Intel Graphics Media Accelerator X3000. },
}

@inproceedings{4510742,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {McCurdy, C. and Cox, A.L. and Vetter, J.},
 year = {2008},
 pages = {95--104},
 publisher = {IEEE},
 title = {Investigating the TLB Behavior of High-end Scientific Applications on Commodity Microprocessors},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510742},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510742},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510742.pdf?arnumber=4510742},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {AMD Opteron, Application software, Computer science, Costs, Degradation, HPC Challenge suite, Laboratories, Microprocessors, Production, SPEC CPU suite, TLB behavior, cache behavior, cache storage, commodity microprocessors, floating point, floating point arithmetic, instruction set, instruction sets, microprocessor chips, x86 architecture, },
 abstract = {The floating point portion of the SPEC CPU suite and the HPC Challenge suite are widely recognized and utilized as benchmarks that represent scientific application behavior. In this work we show that while these benchmark suites may be representative of the cache behavior of production scientific applications, they do not accurately represent the TLB behavior of these applications. Furthermore, we demonstrate that the difference can have a significant impact on performance. In the first part of the paper we present results from implementation-independent trace-based simulations which demonstrate that benchmarks exhibit significantly different TLB behavior for a range of page sizes than a representative set of production applications. In the second part we validate these results on the AMD Opteron implementation of the x86 architecture, showing that false conclusions about choice of page size, drawn from benchmark performance, can result in performance degradations of up to nearly 50\% for the production applications we investigated.. },
}

@inproceedings{4919627,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {v--vi},
 publisher = {IEEE},
 title = {ISPASS 2009 people},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919627},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919627},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919627.pdf?arnumber=4919627},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Finance, Instruments, },
 abstract = {},
}

@inproceedings{4919624,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {i--i},
 publisher = {IEEE},
 title = {IEEE International symposium on performance analysis of systems and software},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919624},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919624},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919624.pdf?arnumber=4919624},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {CMPSchedSim, Cell BE, Cetra, De Novo Short Read DNA sequence assembly, GARNET, GPU simulator, Internet, Java, Lonestar, SuiteSpecks, SuiteSpots, TRIPS prototype block predictor, WARP, Web 2.0, Zesto, assembly code, benchmark testing, benchmarking programs, branch predictor structures, cache-filtered address traces, coprocessors, cycle-level simulator, data centricity, electric potential, fast CPU scheduler development, flexible full-system functional model, frequency scaling, full-system simulator, learning (artificial intelligence), machine learning, memory footprint, microarchitecture exploration, multi-threaded Java application, multi-threading, multicore platform, multiprocessing systems, network packet signature matching, on-chip network model, on-chip network traffic, online compression, online performance prediction, optimistic software transactional memory, performance counter measurements, performance evaluation, power-aware design, process-driven dynamic voltage, reverse engineering, reverse engineering, runtime parallelization, scheduling, server performance, shared cache management, simulation, storage management, superscalar processor performance, task scheduling, temperature-aware design, trace and analysis framework, },
 abstract = {The following topics are dealt with: differentiating the roles of IR measurement and simulation for power and temperature-aware design; user- and process-driven dynamic voltage and frequency scaling; accuracy of performance counter measurements; GARNET: a detailed on-chip network model inside a full-system simulator; Cetra: a trace and analysis framework for the evaluation of Cell BE; Zesto: a cycle-level simulator for highly detailed microarchitecture exploration; Lonestar: a suite of parallel irregular program; exploring speculative parallelism in SPEC2006; machine learning based online performance prediction for runtime parallelization and task scheduling; WARP: enabling fast CPU scheduler development and evaluation; CMPSchedSim: evaluating OS/CMP interaction on shared cache management; understanding the cost of thread migration for multi-threaded Java applications running on a multicore platform; the data-centricity of Web 2.0 workloads and its impact on server performance; characterizing and optimizing the memory footprint of De Novo Short Read DNA sequence assembly; analytic model of optimistic software transactional memory; analyzing CUDA workloads using a detailed GPU simulator; evaluating GPUs for network packet signature matching; online compression of cache-filtered address traces; analysis of the TRIPS prototype block predictor; experiment flows and microbenchmarks for reverse engineering of branch predictor structures; analyzing the impact of on-chip network traffic on program phases for CMPs; SuiteSpecks and SuiteSpots: a methodology for the automatic conversion of benchmarking programs into intrinsically checkpointed assembly code; accurately approximating superscalar processor performance from traces; and QUICK: a flexible full-system functional model. },
}

@inproceedings{4919625,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {},
 year = {2009},
 pages = {ii--ii},
 publisher = {IEEE},
 title = {Copyright},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919625},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919625},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919625.pdf?arnumber=4919625},
 isbn = {978-1-4244-4184-6},
 language = {English},
 abstract = {},
}

@inproceedings{4919648,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Bakhoda, A. and Yuan, G.L. and Fung, W.W.L. and Wong, H. and Aamodt, T.M.},
 year = {2009},
 pages = {163--174},
 publisher = {IEEE},
 title = {Analyzing CUDA workloads using a detailed GPU simulator},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919648},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919648},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919648.pdf?arnumber=4919648},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Analytical models, CUDA programming, CUDA workload, Computational modeling, Concurrent computing, GPU hardware, GPU simulator, Graphics, Hardware, Microarchitecture, Parallel processing, Parallel programming, Process design, Yarn, cache storage, caches, computer graphic equipment, flexible programming model, graphic processing unit, high-end graphics card, instruction sets, interconnect topology, memory controller, memory request coalescing hardware, microarchitecture design, microarchitecture performance simulator, multi-threading, multiprocessing systems, parallel architectures, parallel thread execution, parallel workload distribution, virtual instruction set, },
 abstract = {Modern graphic processing units (GPUs) provide sufficiently flexible programming models that understanding their performance can provide insight in designing tomorrow's manycore processors, whether those are GPUs or otherwise. The combination of multiple, multithreaded, SIMD cores makes studying these GPUs useful in understanding tradeoffs among memory, data, and thread level parallelism. While modern GPUs offer orders of magnitude more raw computing power than contemporary CPUs, many important applications, even those with abundant data level parallelism, do not achieve peak performance. This paper characterizes several non-graphics applications written in NVIDIA's CUDA programming model by running them on a novel detailed microarchitecture performance simulator that runs NVIDIA's parallel thread execution (PTX) virtual instruction set. For this study, we selected twelve non-trivial CUDA applications demonstrating varying levels of performance improvement on GPU hardware (versus a CPU-only sequential version of the application). We study the performance of these applications on our GPU performance simulator with configurations comparable to contemporary high-end graphics cards. We characterize the performance impact of several microarchitecture design choices including choice of interconnect topology, use of caches, design of memory controller, parallel workload distribution mechanisms, and memory request coalescing hardware. Two observations we make are (1) that for the applications we study, performance is more sensitive to interconnect bisection bandwidth rather than latency, and (2) that, for some applications, running fewer threads concurrently than on-chip resources might otherwise allow can improve performance by reducing contention in the memory system. },
}

@inproceedings{4919649,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Smith, R. and Goyal, N. and Ormont, J. and Sankaralingam, K. and Estan, C.},
 year = {2009},
 pages = {175--184},
 publisher = {IEEE},
 title = {Evaluating GPUs for network packet signature matching},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919649},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919649},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919649.pdf?arnumber=4919649},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Application specific integrated circuits, Automata, Engines, Heart, Inspection, Intrusion detection, Load management, Nvidia G80 GPU, Payloads, Prototypes, SIMD processing, SIMD-based G80 GPU, Telecommunication traffic, application specific integrated circuits, computer networks, deterministic automata, digital signatures, extended finite automata, field programmable gate arrays, finite automata, hardware-centric ASIC-FPGA implementation, high-performance microprocessor, intrusion detection, load balancing, microarchitectural analysis, microprocessor chips, network device, network packet signature matching, network speed, packet inspection, packet payload, parallel architectures, performance requirement, programmable signature matching system, regular-expression based signature, security of data, standard deterministic finite automata, traffic shaping, },
 abstract = {Modern network devices employ deep packet inspection to enable sophisticated services such as intrusion detection, traffic shaping, and load balancing. At the heart of such services is a signature matching engine that must match packet payloads to multiple signatures at line rates. However, the recent transition to complex regular-expression based signatures coupled with ever-increasing network speeds has rapidly increased the performance requirements of signature matching. Solutions to meet these requirements range from hardware-centric ASIC/FPGA implementations to software implementations using high-performance microprocessors. In this paper, we propose a programmable signature matching system prototyped on an Nvidia G80 GPU. We first present a detailed architectural and microarchitectural analysis, showing that signature matching is well suited for SIMD processing because of regular control flow and parallelism available at the packet level. Next, we examine two approaches for matching signatures: standard deterministic finite automata (DFAs) and extended finite automata (XFAs), which use far less memory than DFAs but require specialized auxiliary memory and small amounts of computation in most states. We implement a fully functional prototype on the SIMD-based G80 GPU. This system out-performs a Pentium4 by up to 9X and a Niagara-based 32-threaded system by up to 2.3X and shows that GPUs are a promising candidate for signature matching. },
}

@inproceedings{4919644,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Qiming Teng and Sweeney, P.F. and Duesterwald, E.},
 year = {2009},
 pages = {123--132},
 publisher = {IEEE},
 title = {Understanding the cost of thread migration for multi-threaded Java applications running on a multicore platform},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919644},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919644},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919644.pdf?arnumber=4919644},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Costs, Frequency, Hardware, Java, Java, Load management, Multicore processing, OS behavior, Operating systems, Performance analysis, Yarn, multi-threading, multicore system, multithreaded Java application, operating systems (computers), thread migration overhead, },
 abstract = {Multicore systems increase the complexity of performance analysis by introducing a new source of additional costs: thread migration between cores. This paper explores the cost of thread migration for Java applications. We first present a detailed analysis of the sources of migration overhead and show that they result from a combination of several factors including application behavior (working set size), OS behavior (migration frequency) and hardware characteristics (nonuniform cache sharing among cores). We also present a performance characterization of several multi-threaded Java applications. Surprisingly, our analysis shows that, although significant migration penalizes can be produced in controlled environments, the set of Java applications that we examined do not suffer noticeably from migration overhead when run in a realistic operating environment on an actual multicore platform. },
}

@inproceedings{4919645,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Moriyoshi Ohara and Nagpurkar, P. and Yohei Ueda and Ishizaki, K.},
 year = {2009},
 pages = {133--142},
 publisher = {IEEE},
 title = {The data-centricity of Web 2.0 workloads and its impact on server performance},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919645},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919645},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919645.pdf?arnumber=4919645},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Aggregates, Ajax, Asynchronous Java script, Asynchronous communication, Blogs, Collaborative work, IP networks, Information retrieval, Internet, Internet, Java, Mashups, Network servers, Social network services, Web 2.0 technology, Web server, XML, XML, asynchronous communication, client-server system, client-server systems, data-centricity, groupware, },
 abstract = {Advances in network performance and browser technologies, coupled with the ubiquity of internet access and proliferation of users, have lead to the emergence of a new class of Web applications, called Web 2.0. Web 2.0 technologies enable easy collaboration and sharing by allowing users to contribute, modify, and aggregate content using applications like Wikis, Blogs, Social Networking communities, and Mashups. Web 2.0 applications also make heavy use of Ajax, which allows asynchronous communication between client and server, to provide a richer user experience. In this paper, we analyze the effect of these new features on the infrastructure that hosts these workloads. In particular, we focus on the data-centricity, inherent in many Web 2.0 applications, and study its impact on the persistence layer in an application server context. Our experimental results reveal some important performance characteristics; we show that frequent Ajax requests, and other requests arising from the participatory nature of Web 2.0, often retrieve and update persistent data. This can lead to frequent database accesses, lock contention, and reduced performance. We also show that problems in the persistence layer, arising from the data-intensive nature of Web 2.0 applications, can lead to poor scalability that can inhibit us from exploiting current and future multicore architectures. },
}

@inproceedings{4919646,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Cook, J.J. and Zilles, C.},
 year = {2009},
 pages = {143--152},
 publisher = {IEEE},
 title = {Characterizing and optimizing the memory footprint of de novo short read DNA sequence assembly},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919646},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919646},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919646.pdf?arnumber=4919646},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Assembly, Bioinformatics, Computer science, Costs, DNA, DNA sequence assembly code, Error analysis, Error correction codes, Genomics, Performance analysis, Sequences, bioinformatics, computation-intensive, control-intensive, de Bruijn graph-based assembly, error correction codes, genetics, genome, graph theory, memory-centric optimization, memory-intensive bioinformatics code, optimisation, parallel algorithms, parallel assembly algorithm, preassembly error correction, sequencing machine, },
 abstract = {In this work, we analyze the memory-intensive bioinformatics problem of ldquode novordquo DNA sequence assembly, which is the process of assembling short DNA sequences obtained by experiment into larger contiguous sequences. In particular, we analyze the performance scaling challenges inherent to de Bruijn graph-based assembly, which is particularly well suited for the data produced by ldquonext generationrdquo sequencing machines. Unlike many bioinformatics codes which are computation-intensive or control-intensive, we find the memory footprint to be the primary performance issue for de novo sequence assembly. Specifically, we make four main contributions: 1) we demonstrate analytically that performing error correction before sequence assembly enables larger genomes to be assembled in a given amount of memory, 2) we identify that the use of this technique provides the key performance advantage to the leading assembly code, Velvet, 3) we demonstrate how this pre-assembly error correction technique can be subdivided into multiple passes to enable de Bruijn graph-based assembly to scale to even larger genomes, and 4) we demonstrate how Velvet's in-core performance can be improved using memory-centric optimizations. },
}

@inproceedings{4919647,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Heindl, A. and Pokam, G. and Adl-Tabatabai, A.-R.},
 year = {2009},
 pages = {153--162},
 publisher = {IEEE},
 title = {An analytic model of optimistic Software Transactional Memory},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919647},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919647},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919647.pdf?arnumber=4919647},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Computer science, Concurrent computing, Hardware, Markov processes, Microprocessors, Performance analysis, Power system management, Programming profession, Software performance, Space exploration, Transaction databases, closed-form analytic expression, concurrency control, concurrent transaction, discrete-time Markov chain, in-place memory update, iterative method, iterative methods, optimistic software transactional memory analytic model, program diagnostics, storage management, system behavior, transaction processing, write operation, },
 abstract = {An analytic model is proposed to assess the performance of optimistic software transactional memory (STM) systems with in-place memory updates for write operations. Based on an absorbing discrete-time Markov chain, closed-form analytic expressions are developed, which are quickly solved iteratively to determine key parameters of the STM system. The model covers complex implementation details such as read/write locking, data consistency checks and conflict management. It provides fundamental insight into the system behavior, when we vary input parameters like number and size of concurrent transactions or the number of the data objects. Numerical results are validated by comparison with a discrete-event simulation. },
}

@inproceedings{4919640,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Packirisamy, V. and Zhai, A. and Wei-Chung Hsu and Pen-Chung Yew and Tin-Fook Ngai},
 year = {2009},
 pages = {77--88},
 publisher = {IEEE},
 title = {Exploring speculative parallelism in SPEC2006},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919640},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919640},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919640.pdf?arnumber=4919640},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Application software, Clocks, Computer architecture, Computer industry, Continuous improvement, Hardware, Parallel processing, TLS execution model, Thread-Level Speculation, Transactional Memory, Yarn, complex control flow, computer industry, multicore architectures, multiprocessing systems, multithreaded architectures, optimal loop selection, parallel processing, parallel threads, parallelising compilers, parallelizing compilers, profile-driven TLS compiler, program control structures, single-program performance, speculative parallelism, speculative threads, },
 abstract = {The computer industry has adopted multi-threaded and multi-core architectures as the clock rate increase stalled in early 2000's. It was hoped that the continuous improvement of single-program performance could be achieved through these architectures. However, traditional parallelizing compilers often fail to effectively parallelize general-purpose applications which typically have complex control flow and excessive pointer usage. Recently hardware techniques such as Transactional Memory (TM) and Thread-Level Speculation (TLS) have been proposed to simplify the task of parallelization by using speculative threads. Potential of speculative parallelism in general-purpose applications like SPEC CPU 2000 have been well studied and shown to be moderately successful. Preliminary work examining the potential parallelism in SPEC2006 deployed parallel threads with a restrictive TLS execution model and limited compiler support, and thus only showed limited performance potential. In this paper, we first analyze the cross-iteration dependence behavior of SPEC 2006 benchmarks and show that more parallelism potential is available in SPEC 2006 benchmarks, comparing to SPEC2000. We further use a state-of-the-art profile-driven TLS compiler to identify loops that can be speculatively parallelized. Overall, we found that with optimal loop selection we can potentially achieve an average speedup of 60\% on four cores over what could be achieved by a traditional parallelizing compiler such as Intel's ICC compiler.We also found that an additional 11\% improvement can be potentially obtained on selected benchmarks using 8 cores when we extend TLS on multiple loop levels as opposed to restricting to a single loop level. },
}

@inproceedings{4919641,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Jiangtian Li and Xiaosong Ma and Singh, K. and Schulz, M. and de Supinski, B.R. and McKee, S.A.},
 year = {2009},
 pages = {89--100},
 publisher = {IEEE},
 title = {Machine learning based online performance prediction for runtime parallelization and task scheduling},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919641},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919641},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919641.pdf?arnumber=4919641},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Application software, Artificial Neural Networks, Automatic Task Scheduling, Costs, Hardware, Load management, Machine learning, Parallel programming, Performance Prediction, Predictive models, R language, Runtime, Scheduling algorithm, Scripting Languages, Testing, authoring languages, automatic performance prediction, learning (artificial intelligence), machine learning, next-generation software, online performance prediction, online task partitioning, pR framework, parallel programming, parallel programming, program execution, runtime parallelization, scheduling, scripting language, task analysis, task cost estimates, task scheduling, },
 abstract = {With the emerging many-core paradigm, parallel programming must extend beyond its traditional realm of scientific applications. Converting existing sequential applications as well as developing next-generation software requires assistance from hardware, compilers and runtime systems to exploit parallelism transparently within applications. These systems must decompose applications into tasks that can be executed in parallel and then schedule those tasks to minimize load imbalance. However, many systems lack a priori knowledge about the execution time of all tasks to perform effective load balancing with low scheduling overhead. In this paper, we approach this fundamental problem using machine learning techniques first to generate performance models for all tasks and then applying those models to perform automatic performance prediction across program executions. We also extend an existing scheduling algorithm to use generated task cost estimates for online task partitioning and scheduling. We implement the above techniques in the pR framework, which transparently parallelizes scripts in the popular R language, and evaluate their performance and overhead with both a real-world application and a large number of synthetic representative test scripts. Our experimental results show that our proposed approach significantly improves task partitioning and scheduling, with maximum improvements of 21.8\%, 40.3\% and 22.1\% and average improvements of 15.9\%, 16.9\% and 4.2\% for LMM (a real R application) and synthetic test cases with independent and dependent tasks, respectively. },
}

@inproceedings{4919642,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Haoqiang Zheng and Nieh, J.},
 year = {2009},
 pages = {101--112},
 publisher = {IEEE},
 title = {WARP: Enabling fast CPU scheduler development and evaluation},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919642},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919642},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919642.pdf?arnumber=4919642},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {CPU scheduler development, Code standards, Debugging, Hardware, Kernel, Linux, Linux, Linux operating system, Monitoring, Operating systems, Scheduling algorithm, System testing, Timing, kernel tracing toolkit, operating system kernel code testing, performance monitoring tools, program debugging, program testing, scheduling, scheduling algorithms, software performance evaluation, trace-driven virtualized scheduler execution, unmodified kernel scheduling code, user-space debugging, },
 abstract = {Developing CPU scheduling algorithms and understanding their impact in practice can be difficult and time consuming due to the need to modify and test operating system kernel code and measure the resulting performance on a consistent workload of real applications. To address this problem, we have developed WARP, a trace-driven virtualized scheduler execution environment that can dramatically simplify and speed the development of CPU schedulers. WARP is easy to use as it can run unmodified kernel scheduling code and can be used with standard user-space debugging and performance monitoring tools. It accomplishes this by virtualizing operating system and hardware events to decouple kernel scheduling code from its native operating system and hardware environment. A simple kernel tracing toolkit can be used with WARP to capture traces of all CPU scheduling related events from a real system. WARP can then replay these traces in its virtualized environment with the same timing characteristics as in the real system. Traces can be used with different schedulers to provide accurate comparisons of scheduling performance for a given application workload. We have implemented a WARP Linux prototype. Our results show that WARP can use application traces captured from its toolkit to accurately reflect the scheduling behavior of the real Linux operating system. Furthermore, testing scheduler behavior using WARP with application traces can be two orders of magnitude faster than running the applications using Linux. },
}

@inproceedings{4919643,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Moses, J. and Aisopos, K. and Jaleel, A. and Iyer, R. and Illikkal, R. and Newell, D. and Makineni, S.},
 year = {2009},
 pages = {113--122},
 publisher = {IEEE},
 title = {CMPSched$im: Evaluating OS/CMP interaction on shared cache management},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919643},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919643},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919643.pdf?arnumber=4919643},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Analytical models, CMPSched$im, Environmental management, Hardware, Instruments, Linsched, Monitoring, Operating systems, Optimal scheduling, Performance analysis, Pin, Resource management, Virtual machine monitors, application classification, binary instrumentation tools, cache simulators, cache storage, core simulators, full-system execution-driven simulations, instrumentation, operating system scheduling heuristics, operating system-chip-multiprocessor interaction, operating systems (computers), performance analysis, resource allocation, resource management, resource monitoring, scheduling, shared cache management, shared cache monitoring, shared memory systems, software performance evaluation, storage management, user-level scheduling tools, },
 abstract = {CMPs have now become mainstream and are growing in complexity with more cores, several shared resources (cache, memory, etc) and the potential for additional heterogeneous elements. In order to manage these resources, it is becoming critical to optimize the interaction between the execution environment (operating systems, virtual machine monitors, etc) and the CMP platform. Performance analysis of such OS and CMP interactions is challenging because it requires long running full-system execution-driven simulations. In this paper, we explore an alternative approach (CMPSched\$im) to evaluate the interaction of OS and CMP architectures. In particular, CMPSched\$im is focused on evaluating techniques to address the shared cache management problem through better interaction between CMP hardware and operating system scheduling. CMPSched\$im enables fast and flexible exploration of this interaction by combining the benefits of (a) binary instrumentation tools (Pin), (b) user-level scheduling tools (Linsched) and (c) simple core/cache simulators. In this paper, we describe CMPSched\$im in detail and present case studies showing how CMPSched\$im can be used to optimize OS scheduling by taking advantage of novel shared cache monitoring capabilities in the hardware. We also describe OS scheduling heuristics to improve overall system performance through resource monitoring and application classification to achieve near optimal scheduling that minimizes the effects of contention in the shared cache of a CMP platform. },
}

@inproceedings{1430554,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Albayraktaroglu, K. and Jaleel, A. and Wu, X. and Franklin, M. and Jacob, B. and Tseng, C.-W. and Yeung, D.},
 year = {2005},
 pages = {2--9},
 publisher = {IEEE},
 title = {BioBench: A Benchmark Suite of Bioinformatics Applications},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430554},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430554},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430554.pdf?arnumber=1430554},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Application software, BioBench, Bioinformatics, Computer architecture, Displays, Drugs, Genetics, Genomics, ILP, Medical treatment, Microarchitecture, Scientific computing, benchmark suite, benchmark testing, bioinformatics applications, biotechnology, computer architecture, computer architecture, drug discovery, genetics, genomics, instruction level parallelism, instruction sets, load-store instruction, microarchitectural design, microprocessor chips, scientific computing application, },
 abstract = {Recent advances in bioinformatics and the significant increase in computational power available to researchers have made it possible to make better use of the vast amounts of genetic data that has been collected over the last two decades. As the uses of genetic data expand to include drug discovery and development of gene-based therapies, bioinformatics is destined to take its place in the forefront of scientific computing application domains. Despite the clear importance of this field, common bioinformatics applications and their implication on microarchitectural design have received scant attention from the computer architecture community so far. The availability of a common set of bioinformatics benchmarks could be the first step to motivate further research in this crucial area. To this end, this paper presents BioBench, a benchmark suite that represents a diverse set of bioinformatics applications. The first version of BioBench includes applications from different application domains, with a particular emphasis on mature genomics applications. The applications in the benchmark are described briefly, and basic execution characteristics obtained on a real processor are presented. Compared to SPEC INT and SPEC FP benchmarks, applications in BioBench display a higher percentage of load/store instructions, almost negligible floating-point operation content, and higher IPC than either SPEC INT or SPEC FP applications. Our evaluation suggests that bioinformatics applications have distinctly different characteristics from the applications in both of the mentioned SPEC suites; and our findings indicate that bioinformatics workloads can benefit from architectural improvements to memory bandwidth and techniques that exploit their high levels of ILP. The entire BioBench suite and accompanying reference data will be made freely available to researchers },
}

@inproceedings{1430579,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Murali Vilayannur and Anand Sivasubramaniam and Kandemir, M.},
 year = {2005},
 pages = {248--257},
 publisher = {IEEE},
 title = {Pro-active Page Replacement for Scientific Applications: A Characterization},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430579},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430579},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430579.pdf?arnumber=1430579},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Application software, Biomedical imaging, Computer science, Intelligent systems, Linux, Linux, Linux, Memory management, Operating systems, Prefetching, Runtime, Technological innovation, compiler-based techniques, intelligent prefetching, operating system, operating system kernels, page-fault patterns, paged storage, paging policies, performance evaluation, physical memory usage, pro-active page replacement, program compilers, scientific applications, virtual memory, },
 abstract = {Paging policies implemented by today's operating systems cause scientific applications to exhibit poor performance, when the application's working set does not fit in main memory. This has been typically attributed to the sub-optimal performance of LRU-like virtual-memory replacement algorithms. On one end of the spectrum, researchers in the past have proposed fully automated compiler-based techniques that provide crucial information on future access patterns (reuse-distances, release hints etc) of an application that can be exploited by the operating system to make intelligent prefetching and replacement decisions. Static techniques like the aforementioned can be quite accurate, but require that the source code be available and analyzable. At the other end of the spectrum, researchers have also proposed pure system-level algorithmic innovations to improve the performance of LRU-like algorithms, some of which are only interesting from the theoretical sense and may not really be implementable. Instead, in this paper we explore the possibility of tracking application's runtime behavior in the operating system, and find that there are several useful characteristics in the virtual memory behavior that can be anticipated and used to pro-actively manage physical memory usage. Specifically, we show that LRU-like replacement algorithms hold onto pages long after they outlive their usefulness and propose a new replacement algorithm that exploits the predictability of the application's page-fault patterns to reduce the number of page-faults. Our results demonstrate that such techniques can reduce page-faults by as much as 78\% over both LRU and EELRU that is considered to be one of the state-of-the-art algorithms towards addressing the performance shortcomings of LRU. Further, we also present an implementable replacement algorithm within the operating system, that performs considerably better than the Linux kernel's replacement algorithm },
}

@inproceedings{1430578,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Lau, J. and Sampson, J. and Perelman, E. and Hamerly, G. and Calder, B.},
 year = {2005},
 pages = {236--247},
 publisher = {IEEE},
 title = {The Strong correlation Between Code Signatures and Performance},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430578},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430578},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430578.pdf?arnumber=1430578},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Application software, Computer science, Counting circuits, Databases, Frequency conversion, Hardware, Instruments, Lifting equipment, Performance analysis, Sampling methods, benchmark testing, computer architecture, fuzzy correlation, instruction sets, performance predictability, phase analysis, program compilers, program control structures, sampled code signatures, sampled hardware counters, sampled instruction counts, sampling methods, },
 abstract = {A recent study examined the use of sampled hardware counters to create sampled code signatures. This approach is attractive because sampled code signatures can be quickly gathered for any application. The conclusion of their study was that there exists a fuzzy correlation between sampled code signatures and performance predictability. The paper raises the question of how much information is lost in the sampling process, and our paper focuses on examining this issue. We first focus on showing that there exists a strong correlation between code signatures and performance. We then examine the relationship between sampled and full code signatures, and how these affect performance predictability. Our results confirm that there is a fuzzy correlation found in recent work for the SPEC programs with sampled code signatures, but that a strong correlation exists with full code signatures. In addition, we propose converting the sampled instruction counts, used in the prior work, into sampled code signatures representing loop and procedure execution frequencies. These sampled loop and procedure code signatures allow phase analysis to more accurately and easily find patterns, and they correlate better with performance },
}

@inproceedings{4211038,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Vaidyanathan, K. and Panda, D.K.},
 year = {2007},
 pages = {220--229},
 publisher = {IEEE},
 title = {Benefits of I/O Acceleration Technology (I/OAT) in Clusters},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363752},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211038},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211038.pdf?arnumber=4211038},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Acceleration, Bandwidth, CPU utilization, Computer science, Delay, Ethernet networks, File systems, I/O acceleration technology, Internet, Internet protocol, Network servers, Scalability, Sun, TCP/IP stack, TCPIP, central processing unit, concurrent thread, input-output programs, multigigabit data rate, multitier data center, network bandwidth performance, packet processing overhead, parallel processing, parallel virtual file system, transmission control protocol, transport protocol, transport protocols, },
 abstract = {Packet processing in the TCP/IP stack at multi-gigabit data rates occupies a significant portion of the system overhead. Though there are several techniques to reduce the packet processing overhead on the sender-side, the receiver-side continues to remain as a bottleneck. I/O acceleration technology (I/OAT), developed by Intel, is a set of features particularly designed to reduce the receiver-side packet processing overhead. This paper studies the benefits of the I/OAT technology by extensive evaluations through micro-benchmarks as well as evaluations on two different application domains: (1) a multi-tier data-center environment and (2) a parallel virtual file system (PVFS). Our micro-benchmark evaluations show that I/OAT results in 38\% lower overall CPU utilization in comparison with traditional communication. Due to this reduced CPU utilization, I/OAT delivers better performance and increased network bandwidth. Our experimental results with data-centers and file systems reveal that I/OAT can improve the total number of transactions processed by 14\% and throughput by 12\%, respectively. In addition, I/OAT can sustain a large number of concurrent threads (up to a factor of four as compared to non-I/OAT) in data-center environments, thus increasing the scalability of the servers },
}

@inproceedings{4211039,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Sangyeun Cho and Martin, J.R. and Ruibin Xu and Hammoud, M.H. and Melhem, R.},
 year = {2007},
 pages = {230--241},
 publisher = {IEEE},
 title = {CA-RAM: A High-Performance Memory Substrate for Search-Intensive Applications},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363753},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211039},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211039.pdf?arnumber=4211039},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Acceleration, Application specific processors, Associative memory, CADCAM, Computer aided manufacturing, Databases, Energy consumption, Hardware, Random access memory, Speech recognition, application-specific processor, content addressable random access memory, direct hardware implementation, hash function, hashing technique, high-performance memory substrate, high-performance search accelerator, memory access, memory hierarchy concept, memory structure, parallel key matching operation, random-access storage, search operation, search-intensive application, storage management, },
 abstract = {This paper proposes a specialized memory structure called CA-RAM (content addressable random access memory) to accelerate search operations present in many important real-world applications. Search operations can occupy a significant portion of total execution time and energy consumption, while posing a difficult performance problem to tackle using traditional memory hierarchy concepts. In essence, CA-RAM is a direct hardware implementation of the well-known hashing technique. Searchable records are stored in CA-RAM at a location determined by a hash function, defined on their search key. After a database has been built, looking up a record in CA-RAM typically involves a single memory access followed by a parallel key matching operation. Compared with a conventional CAM (content addressable memory) solution, CA-RAM capitalizes on dense SRAM and DRAM designs, and achieves comparable search performance while occupying much smaller area and consuming significantly less power. This paper presents detailed design aspects of CA-RAM, to be integrated in future general-purpose and application-specific processors and systems. To further motivate and justify our approach, we present two real examples of using CA-RAM to build a high-performance search accelerator targeting: IP address lookup in core routers and trigram lookup in a large speech recognition system },
}

@inproceedings{4211036,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Younggyun Koh and Knauerhase, R. and Brett, P. and Bowman, M. and Zhihua Wen and Pu, C.},
 year = {2007},
 pages = {200--209},
 publisher = {IEEE},
 title = {An Analysis of Performance Interference Effects in Virtual Environments},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363750},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211036},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211036.pdf?arnumber=4211036},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Character generation, Data security, Interference, Isolation technology, Ken hypervisor, Measurement, Performance analysis, Throughput, Virtual environment, Virtual machining, Voice mail, data analysis, performance evaluation, performance interference, performance isolation, performance metrics, runtime characteristics, system throughput, system-level workload characteristics, virtual environment, virtual machines, virtual machines, virtualization, },
 abstract = {Virtualization is an essential technology in modern datacenters. Despite advantages such as security isolation, fault isolation, and environment isolation, current virtualization techniques do not provide effective performance isolation between virtual machines (VMs). Specifically, hidden contention for physical resources impacts performance differently in different workload configurations, causing significant variance in observed system throughput. To this end, characterizing workloads that generate performance interference is important in order to maximize overall utility. In this paper, we study the effects of performance interference by looking at system-level workload characteristics. In a physical host, we allocate two VMs, each of which runs a sample application chosen from a wide range of benchmark and real-world workloads. For each combination, we collect performance metrics and runtime characteristics using an instrumented Ken hypervisor. Through subsequent analysis of collected data, we identify clusters of applications that generate certain types of performance interference. Furthermore, we develop mathematical models to predict the performance of a new application from its workload characteristics. Our evaluation shows our techniques were able to predict performance with average error of approximately 5\% },
}

@inproceedings{842294,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Sarkar, V. and Megiddo, N.},
 year = {2000},
 pages = {146--153},
 publisher = {IEEE},
 title = {An analytical model for loop tiling and its solution},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842294},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842294},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842294.pdf?arnumber=842294},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Analytical models, Costs, FORTRAN, Hardware, IBM XL Fortran product compilers, Multidimensional systems, Multiprocessing systems, Optimizing compilers, Polynomials, Program processors, Programming profession, Tiles, analytical model, constant-time algorithm, doubly nested loops, iterative search, loop nest, loop tiling, memory cost estimation, memory hierarchy parameters, memory hierarchy utilization, optimal solution, optimal tile size values, optimising compilers, performance estimation, processor designers, production-quality optimizing compilers, program control structures, program transformation, rational polynomial, search problems, software performance evaluation, tile size variable, tile size variables, tiled loops, },
 abstract = {The authors address the problem of estimating the performance of loop tiling, an important program transformation for improved memory hierarchy utilization. We introduce an analytical model for estimating the memory cost of a loop nest as a rational polynomial in tile size variables. We also present a constant-time algorithm for finding an optimal solution to the model (i.e., for selecting optimal tile sizes) for the case of doubly nested loops. This solution can be applied to tiling of three loops by performing an iterative search on the value of the first tile size variable, and using the constant-time algorithm at each point in the search to obtain optimal tile size values for the remaining two loops. Our solution is efficient enough to be used in production-quality optimizing compilers, and has been implemented in the IBM XL Fortran product compilers. This solution can also be used by processor designers to efficiently predict the performance of a set of tiled loops for a range of memory hierarchy parameters },
}

@inproceedings{842297,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Gomez, M.E. and Santonja, V.},
 year = {2000},
 pages = {172--177},
 publisher = {IEEE},
 title = {A new approach in the analysis and modeling of disk access patterns },
 date = {2000},
 doi = {10.1109/ISPASS.2000.842297},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842297},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842297.pdf?arnumber=842297},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Ethernet networks, Large Hadron Collider, Pattern analysis, Performance analysis, Sliding mode control, accessed blocks, arrival patterns, bursty behavior, disc storage, disk access pattern analysis, disk arrival patterns, input-output programs, mathematical evidence, physical explanation, self-similar phenomenon, self-similar property, self-similarity, spatial series, starting address, storage management, time series, time series, },
 abstract = {While in previous work we have demonstrated that disk arrival patterns are consistent with self-similarity and have provided a physical explanation for the self-similar phenomenon in disk arrival patterns, the authors now deal with the analysis and modeling of disk access patterns. We provide visual and mathematical evidence showing that the same bursty behavior observed in the time series can also be observed in the spatial series formed by the starting address of the accessed blocks. Moreover, we demonstrate that the clustering of accesses in areas of the disk has self-similar characteristics. Next, we demonstrate that the observed behavior can be explained using the same self-similar property used in the analysis of arrival patterns and applying the same physical explanation },
}

@inproceedings{4211035,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Bryan, P.D. and Rosier, M.C. and Conte, T.M.},
 year = {2007},
 pages = {190--199},
 publisher = {IEEE},
 title = {Reverse State Reconstruction for Sampled Microarchitectural Simulation},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363749},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211035},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211035.pdf?arnumber=4211035},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Computational modeling, Computer architecture, Computer simulation, Costs, Hardware, Inspection, Microarchitecture, Process design, Research and development, Sampling methods, computer architecture, performance evaluation, processor simulation, reverse engineering, reverse state reconstruction, sampled microarchitectural simulation, virtual machines, },
 abstract = {For simulation, a tradeoff exists between speed and accuracy. The more instructions simulated from the workload, the more accurate the results - but at a higher cost. To reduce processor simulation times, a variety of techniques have been introduced. Statistically sampled simulation is one method that mitigates the cost of simulation while retaining high accuracy. A contiguous group of instructions, called a cluster, is simulated and then a fast type of simulation is used to skip to the next group. As instructions are skipped, non-sampling bias is introduced and must be removed for accurate measurements to be taken. In this paper, the reverse state reconstruction warm-up method is introduced. While skipping between clusters, the data necessary for reconstruction are recorded. Later, these data are scanned in reverse order so that processor state can be approximated without functionally applying every skipped instruction. By trading storage for speed, the proposed method introduces the concept of on-demand state reconstruction for sampled simulations. Using this technique, the method isolates ineffectual instructions from the skipped instructions without the use of profiling. Compared to SMARTS, reverse state reconstruction achieves a maximum and average speedup ratio of 2.45 and 1.64, respectively, with minimal sacrifice to accuracy (less than 0.3\%) },
}

@inproceedings{4211032,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Bircher, W.L. and John, L.K.},
 year = {2007},
 pages = {158--168},
 publisher = {IEEE},
 title = {Complete System Power Estimation: A Trickle-Down Approach Based on Performance Events},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363746},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211032},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211032.pdf?arnumber=4211032},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Computer architecture, Counting circuits, Energy consumption, Hardware, Laboratories, Microprocessors, Power engineering computing, Power measurement, Power system modeling, Temperature sensors, complete system power consumption, complete system power estimation, microprocessor performance counter, microprocessor performance event, microprocessor power, on-chip performance event counter, online measurement, performance evaluation, power aware computing, power model, power sensing hardware, system power consumption estimation, },
 abstract = {This paper proposes the use of microprocessor performance counters for online measurement of complete system power consumption. While past studies have demonstrated the use of performance counters for microprocessor power, to the best of our knowledge, we are the first to create power models for the entire system based on processor performance events. Our approach takes advantage of the "trickle-down" effect of performance events in a microprocessor. We show how well known performance-related events within a microprocessor such as cache misses and DMA transactions are highly correlated to power consumption outside of the microprocessor. Using measurement of an actual system running scientific and commercial workloads we develop and validate power models for five subsystems: memory, chipset, I/O, disk and microprocessor. These models are shown to have an average error of less than 9\% per subsystem across the considered workloads. Through the use of these models and existing on-chip performance event counters, it is possible to estimate system power consumption without the need for additional power sensing hardware },
}

@inproceedings{1430570,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Carroll, H. and Flanagan, J.K. and Satish Baniya},
 year = {2005},
 pages = {157--166},
 publisher = {IEEE},
 title = {A Trace-Driven Simulator For Palm OS Devices},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430570},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430570},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430570.pdf?arnumber=1430570},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computational modeling, Computer science, Computer simulation, Discrete event simulation, Handheld computers, Hardware, Instruments, Monitoring, Operating systems, Palm OS devices, Software performance, cache storage, cache storage, digital simulation, memory performance, notebook computers, operating environment, operating systems (computers), performance evaluation, performance statistics, software simulator, trace-driven simulator, },
 abstract = {Due to the high cost of producing hardware prototypes, software simulators are typically used to determine the performance of proposed systems. To accurately represent a system with a simulator, the simulator inputs need to be representative of actual system usage. Trace-driven simulators that use logs of actual usage are generally preferred by researchers and developers to other types of simulators to determine expected performance. In this paper we explain the design and results of a trace-driven simulator for Palm OS devices capable of starting in a specified state and replaying a log of inputs originally generated on a handheld. We collect the user inputs with an acceptable amount of overhead while a device is executing real applications in normal operating environments. We based our simulator on the deterministic state machine model. The model specifies that two equivalent systems that start in the same state and have the same inputs applied, follow the same execution paths. By replaying the collected inputs we are able to collect traces and performance statistics from the simulator that are representative of actual usage with minimal perturbation. Our simulator can be used to evaluate various hardware modifications to Palm OS devices such as adding a cache. At the end of this paper we present an in-depth case study analyzing the expected memory performance from adding a cache to a Palm m515 device },
}

@inproceedings{1430573,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Yuan Zhao and Kennedy, K.},
 year = {2005},
 pages = {187--196},
 publisher = {IEEE},
 title = {Scalarization on Short Vector Machines},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430573},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430573},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430573.pdf?arnumber=1430573},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Cache storage, Computer science, Microprocessors, Prefetching, SIMD, array statements, array syntax, data alignment properly, instruction sets, loop alignment algorithm, loop nests, memory hierarchy performance, microprocessors, parallel architectures, program control structures, scalarization, short vector machines, storage allocation, temporary storage, vector processor systems, vectorized scalar replacement, },
 abstract = {Scalarization is a process that converts array statements into loop nests so that they can run on a scalar machine. One technical difficulty of scalarization is that temporary storage often needs to be allocated in order to preserve the semantics of array syntax - "fetch before store". Many techniques have been developed to reduce the size of temporary storage requirement in order to improve the memory hierarchy performance. With the emergence of short vector units on modern microprocessors, it is interesting to see how to extend the preexisting scalarization methods so that the underlying vector infrastructure is fully utilized, while at the same time keep the temporary storage minimized. In this paper, we extend a loop alignment algorithm for scalarization on short vector machines. The revised algorithm not only achieves vector execution with minimum temporary storage, but also handles data alignment properly, which is very important for performance. Our experiments on two types of widely available architectures demonstrate the effectiveness of our strategy },
}

@inproceedings{1430572,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Budiu, M. and Artigas, P.V. and Goldstein, S.C.},
 year = {2005},
 pages = {177--186},
 publisher = {IEEE},
 title = {Dataflow: A Complement to Superscalar},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430572},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430572},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430572.pdf?arnumber=1430572},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Ash, Circuits, Clocks, Computer architecture, Hardware, Parallel processing, Performance analysis, Registers, Silicon, Wires, control-intensive program, data flow analysis, data flow computing, data-parallel program, dataflow architecture, general-purpose codes, integer media, parallel architectures, parallel programming, performance evaluation, program control structures, static dataflow machines, superscalar processor, },
 abstract = {There has been a resurgence of interest in dataflow architectures, because of their potential for exploiting parallelism with low overhead. In this paper we analyze the performance of a class of static dataflow machines on integer media and control-intensive programs and we explain why a dataflow machine, even with unlimited resources, does not always outperform a superscalar processor on general-purpose codes, under the assumption that both machines take the same time to execute basic operations. We compare a program-specific dataflow machine with unlimited parallelism to a superscalar processor running the same program. While the dataflow machines provide very good performance on most data-parallel programs, we show that the dataflow machine cannot always take advantage of the available parallelism. Using the dynamic critical path we investigate the mechanisms used by superscalar processors to provide a performance advantage and their impact on a dataflow model },
}

@inproceedings{1291370,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Eeckhout, L.},
 year = {2004},
 publisher = {IEEE},
 title = {Efficient architectural design of high performance microprocessors},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291370},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291370},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291370.pdf?arnumber=1291370},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { architectural simulation,  benchmarking,  high performance microprocessors,  microprocessor architectural design,  microprocessor chips,  representative workload design,  statistical analysis,  statistical data analysis,  statistical simulation,  trace sampling,  virtual machines, Analytical models, Biographies, Computational modeling, Computer aided instruction, Computer architecture, Computer science, Data analysis, Microarchitecture, Microprocessors, Sampling methods, },
 abstract = {Summary form only given. Designing a high performance microprocessor is extremely time-consuming taking at least several years. An important part of this design effort is architectural simulation which defines the microarchitecture or the organization of the microprocessor. The reason why these simulations are so time-consuming is fourfold: (i) the architectural design space is huge; (ii) the number of benchmarks the microarchitecture needs to be evaluated with, is large; (iii) the number of instructions that need to be simulated per benchmark is huge as well; and (iv) simulators are becoming relatively slower due to the increasingly complex designs of current high performance microprocessors. In this tutorial, we discuss these issues and propose a solution for each of them. As such, we present an architectural simulation framework for designing high performance microprocessors which reduces the total simulation time by several orders of magnitude without sacrificing accuracy. This is done by combining several recently proposed techniques, such as statistical simulation, representative workload design using statistical data analysis techniques, trace sampling and reduced input sets. },
}

@inproceedings{1291371,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Wolf, W.},
 year = {2004},
 publisher = {IEEE},
 title = {Architectures and compilers for multimedia},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291371},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291371},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291371.pdf?arnumber=1291371},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { audio compression,  continuous media,  data compression,  energy constraint,  gesture recognition,  multimedia architecture,  multimedia compiler,  multimedia computing,  multimedia computing systems,  multiprocessing systems,  multiprocessor system-on-chip design,  power constraint,  program compilers,  real-time constraint,  real-time gesture recognition,  software architecture,  system-on-chip,  video coding,  video compression, Application software, Audio compression, Computer architecture, Hardware, Multimedia computing, Multimedia systems, Multiprocessing systems, Real time systems, Shape measurement, Video compression, },
 abstract = {Summary form only given. The article covers architectures and compilers for multimedia systems. Multimedia applications impose real-time constraints on continuous media; they also include a surprisingly wide variety of algorithms. Many multimedia systems also operate under power/energy constraints. As such, multimedia computing systems are an important area of interest for ISPASS. This tutorial targets individuals with experience in hardware and software but who have limited expertise in multimedia. We start with an introduction to multimedia algorithms such as video and audio compression since the characteristics of these algorithms help to shape measurement strategies and architectural decisions. We then cover modern multimedia architectures and compilation techniques relevant to those architectures. We conclude with a case study drawn from our own research - the design of a multiprocessor system-on-chip for real-time gesture recognition. },
}

@inproceedings{5452021,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Cain, H.W. and Nagpurkar, P.},
 year = {2010},
 pages = {203--212},
 publisher = {IEEE},
 title = {Runahead execution vs. conventional data prefetching in the IBM POWER6 microprocessor},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452021},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452021},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452021.pdf?arnumber=5452021},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Context modeling, Hardware, IBM POWER6 commercial server, IBM POWER6 microprocessor, Java, Microprocessors, Optimizing compilers, Performance evaluation, Prefetching, Proposals, Software performance, compiler-inserted software prefetching, data prefetching, hardware-based sequential stream prefetcher, microprocessor chips, program compilers, sequential based prefetching algorithms, software-directed prefetching, storage management, stride-based prefetching algorithms, },
 abstract = {After many years of prefetching research, most commercially available systems support only two types of prefetching: software-directed prefetching and hardware-based prefetchers using simple sequential or stride-based prefetching algorithms. More sophisticated prefetching proposals, despite promises of improved performance, have not been adopted by industry. In this paper, we explore the efficacy of both hardware and software prefetching in the context of an IBM POWER6 commercial server. Using a variety of applications that have been compiled with an aggressively optimizing compiler to use software prefetching when appropriate, we perform the first study of a new runahead prefetching feature adopted by the POWER6 design, evaluating it in isolation and in conjunction with a conventional hardware-based sequential stream prefetcher and compiler-inserted software prefetching. We find that the POWER6 implementation of runahead prefetching is quite effective on many of the memory intensive applications studied; in isolation it improves performance as much as 36\% and on average 10\%. However, it outperforms the hardware-based stream prefetcher on only two of the benchmarks studied, and in those by a small margin. When used in conjunction with the conventional prefetching mechanisms, the runahead feature adds an additional 6\% on average, and 39\% in the best case (GemsFDTD). },
}

@inproceedings{5452020,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Secchi, S. and Meloni, P. and Raffo, L.},
 year = {2010},
 pages = {194--202},
 publisher = {IEEE},
 title = {Exploiting FPGAs for technology-aware system-level evaluation of multi-core architectures},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452020},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452020},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452020.pdf?arnumber=5452020},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {2D homogeneous mesh architecture, ASIC, Analytical models, Application software, Computer architecture, Current measurement, Emulation, FPGA, Field programmable gate arrays, Hardware, MPSoC computing platforms, Prototypes, Software prototyping, Time to market, field programmable gate arrays, hardware emulators, hardware-software codevelopment, integrated circuit design, interconnection network parameters, multicore architectures, multiprocessing systems, power consumption, reconfigurable architectures, software-based fully cycle-accurate simulators, system-on-chip, technology-aware system-level evaluation, technology-related analytical models, },
 abstract = {The hardware-software co-development of modern complex MPSoC computing platforms exposes to the designer a huge complexity, resulting from the combination of vastly different architectural possibilities with strict demands posed by the target applications. To handle this complexity, highly accurate but rapid prototyping/evaluation environments need to be developed, that would possibly be able to provide an effective measurement of the system under design as soon as possible, allowing to comply with current time-to-market. While software-based fully cycle-accurate simulators do not seem to represent anymore an adequate solution to solve this issue, the attention has been recently shifted to the adoption of hardware emulators in the early stages of the design flow. In this work, we present an emulation framework for library-based semiautomatic instantiation of complex multi-core platforms that exploits FPGA devices to provide detailed functional information on the platform under development, and at the same time using hardware execution traces with technology-related analytical models to extract, already at system-level, physical metrics on power consumption, maximum operating frequency and area occupation of a prospective ASIC implementation of the system. Two prospective use case scenarios are presented to validate the usefulness of the presented framework: the first one analyzes the mapping and the scalability of a highly parallel application over a 2D homogeneous mesh architecture for increasing number of processors, while the second one employs the emulation infrastructure inside a design space exploration flow for the configuration of some interconnection network parameters. },
}

@inproceedings{5452025,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Alexandrov, A. and Armstrong, D. and Rajic, H. and Voss, M. and Hayes, D.},
 year = {2010},
 pages = {184--193},
 publisher = {IEEE},
 title = {High-level performance modeling of task-based algorithms},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452025},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452025},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452025.pdf?arnumber=5452025},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Algorithm design and analysis, Intel threading building blocks, Intel&#x00AE,  Threading Building Blocks, Measurement, Microsoft parallel pattern library, Parallel algorithms, Parallel programming, Performance analysis, Pipelines, Prototypes, Runtime library, Visualization, Yarn, client-server benchmark, data visualisation, high-level performance modeling, parallel algorithms, parallel programming, parallel programming tools, parallel programming tools, task analysis, task-based algorithms, task-based parallel algorithm visualization, },
 abstract = {Performing modeling and visualization of task-based parallel algorithms is challenging. Libraries such as Intel Threading Building Blocks (TBB) and Microsoft's Parallel Patterns Library provide high-level algorithms that are implemented using low-level tasks. Current tools present performance at this lower level. Developers like to tune and debug at the same level as the coding abstraction, so in this paper we propose tools and a two step methodology that target this level of abstraction. In the first step, the system level metrics of utilization and overhead are collected to determine if performance is acceptable. If a problem is suspected, the second step of our methodology projects these metrics on to the algorithms contained in the application. Using these projections many common performance issues can be quickly diagnosed. We demonstrate our methodology using a prototype implementation that is integrated with the Intel Threading Building Blocks library. We show the flexibility of the approach by analyzing three applications, including a client-server benchmark that uses a parallel_for nested within a parallel pipeline. },
}

@inproceedings{5452024,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Laurenzano, M.A. and Tikir, M.M. and Carrington, L. and Snavely, A.},
 year = {2010},
 pages = {175--183},
 publisher = {IEEE},
 title = {PEBIL: Efficient static binary instrumentation for Linux},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452024},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452024},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452024.pdf?arnumber=5452024},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Assembly, Costs, Debugging, Hardware, Instruments, Laboratories, Libraries, Linux, Linux, Linux, PEBIL API, Runtime, Supercomputers, application program interfaces, dynamic binary instrumentation, function level code relocation, static binary instrumentation, },
 abstract = {Binary instrumentation facilitates the insertion of additional code into an executable in order to observe or modify the executable's behavior. There are two main approaches to binary instrumentation: static and dynamic binary instrumentation. In this paper we present a static binary instrumentation toolkit for Linux on the x86/x86_64 platforms, PEBIL (PMaC's Efficient Binary Instrumentation Toolkit for Linux). PEBIL is similar to other toolkits in terms of how additional code is inserted into the executable. However, it is designed with the primary goal of producing efficient-running instrumented code. To this end, PEBIL uses function level code relocation in order to insert large but fast control structures. Furthermore, the PEBIL API provides tool developers with the means to insert lightweight hand-coded assembly rather than relying solely on the insertion of instrumentation functions. These features enable the implementation of efficient instrumentation tools with PEBIL. The overhead introduced for basic block counting by PEBIL is an average of 65\% of the overhead of Dyninst, 41\% of the overhead of Pin, 15\% of the overhead of DynamoRIO, and 8\% of the overhead of Valgrind. },
}

@inproceedings{5452045,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Shafer, J. and Rixner, S. and Cox, A.L.},
 year = {2010},
 pages = {122--133},
 publisher = {IEEE},
 title = {The Hadoop distributed filesystem: Balancing portability and performance},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452045},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452045},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452045.pdf?arnumber=5452045},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Data analysis, Databases, Delay, Hadoop distributed file system, Hardware, Java, Java, Java, MapReduce task scheduling, Open source software, Performance analysis, Processor scheduling, Resource management, distributed user-level file system, large dataset analysis, portability balancing, public domain software, scheduling, software platforms, software portability, storage management, storage resource management, very large databases, },
 abstract = {Hadoop is a popular open-source implementation of MapReduce for the analysis of large datasets. To manage storage resources across the cluster, Hadoop uses a distributed user-level filesystem. This filesystem - HDFS - is written in Java and designed for portability across heterogeneous hardware and software platforms. This paper analyzes the performance of HDFS and uncovers several performance issues. First, architectural bottlenecks exist in the Hadoop implementation that result in inefficient HDFS usage due to delays in scheduling new MapReduce tasks. Second, portability limitations prevent the Java implementation from exploiting features of the native platform. Third, HDFS implicitly makes portability assumptions about how the native platform manages storage resources, even though native filesystems and I/O schedulers vary widely in design and behavior. This paper investigates the root causes of these performance bottlenecks in order to evaluate tradeoffs between portability and performance in the Hadoop distributed filesystem. },
}

@inproceedings{5452029,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Ariel, A. and Fung, W.W.L. and Turner, A.E. and Aamodt, T.M.},
 year = {2010},
 pages = {164--174},
 publisher = {IEEE},
 title = {Visualizing complex dynamics in many-core accelerator architectures},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452029},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452029},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452029.pdf?arnumber=5452029},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Accelerator architectures, AerialVision tool, Application software, Computational modeling, Computer architecture, Concurrent computing, Counting circuits, GPGPU-Sim simulator, GPU performance visualization, Graphics, Hardware, Parallel processing, Visualization, bottleneck identification process, computer graphic equipment, coprocessors, data visualisation, graphics processing units, many-core accelerator architectures, multiprocessing systems, parallel architectures, pathological dynamic architectural behaviors, performance evaluation, performance statistics, },
 abstract = {While many-core accelerator architectures, such as today's Graphics Processing Units (GPUs), offer orders of magnitude more raw computing power than contemporary CPUs, their massive parallelism often produces complex dynamic behaviors even with the simplest applications. Using a fixed set of hardware or simulator performance counters to quantify behavior over a large interval of time such as an entire application execution run or program phase may not capture this behavior. Software and/or hardware designers may consequently miss out on opportunities to optimize for better performance. Similarly, significant effort may be expended to find metrics that explain anomalous behavior in architecture design studies. Moreover, the increasing complexity of applications developed for today's GPU has created additional difficulties for software developers when attempting to identify bottlenecks of an application for optimization. This paper presents a novel GPU performance visualization tool, AerialVision, to address these two problems. It interfaces with the GPGPU-Sim simulator to capture and visualize the dynamic behavior of a GPU architecture throughout an application run. Similar to existing performance analysis tools for CPUs, it can annotate individual lines of source code with performance statistics to simplify the bottleneck identification process. To provide further insight, AerialVision introduces a novel methodology to relate pathological dynamic architectural behaviors resulting in performance loss with the part of the source code that is responsible. By rapidly providing insight into complex dynamic behavior, AerialVision enables research on improving many-core accelerator architectures and will help ensure applications written for these architectures reach their full performance potential. },
}

@inproceedings{5452028,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Jianmin Chen and Zhuo Huang and Feiqi Su and Peir, J.-K. and Ho, J. and Lu Peng},
 year = {2010},
 pages = {154--163},
 publisher = {IEEE},
 title = {Weak execution ordering - exploiting iterative methods on many-core GPUs},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452028},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452028},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452028.pdf?arnumber=5452028},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Chaotic communication, Computer graphics, Computer vision, Data communication, Iterative methods, Large-scale systems, Partial differential equations, Poisson image editing, Shape measurement, Tesla C1060, Yarn, computer graphics, computer graphics, computer vision, coprocessors, data communication, data communication equipment, host synchronization, iterative methods, iterative methods, many-core GPU, parallel thread blocks, partial differential equations, partial differential equations, shape from shading, weak execution ordering, },
 abstract = {On NVIDIA's many-core GPUs, there is no synchronization function among parallel thread blocks. When fine-granularity of data communication and synchronization is required for large-scale parallel programs executed by multiple thread blocks, frequent host synchronization are necessary, and they incur a significant overhead. In this paper, we investigate a class of applications which uses a chaotic version of iterative methods [5], [22] to obtain numerical solutions for partial differential equations (PDE). Such a fast PDE solver is parallelized on GPUs with multiple thread blocks. In this parallel implementation, although frequent data communication is needed between adjacent thread blocks, a precise order of the data communication is not necessary. Separate communication threads are used for periodically exchanging the boundary values with adjacent thread blocks through the global memory. Since a precise order of the data communication is not required, the computation and the communication threads can be overlapped to alleviate the communication overhead. Performance measurements of two popular applications, Poisson image editing from computer graphics and shape from shading from computer vision, on Tesla C1060 show that a speedup of 4-5 times is achievable for both applications in comparison with the solution using host synchronization. },
}

@inproceedings{4919630,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Bhandarkar, Dileep},
 year = {2009},
 pages = {ix--ix},
 publisher = {IEEE},
 title = {Performance analysis in the real world of on line services},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919630},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919630},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919630.pdf?arnumber=4919630},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Computer architecture, Dictionaries, Energy efficiency, Energy measurement, Instruments, Internet, Performance analysis, Power measurement, System performance, Velocity measurement, },
 abstract = {Performance analysis has always been an integral part of a computer architect's agenda. However, the term performance is used largely to measure \&#x201C;speed\&#x201D;. The dictionary defines performance more broadly as \&#x201C;the manner in which or the efficiency with which something reacts or fulfills its intended purpose\&#x201D;. In today's internet based on line computing environment, performance has taken a broader view. For example, power and energy efficiency is becoming as or more important measures of system performance as speed of computation. The industry's ability to deliver speed has outpaced the ability of most applications to consume it effectively. This talk will discuss how performance is viewed in the world of on line web services from an end user's point of view. },
}

@inproceedings{1190246,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Haskins, J.W., Jr. and Skadron, K.},
 year = {2003},
 pages = { 195-- 203},
 publisher = {IEEE},
 title = {Memory reference reuse latency: Accelerated warmup for sampled microarchitecture simulation},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190246},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190246},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190246.pdf?arnumber=1190246},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { branch predictor modeling,  cache hierarchy,  cache storage,  memory architecture,  memory reference reuse latencies,  microprocessor simulations,  parallel architectures,  performance evaluation,  simulation accuracy,  warmup times, Acceleration, Computational modeling, Computer architecture, Computer simulation, Delay, Hardware, Microarchitecture, Microprocessors, Predictive models, Throughput, },
 abstract = {This paper proposes to speedup sampled microprocessor simulations by reducing warmup times without sacrificing simulation accuracy. It exploiting the observation that of the memory references that precede a sample cluster, references that occur nearest to the cluster are more likely to be germane to the execution of the cluster itself. Hence, while modeling all cache and branch predictor interactions that precede a sample cluster would reliably establish their state, this is overkill and leads to long-running simulations. Instead, accurately establishing simulated cache and branch predictor state can be accomplished quickly by only modeling a subset of the memory references and control-flow instructions immediately preceding a sample cluster. Our technique measures memory reference reuse latencies (MRRLs) - the number of completed instructions between consecutive references to each unique memory location - and uses these data to choose a point prior to each cluster to engage cache hierarchy and branch predictor modeling. By starting cache and branch predictor modeling late in the pre-cluster instruction stream, we were able to reduce overall simulation running times by an average of 90.62\% of the maximum potential speedup (accomplished by performing no pre-cluster warmup at all), while generating an average error in IPC of less than 1\%, both relative to the IPC generated by warming up all pre-cluster cache and branch predictor interactions. },
}

@inproceedings{1190247,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Michaud, P.},
 year = {2003},
 pages = { 204-- 213},
 publisher = {IEEE},
 title = {A statistical model of skewed-associativity},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190247},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190247},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190247.pdf?arnumber=1190247},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { associativity,  cache,  cache storage,  computer architecture,  content-addressable storage,  performance evaluation,  skewed-associativity, Computer architecture, Costs, Hardware, History, Indexing, Microarchitecture, Paints, Probability, },
 abstract = {This paper presents a statistical model for explaining why skewed-associativity removes conflicts better than set-associativity. We show that, with a high probability, 2-way skewed associativity emulates full associativity for working-sets up to half the cache size, and we show that 3-way skewed-associativity is almost equivalent to full associativity. },
}

@inproceedings{4510739,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Saidi, A.G. and Binkert, N.L. and Reinhardt, S.K. and Mudge, T.},
 year = {2008},
 pages = {63--74},
 publisher = {IEEE},
 title = {Full-System Critical Path Analysis},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510739},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510739},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510739.pdf?arnumber=4510739},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Bandwidth, CPU processing power, Control systems, Hardware, I-O devices, Kernel, Linux, Linux 2.6.13 kernel, Network interfaces, Performance analysis, Protocols, Software performance, TCPIP, complex software, concurrent hardware components, control flow tracing, critical path analysis, detailed domain knowledge, finite state machines, full-system critical path analysis, hardware bottlenecks, hardware-software boundaries, hardware-software codesign, interacting state machines, iterative methods, iterative refinement, memory system, operating system kernels, optimisation, optimization, software profiling, user-kernel boundaries, },
 abstract = {Many interesting workloads today are limited not by CPU processing power but by the interactions between the CPU, memory system, I/O devices, and the complex software that ties all the components together. Optimizing these workloads requires identifying performance bottlenecks across concurrent hardware components and across multiple layers of software. Common software profiling techniques cannot account for hardware bottlenecks or situations where software overheads are hidden due to overlap with hardware operations. Critical-path analysis is a powerful approach for identifying bottlenecks in highly concurrent systems, but typically requires detailed domain knowledge to construct the required event dependence graphs. As a result, to date it has been applied only to isolated system layers (e.g., processor microarchitectures or message-passing applications). In this paper we present a novel technique for applying critical-path analysis to complex systems composed of numerous interacting state machines. We avoid tedious up-front modeling by using control-flow tracing to expose implicit software state machines automatically, and iterative refinement to add necessary manual annotations with minimal effort. By applying our technique within a full-system simulator, we achieve an integrated trace of hardware and software events with minimal perturbation. As a result, we can perform this analysis across the user/kernel and hardware/software boundaries and even across multiple systems. We apply this technique to analyzing network performance, and show that we are able to find performance bottlenecks in both hardware and software, including some surprising bottlenecks in the Linux 2.6.13 kernel. },
}

@inproceedings{4510738,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Baugh, L. and Zilles, C.},
 year = {2008},
 pages = {54--62},
 publisher = {IEEE},
 title = {An Analysis of I/O And Syscalls In Critical Sections And Their Implications For Transactional Memory},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510738},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510738},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510738.pdf?arnumber=4510738},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Cache storage, Computer science, Concurrent computing, Data structures, I/O analysis, Programming profession, Proposals, Protection, System recovery, Uncertainty, Yarn, concurrent programming, critical sections, distributed programming, distributed shared memory systems, multi-threading, multithreaded workloads, remote procedure calls, shared memory systems, side-effecting operations, storage management, syscalls analysis, transaction processing, transactional memory, },
 abstract = {Transactional memory (TM) is a scalable and concurrent way to build atomic sections. One aspect of TM that remains unclear is how side-effecting operations - that is, those which cannot be transparently undone by a TM system - should be handled. This uncertainty poses a significant barrier to the general applicability and acceptance of TM. Further, the absence of transactional workloads makes it difficult to study this aspect In this paper, we characterize the usage of I/O, and in particular system calls, within critical sections in two large applications, exploring both the actions performed and the characteristics of the critical sections in which they are performed. Shared memory programs employing critical sections are the closest approximation available to transactional workloads, so using this characterization, we attempt to reason about how the behavior we observed relates to the previous proposals for handling side-effecting operations within transactions. We find that the large majority of syscalls performed within critical sections can be handled with a range of existing techniques in a way transparent to the application developer. We also find that while side-effecting critical sections are rare, they tend to be quite long-lasting, and that many of these critical sections perform their first syscall (and thus become side-effecting) relatively early in their execution. Finally, we show that while these long-lived, side-effecting critical sections tend to execute concurrently with many critical sections on other threads, we observe little concurrency between side-effecting critical sections. },
}

@inproceedings{1190242,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Alvim Seabra dos Santos, D. and Borges Vieira, A. and Ribeiro-Neto, B. and Vale Aguiar Campos, S.},
 year = {2003},
 pages = { 156-- 165},
 publisher = {IEEE},
 title = {Performance analysis and optimization of a distributed Video on Demand service},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190242},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190242},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190242.pdf?arnumber=1190242},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { ATM network,  Video on Demand,  VoD,  VoD server,  distributed VoD service,  neighbor clients,  optimizations,  performance,  performance evaluation,  video on demand,  video servers, Analytical models, Application software, Cable TV, Cities and towns, Computer science, Hardware, Performance analysis, Video on demand, Videoconference, Watches, },
 abstract = {Video on Demand (VoD) services are very appealing these days. In this work, we discuss four distinct alternatives for the architecture of a VoD server and compare their performances under different conditions. We later used the best configuration found in our analysis to evaluate, using simulations, the performance of a distributed VoD service in an ATM network covering an area the size of a large city neighborhood. We also introduced optimizations to the system, such as anticipated delivery and retrieval of video blocks from neighbor clients. Our results indicate that a server-driven operation mode (i.e., based on cycles) is not the most appropriate choice for a variety of workloads, even when the layout is striped (a result that challenges the conventional wisdom in the field). Also, our optimization strategies increased significantly the number of clients served in the system, which in our study case represented a savings of approximately 33\% in the hardware required for the deployment of the service. },
}

@inproceedings{1190243,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Carrera, D. and Guitart, J. and Torres, J. and Ayguade, E. and Labarta, J.},
 year = {2003},
 pages = { 166-- 175},
 publisher = {IEEE},
 title = {Complete instrumentation requirements for performance analysis of Web based technologies},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190243},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190243},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190243.pdf?arnumber=1190243},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { application program interfaces,  eDragon environment,  parallel platforms,  performance analysis,  performance evaluation,  performance metrics,  software tools,  visualization tool,  web, Cameras, Computer architecture, Delay, Information analysis, Instruments, Java, Measurement, Parallel processing, Performance analysis, Throughput, },
 abstract = {In this paper we present the eDragon environment, a research platform created to perform complete performance analysis of new Web-based technologies. eDragon enables the understanding of how application servers work in both sequential and parallel platforms offering a new insight in the usage of system resources. The environment is composed of a set of instrumentation modules, a performance analysis and visualization tool and a set of experimental methodologies to perform complete performance analysis of Web-based technologies. This paper describes the design and implementation of this research platform and highlights some of its main functionalities. We will also show how a detailed analytical view can be obtained through the application of a bottom-up strategy, starting with a group of system events and advancing to more complex performance metrics using a continuous derivation process. },
}

@inproceedings{1190240,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Paul, A. and Harel, N. and Adhikari, S. and Agarwalla, B. and Ramachandran, U. and Mackenzie, K.},
 year = {2003},
 pages = { 133-- 142},
 publisher = {IEEE},
 title = {Performance study of a cluster runtime system for dynamic interactive stream-oriented applications},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190240},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190240},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190240.pdf?arnumber=1190240},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Stampede,  cluster programming system,  distributed processing,  memory allocation,  multimedia,  overhead,  performance evaluation,  pervasive computing,  processor scheduling,  runtime systems,  support mechanisms,  thread scheduler,  timing infrastructure,  ubiquitous computing, Animation, Application software, Clustering algorithms, Collaboration, Linux, Multimedia systems, Runtime, Software algorithms, Streaming media, Timing, },
 abstract = {Emerging application domains such as interactive vision, animation, and multimedia collaboration need specialized runtime systems that provide support mechanisms to enable plumbing, cross module data transfer, buffer management, synchronization and so on. Using Stampede, a cluster programming system that is designed to meet the requirements of such applications, we quantify the performance of such mechanisms. We have developed a timing infrastructure that helps tease out the time spent by an application in different layers of software, viz., the main algorithmic component, the support mechanisms, and the raw messaging. Several interesting insights have surfaced from this study. First, memory allocation does not take up a significant amount of the execution time despite the interactive and dynamic nature of the application domain. Second, the Stampede runtime adds a minimal overhead over raw messaging for structuring such applications. Third, the results suggest that the thread scheduler on Linux may be more responsive than the one on Solaris. Fourth, the messaging layer spends quite a bit of time in synchronization operations. Perhaps the most interesting result of this study is that general-purpose operating systems such as Linux and Solaris are quite adequate to meet the requirements of emerging dynamic interactive stream-oriented applications. },
}

@inproceedings{1190241,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Kounev, S. and Buchmann, A.},
 year = {2003},
 pages = { 143-- 155},
 publisher = {IEEE},
 title = {Performance modelling of distributed e-business applications using Queuing Petri Nets},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190241},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190241},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190241.pdf?arnumber=1190241},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Petri nets,  QPN,  Queuing Petri Net,  blocking,  contention,  distributed e-business,  e-business,  electronic commerce,  hardware contention,  performance analysis,  performance evaluation,  queueing theory,  scheduling,  simultaneous resource possession,  software resources,  synchronization, Application software, Capacity planning, Computer science, Hardware, Performance analysis, Petri nets, Power system modeling, Predictive models, Queueing analysis, Stochastic processes, },
 abstract = {In this paper we show how Queuing Petri Net (QPN) models can be exploited for performance analysis of distributed e-business systems. We study a real-world application, and demonstrate the benefits, in terms of modelling power and expressiveness, that QPN models provide over conventional modelling paradigms such as Queuing Networks and Petri Nets. As shown, QPNs facilitate the integration of both hardware and software aspects of system behavior in the same model. In addition to hardware contention and scheduling strategies, using QPNs one can easily model simultaneous resource possession, synchronization, blocking and contention for software resources. By validating the models presented through measurements, we show that they are not just powerful as a specification mechanism, but are also very powerful as a performance analysis and prediction tool. However, currently available tools and techniques for QPN analysis are limited. Improved solution methods, which enable larger models to be analyzed, need to be developed. By demonstrating the power of QPNs as a modelling paradigm in realistic scenarios, we hope to motivate further research in this area. },
}

@inproceedings{4510733,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Pellauer, M. and Vijayaraghavan, M. and Adler, M. and Arvind and Emer, J.},
 year = {2008},
 pages = {1--10},
 publisher = {IEEE},
 title = {Quick Performance Models Quickly: Closely-Coupled Partitioned Simulation on FPGAs},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510733},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510733},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510733.pdf?arnumber=4510733},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Artificial intelligence, Computational modeling, Computer science, Computer simulation, FPGA, FPGAs, Field programmable gate arrays, Hardware, Microprocessors, Multicore processing, Performance Modeling, Process design, Simulation, Timing, closely-coupled partitioned simulation, field programmable gate arrays, logic partitioning, logic simulation, microprocessor chips, microprocessor performance model, },
 abstract = {In this paper we explore microprocessor performance models implemented on FPGAs. While FPGAs can help with simulation speed, the increased implementation complexity can degrade model development time. We assess whether a simulator split into closely-coupled timing and functional partitions can address this by easing the development of timing models while retaining fine-grained parallelism. We give the semantics of our simulator partitioning, and discuss the architecture of its implementation on an FPGA. We describe how three timing models of vastly different target processors can use the same functional partition, and assess their performance. },
}

@inproceedings{4510732,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {},
 year = {2008},
 pages = {xiii--xiv},
 publisher = {IEEE},
 title = {Commentary},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510732},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510732},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510732.pdf?arnumber=4510732},
 isbn = {978-1-4244-2232-6},
 language = {English},
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/04510732.png" border="0"> },
}

@inproceedings{4510731,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {},
 year = {2008},
 pages = {ix--xii},
 publisher = {IEEE},
 title = {Table of Contents},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510731},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510731},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510731.pdf?arnumber=4510731},
 isbn = {978-1-4244-2232-6},
 language = {English},
 abstract = {},
}

@inproceedings{4510730,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {},
 year = {2008},
 pages = {vii--vii},
 publisher = {IEEE},
 title = {Reviewer and Referee Listings},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510730},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510730},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510730.pdf?arnumber=4510730},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {IEEE, },
 abstract = {},
}

@inproceedings{4211012,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {vi--vi},
 publisher = {IEEE},
 title = {Contributor Listings},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363726},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211012},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211012.pdf?arnumber=4211012},
 isbn = {1-4244-1082-7},
 language = {English},
 abstract = {},
}

@inproceedings{4510740,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Ram, K.K. and Fedeli, I.C. and Cox, A.L. and Rixner, S.},
 year = {2008},
 pages = {75--84},
 publisher = {IEEE},
 title = {Explaining the Impact of Network Transport Protocols on SIP Proxy Performance},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510740},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510740},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510740.pdf?arnumber=4510740},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Communication system control, Computer architecture, File servers, Internet telephony, Internet telephony, Network servers, OpenSER SIP proxy server performance, Performance loss, Scalability, Sockets, Throughput, Transport protocols, UDP/TCP, VoIP phone calls, application-layer signaling protocol, network transport protocol, session initiation protocol, signalling protocols, transport protocols, voice-over-IP, },
 abstract = {This paper characterizes the impact that the use of UDP versus TCP has on the performance and scalability of the OpenSER SIP proxy server. The session initiation protocol (SIP) is an application-layer signaling protocol that is widely used for establishing voice-over-IP (VoIP) phone calls. SIP can utilize a variety of transport protocols, including UDP and TCP. Despite the advantages of TCP, such as reliable delivery and congestion control, the common practice is to use UDP. This is a result of the belief that UDP's lower processor and network overhead results in improved performance and scalability of SIP services. This paper argues against this conventional wisdom. This paper shows that the principal reasons for OpenSER's poor performance using TCP are caused by the server's design, and not the low-level performance of UDP versus TCP. Specifically, OpenSER's architecture for handling concurrent calls is responsible for most of the difference. Moreover, once these issues are addressed, OpenSER's performance using TCP is much more competitive with its performance using UDP. },
}

@inproceedings{4510735,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Falcon, A. and Faraboschi, P. and Ortega, D.},
 year = {2008},
 pages = {22--31},
 publisher = {IEEE},
 title = {An Adaptive Synchronization Technique for Parallel Simulation of Networked Clusters},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510735},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510735},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510735.pdf?arnumber=4510735},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {8-node cluster running NAMD, Computational modeling, Computer networks, Computer simulation, Concurrent computing, Discrete event simulation, High performance computing, Laboratories, Parallel machines, Switches, Timing, adaptive synchronization, computer clusters, cost-effective approach, discrete event simulation, high performance computing, molecular dynamics method, networked clusters, parallel discrete event simulation, parallel molecular dynamics application, parallel programming, parallel simulation, parallel simulators, synchronisation, workstation clusters, },
 abstract = {Computer clusters are a very cost-effective approach for high performance computing, but simulating a complete cluster is still an open research problem. The obvious approach - to parallelize individual node simulators - is complex and slow. Combining individual parallel simulators implies synchronizing their progress of time. This can be accomplished with a variety of parallel discrete event simulation techniques, but unfortunately any straightforward approach introduces a synchronization overhead causing up two orders of magnitude of slowdown with respect to the simulation speed of an individual node. In this paper we present a novel adaptive technique that automatically adjusts the synchronization boundaries. By dynamically relaxing accuracy over the least interesting computational phases we dramatically increase performance with a marginal loss of precision. For example, in the simulation of an 8-node cluster running NAMD (a parallel molecular dynamics application) we show an acceleration factor of 26x over the deterministic "ground truth" simulation, at less than a 1\% accuracy error. },
}

@inproceedings{1190249,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {},
 year = {2003},
 pages = { 223-- 223},
 publisher = {IEEE},
 title = {Author Index},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190249},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190249},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190249.pdf?arnumber=1190249},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01190249.png" border="0"> },
}

@inproceedings{990688,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Yue Luo and John, L.K.},
 year = {2001},
 pages = {128--136},
 publisher = {IEEE},
 title = {Workload characterization of multithreaded java servers},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990688},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990688},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990688.pdf?arnumber=990688},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Application software, Decision support systems, Java, Microarchitecture, Multithreading, Scalability, Sun, Virtual manufacturing, Web server, Yarn, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990688.png" border="0"> },
}

@inproceedings{990682,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Iancu, C. and Acharya, A.},
 year = {2001},
 pages = {93--102},
 publisher = {IEEE},
 title = {An evaluation of search tree techniques in the presence of caches},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990682},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990682},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990682.pdf?arnumber=990682},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Algorithm design and analysis, Bridges, Computer science, Frequency, Guidelines, Performance analysis, Prediction algorithms, Random access memory, Tree graphs, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990682.png" border="0"> },
}

@inproceedings{990681,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Skotiniotis, T. and Chang, M.J.},
 year = {2001},
 pages = {85--92},
 publisher = {IEEE},
 title = {Estimating internal memory fragmentation for java programs under the binary buddy policy},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990681},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990681},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990681.pdf?arnumber=990681},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Computer science, Educational institutions, Heuristic algorithms, Java, Memory management, Object oriented modeling, Performance analysis, Programming profession, Testing, Virtual machining, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990681.png" border="0"> },
}

@inproceedings{990687,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Vandierendonck, H. and De Bosschere, K.},
 year = {2001},
 pages = {120--127},
 publisher = {IEEE},
 title = {Efficient profile-based evaluation of randomising set index functions for cache memories},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990687},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990687},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990687.pdf?arnumber=990687},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Analytical models, Cache memory, Clocks, Degradation, Design optimization, Extrapolation, Hardware, Information systems, Null space, Performance analysis, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990687.png" border="0"> },
}

@inproceedings{990684,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Coleman, C.L. and Davidson, J.W.},
 year = {2001},
 pages = {103--110},
 publisher = {IEEE},
 title = {Automatic memory hierarchy characterization},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990684},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990684},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990684.pdf?arnumber=990684},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Computer science, Delay, Design optimization, Documentation, Electronic mail, Lifting equipment, Optimizing compilers, Performance analysis, Size measurement, Timing, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990684.png" border="0"> },
}

@inproceedings{990685,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Tsozen Yeh and Long, D.D.E. and Brandt, S.A.},
 year = {2001},
 pages = {111--119},
 publisher = {IEEE},
 title = {Using program and user information to improve file prediction performance},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990685},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990685},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990685.pdf?arnumber=990685},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Accuracy, Bandwidth, Cache memory, Computer science, History, Lifting equipment, Prediction algorithms, Predictive models, Prefetching, System performance, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990685.png" border="0"> },
}

@inproceedings{4211030,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Chang-Burm Cho and Tao Li},
 year = {2007},
 pages = {136--145},
 publisher = {IEEE},
 title = {Using Wavelet Domain Workload Execution Characteristics to Improve Accuracy, Scalability and Robustness in Program Phase Analysis},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363744},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211030},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211030.pdf?arnumber=4211030},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Application software, Computer architecture, Design optimization, Robustness, Runtime, SPEC CPU 2000 benchmark, Scalability, Statistical analysis, Time domain analysis, Wavelet analysis, Wavelet domain, computer architecture, computer architecture design, computer architecture optimization, phase classification accuracy, program diagnostics, program execution statistics, program execution variability, program phase analysis, runtime workload execution characteristics, sampled workload statistics, scalable phase analysis, time domain, wavelet denoising, wavelet domain phase analysis, wavelet transform, wavelet transforms, workload execution statistics, },
 abstract = {Program phase analysis has many applications in computer architecture design and optimization. Recently, there has been a growing interest in employing wavelets as a tool for phase analysis. Nevertheless, the examined scope of workload characteristics and the explored benefits due to wavelet-based analysis are quite limited. This work further extends prior research by applying wavelets analysis to abundant types of program execution statistics and quantifying the benefits of wavelet analysis in terms of accuracy, scalability and robustness in phase classification. Experimental results on SPEC CPU 2000 benchmarks show that compared with methods that work in the time domain, wavelet domain phase analysis achieves higher accuracy and exhibits superior scalability and robustness. We examine and contrast the effectiveness of applying wavelets to a wide range of runtime workload execution characteristics. We find that wavelet transform significantly reduces temporal dependence in the sampled workload statistics and therefore simple models which are insufficient in the time domain become quite accurate in the wavelet domain. More attractively, we show that different types of workload execution characteristics in wavelet domain can be assembled together to further improve phase classification accuracy. For long-running, complex and real-world workloads, a scalable phase analysis technique is essential to capture the manifested large-scale program behavior. In this study, we show that such scalability can be achieved by applying wavelet analysis of high dimension sampled workload statistics to alleviate the counter overflow problem which can negatively affect phase classification accuracy. By exploiting the wavelet denoising capability, we show in this paper that phase classification can be performed robustly under program execution variability. To our knowledge, this work presents the first effort on using wavelets to improve scalability and robustness in phase analysis },
}

@inproceedings{842295,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Wolf, T. and Franklin, M.},
 year = {2000},
 pages = {154--162},
 publisher = {IEEE},
 title = {CommBench-a telecommunications benchmark for network processors},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842295},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842295},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842295.pdf?arnumber=842295},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Application specific integrated circuits, CommBench, Costs, GSM, Logic, Petroleum, Process design, Programmable control, Routing, Transcoding, Virtual colonoscopy, benchmark applications, cache performance, cache storage, computational complexity, computational complexity, computationally intense program kernels, data stream processing, instruction frequencies, network processor environment, network processors, packet header processing, performance evaluation, single chip network multiprocessor, standard SPEC benchmark, telecommunication computing, telecommunication network reliability, telecommunications benchmark, telecommunications network processor design, },
 abstract = {The paper presents a benchmark, CommBench, for use in evaluating and designing telecommunications network processors. The benchmark applications focus on small, computationally intense program kernels typical of the network processor environment. The benchmark is composed of eight programs, four of them oriented towards packet header processing and four oriented towards data stream processing. The benchmark is defined and characteristics such as instruction frequencies, computational complexity, and cache performance are presented. These measured characteristics are compared to the standard SPEC benchmark. Three examples are presented indicating how CommBench can aid in the design of a single chip network multiprocessor },
}

@inproceedings{1430568,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Lau, J. and Perelman, E. and Hamerly, G. and Sherwood, T. and Calder, B.},
 year = {2005},
 pages = {135--146},
 publisher = {IEEE},
 title = {Motivation for Variable Length Intervals and Hierarchical Phase Behavior},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430568},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430568},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430568.pdf?arnumber=1430568},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computer science, Counting circuits, Frequency, Hardware, Large-scale systems, Machine learning, Optimizing compilers, Phase detection, SimPoint, hierarchical phase behavior, multi-threading, program compilers, program control structures, program diagnostics, program execution, program periodic phase behavior, variable length interval, },
 abstract = {Most programs are repetitive, where similar behavior can be seen at different execution times. Proposed algorithms automatically group similar portions of a program's execution into phases, where the intervals in each phase have homogeneous behavior and similar resource requirements. These prior techniques focus on fixed length intervals (such as a hundred million instructions) to find phase behavior. Fixed length intervals can make a program's periodic phase behavior difficult to find, because the fixed interval length can be out of sync with the period of the program's actual phase behavior. In addition, a fixed interval length can only express one level of phase behavior. In this paper, we graphically show that there exists a hierarchy of phase behavior in programs and motivate the need for variable length intervals. We describe the changes applied to SimPoint to support variable length intervals. We finally conclude by providing an initial study into using variable length intervals to guide SimPoint },
}

@inproceedings{1430569,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Ram Srinivasan and Cook, J. and Cooper, S.},
 year = {2005},
 pages = {147--156},
 publisher = {IEEE},
 title = {Fast, Accurate Microarchitecture Simulation Using Statistical Phase Detection},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430569},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430569},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430569.pdf?arnumber=1430569},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Algorithm design and analysis, Cost function, Microarchitecture, Phase detection, Robustness, Sampling methods, Space exploration, Statistics, Timing, Velocity measurement, benchmark testing, computer architecture, digital simulation, instruction sets, instructions committed per cycle, microarchitecture simulation, processor configuration, statistical analysis, statistical phase detection, },
 abstract = {Simulation-based microarchitecture research is often hindered by the slow speed of simulators. In this work, we propose a novel statistical technique to identify highly representative unique behaviors or phases in a benchmark based on its IPC (instructions committed per cycle) trace. By simulating the timing of only the unique phases, the cycle-accurate simulation time for the SPEC suite is reduced from 5 months to 5 days, with a significant retention of the original dynamic behavior. Evaluation across many processor configurations within the same architecture family shows that the algorithm is robust. A cost function is provided that enables users to easily optimize the parameters of the algorithm for either simulation speed or accuracy depending on preference. A new measure is introduced to quantify the ability of a simulation speedup technique to retain behavior realized in the original workload. Unlike a first order statistic such as mean value, the newly introduced measure captures important differences in dynamic behavior between the complete and the sampled simulations },
}

@inproceedings{1291343,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {John, L.K.},
 year = {2004},
 pages = { iv-- iv},
 publisher = {IEEE},
 title = {Program Chair's Message},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291343},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291343},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291343.pdf?arnumber=1291343},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{4211037,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Jimenez-Gonzalez, D. and Martorell, X. and Ramirez, A.},
 year = {2007},
 pages = {210--219},
 publisher = {IEEE},
 title = {Performance Analysis of Cell Broadband Engine for High Memory Bandwidth Applications},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363751},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211037},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211037.pdf?arnumber=4211037},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Application software, Bandwidth, Computer architecture, DMA controller, Electronic mail, Engines, Instruction sets, Microwave integrated circuits, Performance analysis, Random access memory, Registers, arithmetic performance analysis, bandwidth performance peak, cell broadband engine, data stream, direct memory access, element interconnect bus, memory bandwidth application, message passing interface, parallel processing, processor component, processor speed, single instruction multiple data, storage management, streaming programming model, synergistic processor element, },
 abstract = {The cell broadband engine (CBE) is designed to be a general purpose platform exposing an enormous arithmetic performance due to its eight SIMD-only synergistic processor elements (SPEs), capable of achieving 134.4 GFLOPS (16.8 GFLOPS * 8) at 2.1 GHz, and a 64-bit power processor element (PPE). Each SPE has a 256Kb non-coherent local memory, and communicates to other SPEs and main memory through its DMA controller. CBE main memory is connected to all the CBE processor elements (PPE and SPEs) through the element interconnect bus (EIB), which has a 134.4 GB/s bandwidth performance peak at half the processor speed. Therefore, CBE platform is suitable to be used by applications using MPI and streaming programming models with a potential high performance peak. In this paper we focus on the communication part of those applications, and measure the actual memory bandwidth that each of the CBE processor components can sustain. We have measured the sustained bandwidth between PPE and memory, SPE and memory, two individual SPEs to determine if this bandwidth depends on their physical location, pairs of SPEs to achieve maximum bandwidth in nearly-ideal conditions, and in a cycle of SPEs representing a streaming kind of computation. Our results on a real machine show that following some strict programming rules, individual SPE to SPE communication almost achieves the peak bandwidth when using the DMA controllers to transfer memory chunks of at least 1024 Bytes. In addition, SPE to memory bandwidth should be considered in streaming programming. For instance, implementing two data streams using 4 SPEs each can be more efficient than having a single data stream using the 8 SPEs },
}

@inproceedings{1430562,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Ekman, M. and Stenstrom, P.},
 year = {2005},
 pages = {89--99},
 publisher = {IEEE},
 title = {Enhancing Multiprocessor Architecture Simulation Speed Using Matched-Pair Comparison},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430562},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430562},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430562.pdf?arnumber=1430562},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Arm, Computational modeling, Computer architecture, Computer science, Computer simulation, Gaussian distribution, Multiprocessing systems, SMARTS statistical sampling technique, Sampling methods, Statistical analysis, benchmark testing, computer architecture, digital simulation, instruction sets, matched-pair comparison, multi-threaded application, multi-threading, multiprocessing systems, multiprocessor architecture simulation, multiprocessor system, sampling methods, },
 abstract = {While cycle-level, full-system architecture simulation tools are capable of estimating performance at arbitrary accuracy, the time to simulate an entire application is usually prohibitive. Moreover, simulating multi-threaded applications further exacerbates this problem as most simulation tools are single-threaded. Recently, statistical sampling techniques, such as SMARTS, have managed to bring down the simulation time significantly by making it possible to only simulate about 1\% of the code with sufficient accuracy. However, thousands of simulation points throughout the benchmark must still be simulated. First of all, we propose to use the well-established statistical method matched-pair comparison and motivate why this will bring down the number of simulation points needed to achieve a given accuracy. We apply it to single-processor as well as multiprocessor simulation and show that it is capable of reducing the number of needed simulation points by one order of magnitude. Secondly, since we apply the technique to single- as well as multiprocessors, we study for the first time the efficiency of statistical sampling techniques in multiprocessor systems to establish a baseline to compare with. We show theoretically and confirm experimentally, that while the instruction throughput vary significantly on each individual processor, the variability of instruction throughput across processors in a multiprocessor system decreases as we increase the number of processors for some important workloads. Thus, a factor of P fewer simulation points, where P is the number of processors, are needed to begin with when sampling is applied to multiprocessors },
}

@inproceedings{1430563,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = { Altman, E.},
 year = {2005},
 pages = { 100-- 100},
 publisher = {IEEE},
 title = {Panel Discussion},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430563},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430563},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430563.pdf?arnumber=1430563},
 isbn = {0-7803-8965-4},
 language = {English},
 abstract = {},
}

@inproceedings{1430560,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Barr, K.C. and Pan, H. and Zhang, M. and Asanovic, K.},
 year = {2005},
 pages = {66--77},
 publisher = {IEEE},
 title = {Accelerating Multiprocessor Simulation with a Memory Timestamp Record},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430560},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430560},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430560.pdf?arnumber=1430560},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Acceleration, Artificial intelligence, Checkpointing, Computational modeling, Computer science, Laboratories, Microarchitecture, Multiprocessing systems, Predictive models, Sampling methods, benchmark testing, cache storage, checkpointing, directory-based cache-coherent multiprocessor, fast forwarding, memory reference pattern, memory timestamp record, multi-threading, multiprocessing systems, multiprocessor simulation, multithreading, parallel architectures, },
 abstract = {We introduce a fast and accurate technique for initializing the directory and cache state of a multiprocessor system based on a novel software structure called the memory timestamp record (MTR). The MTR is a versatile, compressed snapshot of memory reference patterns which can be rapidly updated during fast-forwarded simulation, or stored as part of a checkpoint. We evaluate MTR using a full-system simulation of a directory-based cache-coherent multiprocessor running a range of multithreaded workloads. Both MTR and a multiprocessor version of functional fast-forwarding (FFW) make similar performance estimates, usually within 15\% of our detailed model. In addition to other benefits, we show that MTR has up to a 1.45x speedup over FFW, and a 7.7x speedup over our detailed baseline },
}

@inproceedings{1430561,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Ringenberg, J. and Pelosi, C. and Oehmke, D. and Mudge, T.},
 year = {2005},
 pages = {78--88},
 publisher = {IEEE},
 title = {Intrinsic Checkpointing: A Methodology for Decreasing Simulation Time Through Binary Modification},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430561},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430561},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430561.pdf?arnumber=1430561},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Analytical models, Benchmark testing, Checkpointing, Computational modeling, Computer science, Computer simulation, Environmental economics, Hardware design languages, Microarchitecture, benchmark testing, benchmarking, binary modification, checkpointing, computer architecture, instruction set, instruction sets, intrinsic checkpointing, microarchitecture simulation, microprocessor chips, },
 abstract = {With the proliferation of benchmarks available today, benchmarking new designs can significantly impact overall development time. In order to fully test and represent a typical workload, a large number of benchmarks must be run, and while current techniques such as SimPoint and SMARTS have had considerable success reducing simulation time, there are still areas of improvement. This paper details a methodology that continues to decrease this simulation time by analyzing and augmenting benchmark binaries to contain intrinsic checkpoints that allow for the rapid execution of important portions of code thereby removing the need for explicit checkpointing support. In addition, these modified binaries have increased portability across multiple simulation environments and the ability to be run in a highly parallel fashion. Average speedups for SPEC2000 of roughly 60x are seen over a standard SimPoint interval of 100 million instructions corresponding to a reduction in simulation time from 3.13 hours down to 3 minutes },
}

@inproceedings{1430566,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {El-Moursy, A. and Garg, R. and Albonesi, D.H. and Dwarkadas, S.},
 year = {2005},
 pages = {112--123},
 publisher = {IEEE},
 title = {Partitioning Multi-Threaded Processors with a Large Number of Threads},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430566},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430566},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430566.pdf?arnumber=1430566},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computer science, Hardware, IPC performance, L1 Dcache bank, Laboratories, Multithreading, Power dissipation, Process design, Surface-mount technology, System-on-a-chip, Throughput, Yarn, cache storage, chip multiprocessor, clustered multithreaded processor, design complexity, hyper-threaded Pentium 4 processor, instruction sets, monolithic hardware structures, multi-threaded processor partitioning, multi-threading, parallel architectures, performance evaluation, power dissipation, resource allocation, simultaneous multi-threading, superscalar processor, system-on-chip, wire scaling limitation, },
 abstract = {Today's general-purpose processors are increasingly using multithreading in order to better leverage the additional on-chip real estate available with each technology generation. Simultaneous multi-threading (SMT) was originally proposed as a large dynamic superscalar processor with monolithic hardware structures shared among all threads. Inters hyper-threaded Pentium 4 processor partitions the queue structures among two threads, demonstrating more balanced performance by reducing the hoarding of structures by a single thread. IBM's Power5 processor is a 2-way chip multiprocessor (CMP) of SMT processors, each supporting 2 threads, which significantly reduces design complexity and can improve power efficiency. This paper examines processor partitioning options for larger numbers of threads on a chip. While growing transistor budgets permit four and eight-thread processors to be designed, design complexity, power dissipation, and wire scaling limitations create significant barriers to their actual realization. We explore the design choices of sharing, or of partitioning and distributing, the front end (instruction cache, instruction fetch, and dispatch), the execution units and associated state, as well as the L1 Dcache banks, in a clustered multi-threaded (CMT) processor. We show that the best performance is obtained by restricting the sharing of the L1 Dcache banks and the execution engines among threads. On the other hand, significant sharing of the front-end resources is the best approach. When compared against large monolithic SMT processors, a CMT processor provides very competitive IPC performance on average, 90-96\% of that of partitioned SMT while being more scalable and much more power efficient. In a CMP organization, the gap between SMT and CMT processors shrinks further, making a CMP of CMT processors a highly viable alternative for the future },
}

@inproceedings{1430567,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Li, J. and Martinez, J.F.},
 year = {2005},
 pages = {124--134},
 publisher = {IEEE},
 title = {Power-Performance Implications of Thread-level Parallelism on Chip Multiprocessors},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430567},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430567},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430567.pdf?arnumber=1430567},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Analytical models, CMOS technology, Energy consumption, Equations, Frequency, Microprocessors, Parallel processing, Scalability, System-on-a-chip, Voltage, multi-threading, on chip multiprocessor, parallel architectures, parallel code, power consumption, power consumption, power-performance implication, system-on-chip, thread-level parallelism, },
 abstract = {We discuss power-performance implications of running parallel applications on chip multiprocessors (CMPs). First, we develop an analytical model that, for the first time, puts together parallel efficiency, granularity, and voltage/frequency scaling, to quantify the performance and power consumption, delivered by a CMP running a parallel code. Then, we conduct detailed simulations of parallel applications running on a power-performance CMP model. Our experiments confirm that our analytical model predicts power-performance behavior reasonably well. Both analytical and experimental models show that parallel computing can bring significant power savings and still meet a given performance target, by choosing granularity and voltage/frequency levels judiciously. The particular choice, however, is dependent on the application's parallel efficiency curve and the process technology utilized, which our model captures. Likewise, analytical model and experiments show the effect of a limited power budget on the application's scalability curve. In particular, we show that a limited power budget can cause a rapid performance degradation beyond a number of cores, even in the case of applications with excellent scalability properties. On the other hand, our experiments show that power-thrifty memory-bound applications can actually enjoy better scalability than more "nominally scalable" applications (i.e., without regard to power) when a limited power budget is in place },
}

@inproceedings{1430564,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Conte, T.},
 year = {2005},
 pages = {101--101},
 publisher = {IEEE},
 title = {Keynote Talk #2},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430564},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430564},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430564.pdf?arnumber=1430564},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {embedded systems, embedded systems, multi-threading, multi-threading, multiprogramming, multiprogramming, parallel architectures, parallel architectures, },
 abstract = {Summary form is only given. Hamming said, "The purpose of computing is insight, not numbers," yet this conference, like many today, is awash only in numbers. These numbers are perhaps more strategic than insightful. The numbers are used by designers, who want to prove their invention is better than the status quo. Then there are marketers, who want to prove their product's the one to buy over the competition. And then there are the users, who quite frankly are not getting much insight out of any of this. This talk will step back and discuss two aspects of insightful computing: who speaks for the users, and how much we should trust our numbers },
}

@inproceedings{1430565,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Huang, W. and Lin, J. and Zhang, Z. and Chang, J.M.},
 year = {2005},
 pages = {102--111},
 publisher = {IEEE},
 title = {Performance Characterization of Java Applications on SMT Processors},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430565},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430565},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430565.pdf?arnumber=1430565},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Application software, Computer languages, Counting circuits, Intel Pentium 4 hyper-threading processor, Java, Java, Java application, Multithreading, Performance loss, Pipelines, Programming, Surface-mount technology, Yarn, benchmark testing, microarchitecture metrics, multi-threading, multiprogrammed Java benchmark, multiprogramming, parallel architectures, performance evaluation, pipeline inefficiency, pipeline processing, resource allocation, resource contention, simultaneous multithreading processors, software development, },
 abstract = {As Java is emerging as one of the major programming languages in software development, studying how Java applications behave on recent SMT processors is of great interest. This paper characterizes the performance of Java applications on an Intel Pentium 4 hyper-threading processor. Using the performance counters provided by Pentium 4, we quantitatively evaluate micro-architecture metrics while running various types of Java applications. The experimental results reveal that: (1) Hyper-threading can indeed improve the performance of multithreaded Java programs; (2) The resource contentions within Pentium 4 are the major reason of pipeline inefficiency, which prevents better performance promised by SMT; (3) The static partition design of hyper-threading causes considerable performance loss for many single-thread Java programs; (4) Most multiprogrammed Java benchmarks can achieve decent combined speedups on hyper-threading processors },
}

@inproceedings{990677,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Buch, D.K. and Pentkovski, V.M.},
 year = {2001},
 pages = {57--64},
 publisher = {IEEE},
 title = {Performance characterization experience of multi-tier e-business systems using queuing operational analysis},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990677},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990677},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990677.pdf?arnumber=990677},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Equations, Java, Middleware, Performance analysis, Queueing analysis, Software systems, Stress, System performance, Transaction databases, Web server, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990677.png" border="0"> },
}

@inproceedings{990676,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Kant, K. and Tewari, V. and Iyer, R.},
 year = {2001},
 pages = {49--56},
 publisher = {IEEE},
 title = {Geist: a generator for e-commerce & internet server traffic},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990676},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990676},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990676.pdf?arnumber=990676},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Aggregates, Character generation, IP networks, Internet, Network servers, Stress, Surges, Telecommunication traffic, Testing, Web server, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990676.png" border="0"> },
}

@inproceedings{990675,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Petit, S. and Sahuquillo, J. and Pont, A.},
 year = {2001},
 pages = {45--48},
 publisher = {IEEE},
 title = {About the sensitivity of the HLRC-DU protocol on diff and page sizes},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990675},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990675},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990675.pdf?arnumber=990675},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Bandwidth, Delay, Distributed computing, Environmental economics, Multiprocessing systems, Operating systems, Protocols, Software maintenance, Software performance, Support vector machines, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990675.png" border="0"> },
}

@inproceedings{990674,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Yang Qian and Srisa-an, W. and Skotiniotis, T. and Chang, J.M.},
 year = {2001},
 pages = {38--44},
 publisher = {IEEE},
 title = {Cycle accurate thread timer for linux environment},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990674},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990674},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990674.pdf?arnumber=990674},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Application software, Clocks, Communication networks, Filters, Kernel, Linux, Performance analysis, Time measurement, Timing, Yarn, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990674.png" border="0"> },
}

@inproceedings{5452034,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Yan Cui and Yu Chen and Yuanchun Shi},
 year = {2010},
 pages = {134--143},
 publisher = {IEEE},
 title = {Scaling OLTP applications on commodity multi-core platforms},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452034},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452034},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452034.pdf?arnumber=5452034},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Computer architecture, Databases, Kernel, Libraries, Moore law, Moore's Law, Multicore processing, RCU-based IDR API, Scalability, Software performance, Throughput, commodity multicore platforms, data mining, database synchronization, kernel scheduler, microprocessor chips, multicore processor architectures, multiprocessing systems, online transaction processing, processor chip, processor complexity, single core designs, sysbench-OLTP, },
 abstract = {Multi-core processor architectures can have significant performance advantage over traditional single core designs, which are limited by power and processor complexity. Predictions based on Moore's Law state that a processor chip may accommodate thousands of cores in 5-10 years. Can software scale with the number of cores and achieve the performance potential? This paper uses two OLTP (online transaction processing) applications (TPCC-UVa and Sysbench-OLTP) as a case study to investigate this question and determine what the performance bottlenecks are. On an Intel 8-core platform, these applications (with slight modifications to run well on a many-core platform) achieve a speedup (in terms of the transaction throughput) of 3.68 and 5.26, respectively. To find the scalability bottlenecks the paper proposes a method based on function's scalability value metric. Functions with a high scalability value limit the scalability. By looking at the functions with the highest scalability value across all functions in the kernel, libraries, and application processes, the paper finds that database buffer pool contention, database synchronization primitives, scheduler overhead and lock contention in System V IPC are the main bottlenecks for TPCC-UVa. In Sysbench-OLTP, database synchronization primitives and the kernel scheduler limit scalability. The paper also explores several ideas such as scalable database lock, scalable spin lock and RCU-based IDR API to improve the scalability. },
}

@inproceedings{990672,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Terrasa, A. and Paches, I. and Garcia-Fornes, A.},
 year = {2001},
 pages = {30--37},
 publisher = {IEEE},
 title = {An evaluation of the POSIX trace standard implemented in RT-linux},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990672},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990672},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990672.pdf?arnumber=990672},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Application software, Event detection, Kernel, Linux, Monitoring, Operating systems, Real time systems, Runtime, Standards development, Timing, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990672.png" border="0"> },
}

@inproceedings{990671,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Peng Li and Ravindran, B. and Hegazy, T.},
 year = {2001},
 pages = {22--29},
 publisher = {IEEE},
 title = {Implementation and evaluation of a best-effort scheduling algorithm in an embedded real-time system},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990671},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990671},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990671.pdf?arnumber=990671},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Aggregates, Analytical models, Degradation, Neodymium, Operating systems, Predictive models, Real time systems, Regression analysis, Scheduling algorithm, System performance, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990671.png" border="0"> },
}

@inproceedings{990670,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Weaver, C. and Barr, K.C. and Marsman, E. and Ernst, D. and Austin, T.},
 year = {2001},
 pages = {18--21},
 publisher = {IEEE},
 title = {Performance analysis using pipeline visualization},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990670},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990670},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990670.pdf?arnumber=990670},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Computational modeling, Computer architecture, Displays, Hardware, Laboratories, Microprocessors, Performance analysis, Pipelines, Statistics, Visualization, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990670.png" border="0"> },
}

@inproceedings{1291345,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 pages = { vi-- vi},
 publisher = {IEEE},
 title = {ISSPASS Reviewers},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291345},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291345},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291345.pdf?arnumber=1291345},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{1291344,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 pages = { v-- v},
 publisher = {IEEE},
 title = {ISPASS-2004 People},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291344},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291344},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291344.pdf?arnumber=1291344},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = {Finance, Organizing, Sun, },
 abstract = {},
}

@inproceedings{1291347,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 pages = { x-- x},
 publisher = {IEEE},
 title = {Blank Page},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291347},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291347},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291347.pdf?arnumber=1291347},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{1291346,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 pages = { vii-- ix},
 publisher = {IEEE},
 title = {Table of Contents - ISPASS},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291346},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291346},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291346.pdf?arnumber=1291346},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{1291341,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 pages = { ii-- ii},
 publisher = {IEEE},
 title = {Copyright},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291341},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291341},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291341.pdf?arnumber=1291341},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{1291340,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 publisher = {IEEE},
 title = {2004 IEEE International Symposium on Performance Analysis of Systems and Software (IEEE Cat. No.04EX818)},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291340},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291340},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291340.pdf?arnumber=1291340},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { Java,  Java,  architecture evaluation,  benchmark testing,  benchmarking,  caches,  memory,  memory architecture,  performance evaluation,  performance evaluation,  power consumption,  power estimation,  power reduction,  simulation,  simulation,  software performance analysis,  storage management,  system performance analysis,  workload characterization, },
 abstract = {},
}

@inproceedings{990679,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Co, M. and Skadron, K.},
 year = {2001},
 pages = {77--84},
 publisher = {IEEE},
 title = {The effects of context switching on branch predictor performance},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990679},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990679},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990679.pdf?arnumber=990679},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Accuracy, Computer science, Context modeling, Operating systems, Parallel processing, Predictive models, Switches, Testing, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990679.png" border="0"> },
}

@inproceedings{990678,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Tao Li and John, L.K.},
 year = {2001},
 pages = {65--76},
 publisher = {IEEE},
 title = {Understanding control flow transfer and its predictability in java processing},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990678},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990678},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990678.pdf?arnumber=990678},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Application software, Computer architecture, Hardware, Java, Kernel, Laboratories, Microprocessors, Predictive models, Runtime, Virtual machining, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990678.png" border="0"> },
}

@inproceedings{1190233,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Dongara, P. and Vijaykumar, T.N.},
 year = {2003},
 pages = { 58-- 69},
 publisher = {IEEE},
 title = {Accelerating private-key cryptography via multithreading on symmetric multiprocessors},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190233},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190233},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190233.pdf?arnumber=1190233},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { cryptographic processing,  cryptography,  interleaved chaining,  multi-threading,  multiprocessing systems,  multithreading,  private key,  security assurance,  symmetric multiprocessors, Acceleration, High performance computing, Information security, Microprocessors, Modems, Multithreading, Parallel processing, Public key, Public key cryptography, System performance, },
 abstract = {Achieving high performance in cryptographic processing is important due to the increasing connectivity among today's computers. Despite steady improvements in microprocessor and system performance, private-key cipher implementations continue to be slow. Irrespective of the cipher used, the main reason for the low performance is lack of parallelism, which fundamentally comes from encryption modes such as the Cipher Block Chaining (CBC) mode. In CBC, each plaintext block is XOR'ed with the previous ciphertext block and then encrypted, essentially inducing a tight recurrence through the ciphertext blocks. To deliver high performance while maintaining high level of security assurance in real systems, the cryptography community has proposed Interleaved Cipher Block Chaining (ICBC) mode. In four-way interleaved chaining, the first, fifth, and every fourth block thereafter are encrypted in CBC mode; the second, sixth, and every fourth block thereafter are encrypted as another stream, and so on. Thus, interleaved chaining loosens the recurrence imposed by CBC, enabling the multiple encryption streams to be overlapped. The number of interleaved chains can be chosen to balance performance and adequate chaining to get good data diffusion. While ICBC was originally proposed to improve hardware encryption rates by employing multiple encryption chips in parallel, this is the first paper to evaluate ICBC via multithreading commonly-used ciphers on a symmetric multiprocessor (SMP). ICBC allows exploiting the full processing power of SMPs, which spend many cycles in cryptographic processing as medium-scale servers today, and will do so as chip-multiprocessor clients in the future. Using the Wisconsin Wind Tunnel II, we show that our multithreaded ciphers achieve encryption rates of 92 Mbytes/s on a 16-processor SMP at 1 GHz, reaching a factor of almost 10 improvement oiler a uniprocessor, which achieves 9 Mbytes/s. },
}

@inproceedings{4510729,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {},
 year = {2008},
 pages = {iii--vi},
 publisher = {IEEE},
 title = {Commentary},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510729},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510729},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510729.pdf?arnumber=4510729},
 isbn = {978-1-4244-2232-6},
 language = {English},
 abstract = {},
}

@inproceedings{1190231,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Geyong Min and Ould-Khaoua, M.},
 year = {2003},
 pages = { 39-- 48},
 publisher = {IEEE},
 title = {Mathematical modelling of adaptive wormhole routing in the presence of self-similar traffic},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190231},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190231},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190231.pdf?arnumber=1190231},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Markov processes,  Markov-modulated Poisson processes,  adaptive wormhole routing,  analytical performance model,  mathematical modelling,  multiprocessor interconnection networks,  network performance,  performance evaluation,  queueing performance,  self-similar traffic,  telecommunication network routing,  torus interconnection networks, Analytical models, Autocorrelation, Communication system traffic, Mathematical model, Performance analysis, Routing, Stochastic processes, System performance, Telecommunication traffic, Traffic control, },
 abstract = {The properties of self-similar traffic have strong effects on queueing performance. It has been suggested that many existing computer and communication systems need to be reevaluated in the presence of this new type of traffic. To this end, this paper proposes an analytical performance model for adaptive wormhole routing in torus interconnection networks under self-similar traffic. The bursty characteristic of traffic over multiple time scales is captured by the superposition of a number of two-state Markov-modulated poisson processes (MMPPs). Simulation experiments demonstrate that the proposed model exhibits a good degree of accuracy for various system sizes and under different operating conditions. The analytical model is then used to investigate the impact of the important parameter of traffic self-similarity on network performance. },
}

@inproceedings{1190230,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Murta, C.D. and Augusto, M.E.},
 year = {2003},
 pages = { 32-- 38},
 publisher = {IEEE},
 title = {Empirical evaluation of capacity estimation tools},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190230},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190230},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190230.pdf?arnumber=1190230},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Internet,  bandwidth estimation,  bprobe,  capacity estimation tools,  capacity management (computers),  clink,  empirical evaluation,  nettimer,  pathrate,  pchar,  software development management, Bandwidth, Internet, Monitoring, Network servers, Network topology, Quality of service, Robustness, Telecommunication traffic, Web server, },
 abstract = {Bandwidth estimation is an important task because the knowledge of the bandwidth of a path is useful in a wide variety of contexts. Clients, applications and servers benefit greatly from knowing the bandwidth of a route. In this paper we describe and discuss experiments carried out to provide bandwidth estimates using five tools: bprobe, clink, nettimer pathrate, and pchar The tools are evaluated and compared according to the criteria accuracy, statistical robustness and time to estimation. We show several results for short and long network paths. The topologies tested include links which capacities range from 2 Mb/s to 1 Gb/s. },
}

@inproceedings{1190237,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Becerra, Y. and Cortes, T. and Garcia, J. and Navarro, N.},
 year = {2003},
 pages = { 101-- 110},
 publisher = {IEEE},
 title = {Evaluating the importance of virtual memory for Java},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190237},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190237},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190237.pdf?arnumber=1190237},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Java,  Java applications performance,  Java language,  interaction,  memory access pattern,  memory management,  software performance evaluation,  virtual memory system,  virtual storage, Application software, Computer architecture, Data engineering, Data mining, Data security, Environmental management, Grid computing, Java, Memory management, Physics, },
 abstract = {The Java language has rapidly become widespread and it is being used to implement a broad range of applications, including applications with high resource requirements. For this reason, it is important to evaluate the suitability of the Java environment to execute such applications. This paper presents an evaluation of the effects of memory management in the context of memory intensive Java applications executed on a virtual memory system. The goal of this work is to detect the most critical memory management issues for Java applications performance. We measure the overhead that each memory management task adds to the application execution, and we determine which part of this overhead is due to the memory access pattern of the application and which part is due to the interaction between the different memory management tasks. },
}

@inproceedings{842293,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Bermudo, N. and Vera, X. and Gonzalez, A. and Llosa, J.},
 year = {2000},
 pages = {139--145},
 publisher = {IEEE},
 title = {An efficient solver for Cache Miss Equations},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842293},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842293},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842293.pdf?arnumber=842293},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {CME, Cache Miss Equation solver, Equations, algorithm complexity, cache behavior, cache storage, computation cost, computational complexity, exponential complexity, linear function, polyhedra, storage management, },
 abstract = {Cache Miss Equations (CME) (S. Ghosh et al., 1997) is a method that accurately describes the cache behavior by means of polyhedra. Even though the computation cost of generating CME is a linear function of the number of references, solving them is a very time consuming task and thus trying to study a whole program may be infeasible. The paper presents effective techniques that exploit some properties of the particular polyhedra generated by CME. Such techniques reduce the complexity of the algorithm to solve CME, which results in a significant speedup when compared with traditional methods. In particular, the proposed approach does not require the computation of the vertices of each polyhedron, which has an exponential complexity },
}

@inproceedings{1190235,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Weber, S. and Hariharan, R.},
 year = {2003},
 pages = { 80-- 90},
 publisher = {IEEE},
 title = {A new synthetic web server trace generation methodology},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190235},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190235},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190235.pdf?arnumber=1190235},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { client content,  file servers,  queueing models,  queueing theory,  server session caching,  software performance evaluation,  synthetic trace generation,  web server performance benchmarking,  workload model parameters, Aggregates, Banking, Databases, Emulation, Proposals, Statistics, Surges, Telecommunication traffic, Traffic control, Web server, },
 abstract = {We propose a new synthetic trace generation methodology for web server performance benchmarking. We discuss the two primary existing approaches to synthetic trace generation in terms of queueing models. We propose a new methodology as the natural combination of these two approaches. This hybrid approach permits natural modeling of client content and server session caching as well as a natural correspondence between the workload model parameters and the statistics of the resulting synthetic trace. },
}

@inproceedings{1190234,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Foong, A.P. and Huff, T.R. and Hum, H.H. and Patwardhan, J.R. and Regnier, G.J.},
 year = {2003},
 pages = { 70-- 79},
 publisher = {IEEE},
 title = {TCP performance re-visited},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190234},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190234},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190234.pdf?arnumber=1190234},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { CPU scaling,  Ethernet,  TCP performance,  TCP stack,  TCP/IP,  memory bus loading,  performance evaluation,  scaling,  transport protocols, Bandwidth, Computer science, Costs, Current measurement, Engines, Network servers, Performance analysis, Protocols, TCPIP, Thumb, },
 abstract = {Detailed measurements and analyses for the Linux-2.4 TCP stack on current adapters and processors are presented. We describe the impact of CPU scaling and memory bus loading on TCP performance. As CPU speeds outstrip I/O and memory speeds, many generally accepted notions of TCP performance begin to unravel. In-depth examinations and explanations of previously held TCP performance truths are provided, and we expose cases where these assumptions and rules of thumb no longer hold in modern-day implementations. We conclude that unless major architectural changes are adopted, we would be hard-pressed to continue relying on the 1 GHz/1 Gbps rule of thumb. },
}

@inproceedings{1190239,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Gurumurthi, S. and Jianyong Zhang and Sivasubramaniam, A. and Kandemir, M. and Franke, H. and Vijaykrishnan, N. and Irwin, M.J.},
 year = {2003},
 pages = { 123-- 132},
 publisher = {IEEE},
 title = {Interplay of energy and performance for disk arrays running transaction processing workloads},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190239},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190239},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190239.pdf?arnumber=1190239},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Internet,  RAID,  RAID configurations,  TPC-C,  TPC-H,  business enterprises,  disk arrays,  energy,  performance,  performance behavior,  performance evaluation, Business, Cooling, Costs, Data processing, Internet, Packaging, Power dissipation, Power generation, Power system reliability, Web server, },
 abstract = {The growth of business enterprises and the emergence of the Internet as a medium for data processing has led to a proliferation of applications that are server-centric. The power dissipation of such servers has a major consequence not only on the costs and environmental concerns of power generation and delivery, but also on their reliability and on the design of cooling and packaging mechanisms for these systems. This paper examines the energy and performance ramifications in the design of disk arrays which consume a major portion of the power in transaction processing environments. Using traces of TPC-C and TPC-H running on commercial servers, we conduct in-depth simulations of energy and performance behavior of disk arrays with different RAID configurations. Our results demonstrate that conventional disk power optimizations that have been previously proposed and evaluated for single disk systems' (laptops/workstations) are not very effective in server environments, even if we can design disks than have extremely fast spinup/spindown latencies and predict the idle periods accurately. On the other hand, tuning RAID parameters (RAID type, number of disks, stripe size etc.) has more impact on the power and performance behavior of these systems, sometimes having opposite effects on these two criteria. },
}

@inproceedings{842292,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Majumdar, S.},
 year = {2000},
 pages = {129--138},
 publisher = {IEEE},
 title = {Performance scalability in multiprocessor systems with resource contention},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842292},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842292},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842292.pdf?arnumber=842292},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Access protocols, Database systems, Multiprocessing systems, Scalability, Switches, Systems engineering and theory, Telephony, Transaction databases, Writing, analytic models, data consistency, embedded systems, hybrid approach, memory contention, multiple processes, multiprocessing systems, multiprocessor based applications, multiprocessor based telecommunication, multiprocessor systems, performance evaluation, performance scalability, processor scheduling, real time databases, reengineering, resource allocation, resource contention, scheduling approaches, shared memory systems, shared resource contention, shared resources, system behavior, system performance, systems re-engineering, telephone switches, },
 abstract = {Multiple processes may contend for shared resources such as variables stored in the shared memory of a multiprocessor system. Mechanisms required to preserve data consistency on such systems often lead do a decrease in system performance. This research focuses on controlling shared resource contention for achieving high capacity and scalability in multiprocessor based applications that include telephone switches and real time databases. Both reengineering of existing code as well as appropriate scheduling of the processes are two viable methods for controlling memory contention. Emphasis is placed on the second approach. Based on analytic models, three different scheduling approaches are compared. The numerical results obtained from the model provide insights into system behavior and highlight the important attributes of each strategy. A hybrid approach that combines the good attributes of a number of these strategies is proposed and analyzed. The results of this research are useful mainly to designers of software for multiprocessor based telecommunication and other embedded systems },
}

@inproceedings{4211011,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {},
 year = {2007},
 pages = {iv--v},
 publisher = {IEEE},
 title = {Commentary},
 date = {April  2007},
 doi = {10.1109/ISPASS.2007.363725},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211011},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211011.pdf?arnumber=4211011},
 isbn = {1-4244-1082-7},
 language = {English},
 abstract = {},
}

@inproceedings{1190236,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Hassanein, W. and Astfalk, G. and Eigenmann, R.},
 year = {2003},
 pages = { 91-- 100},
 publisher = {IEEE},
 title = {1D performance analysis and tracing of technical and Java applications on the Itanium2 processor},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190236},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190236},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190236.pdf?arnumber=1190236},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Java,  Java applications,  LS-Dyna3D,  Nastran,  Star-CD,  benchmark,  computational fluid dynamics,  finite element analysis,  software performance evaluation,  structural analysis,  technical applications,  workload characterization, Application software, Computer crashes, Computer industry, Finite element methods, Fluid dynamics, Hardware, Instruments, Java, Performance analysis, Phasor measurement units, },
 abstract = {This paper presents a detailed workload characterization of important technical and Java\&trade; applications used in the industry, on the Itanium2 processor. We present a detailed performance study of four major classes of technical applications: 1- Crash finite element analysis (LS-Dyna3D). 2Structural analysis (Nastran). 3- Computational fluid dynamics (Star-CD). 4Other technical applications (GUPS). The performance of technical applications is compared to a commercial Java server benchmark (SPECjbb2000). The data indicate that the average IPC ratio of technical applications to that of the commercial Java application is from 1.23 to 2.36 (1.74 on average). We analyze the time varying behavior of the applications and collect instruction traces at both the kernel and user levels of representative sections of the code. },
}

@inproceedings{4211031,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Ke Meng and Huebbers, F. and Joseph, R. and Ismail, Y.},
 year = {2007},
 pages = {146--157},
 publisher = {IEEE},
 title = {Modeling and Characterizing Power Variability in Multicore Architectures},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363745},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211031},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211031.pdf?arnumber=4211031},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Character generation, Computer architecture, Delay, Energy consumption, Fabrication, Integrated circuit interconnections, Microarchitecture, Multicore processing, Power generation, SPICE, SPICE simulation, VariPower, Virtual manufacturing, mal-fabricated chip, microarchitectural block, multicore architecture, multicore processor, multiprocessing systems, parameter variation, power aware computing, power variability characterization, project power variability, statistical analysis, technology scaling, },
 abstract = {Parameter variation due to manufacturing error is an unavoidable consequence of technology scaling in future generations. The impact of random variation in physical factors such as gate length and interconnect spacing have a profound impact on not only performance of chips, but also their power behavior. While circuit-level techniques such as adaptive body-biasing can help to mitigate mal-fabricated chips, they cannot completely alleviate severe within die variations forecasted for near future designs. Despite the large impact that power variability have on future designs, there is a lack of published work that examines architectural implications of this phenomenon. In this work, we develop architecture level models that model power variability due to manufacturing error and examine its influence on multicore designs. We introduce VariPower, a tool for modeling power variability based on an microarchitectural description and floorplan of a chip. In particular, our models are based on layout level SPICE simulations and project power variability for different microarchitectural blocks using statistical analysis. Using VariPower: (1) we characterize power variability for multicore processors, (2) explore application sensitivity to power variability, and (3) examine clustering techniques that can appropriately classify groups of processors and chips that have similar variability characteristics },
}

@inproceedings{990698,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {},
 year = {2001},
 pages = {185--185},
 publisher = {IEEE},
 title = {Author Index},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990698},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990698},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990698.pdf?arnumber=990698},
 isbn = {0-7695-7230-1},
 language = {English},
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990698.png" border="0"> },
}

@inproceedings{4211033,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Wangyuan Zhang and Xin Fu and Tao Li and Fortes, J.},
 year = {2007},
 pages = {169--178},
 publisher = {IEEE},
 title = {An Analysis of Microarchitecture Vulnerability to Soft Errors on Simultaneous Multithreaded Architectures},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363747},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211033},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211033.pdf?arnumber=4211033},
 isbn = {1-4244-1082-7},
 language = {English},
 keywords = {Computer architecture, Computer errors, Hardware, Microarchitecture, Microprocessors, Multithreading, SPEC CPU 2000 benchmark, Semiconductor device reliability, Surface-mount technology, Throughput, Yarn, fetch policy, microarchitecture reliability profile, microarchitecture structure, microarchitecture vulnerability, microprocessor reliability, multi-threading, multithreading architecture, performance evaluation, processor throughput, program diagnostics, semiconductor transient fault, simultaneous multithreaded architecture, soft error vulnerability analysis, thread-aware reliability optimization, thread-level parallelism, },
 abstract = {Semiconductor transient faults (i.e. soft errors) have become an increasingly important threat to microprocessor reliability. Simultaneous multithreaded (SMT) architectures exploit thread-level parallelism to improve overall processor throughput. A great amount of research has been conducted in the past to investigate performance and power issues of SMT architectures. Nevertheless, the effect of multithreaded execution on a microarchitecture's vulnerability to soft error remains largely unexplored. To address this issue, we have developed a microarchitecture level soft error vulnerability analysis framework for SMT architectures. Using a mixed set of SPEC CPU 2000 benchmarks, we quantify the impact of multithreading on a wide range of microarchitecture structures. We examine how the baseline SMT microarchitecture reliability profile varies with workload behavior, the number of threads and fetch policies. Our experimental results show that the overall vulnerability rises in multithreading architectures, while each individual thread shows less vulnerability. By considering both performance and reliability, SMT outperforms superscalar architectures. The SMT reliability and its tradeoff with performance vary across different fetch policies. With a detailed analysis of the experimental results, we point out a set of potential opportunities to reduce SMT microarchitecture vulnerability, which can serve as guidance to exploiting thread-aware reliability optimization techniques in the near future. To our knowledge, this paper presents the first effort to characterize microarchitecture vulnerability to soft error on SMT processors },
}

@inproceedings{1620789,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Eyerman, S. and Smith, J.E. and Eeckhout, L.},
 year = {2006},
 pages = { 48-- 58},
 publisher = {IEEE},
 title = {Characterizing the branch misprediction penalty},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620789},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620789},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620789.pdf?arnumber=1620789},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { branch misprediction penalty,  frontend pipeline length,  functional unit latency,  interval analysis,  last miss event,  parallel architectures,  performance evaluation,  pipeline processing,  pipelined superscalar processors,  superscalar processor performance modeling, Analytical models, Clocks, Data analysis, Delay, Impedance, Length measurement, Performance analysis, Pipelines, Time measurement, },
 abstract = {Despite years of study, branch mispredictions remain as a significant performance impediment in pipelined superscalar processors. In general, the branch misprediction penalty can be substantially larger than the frontend pipeline length (which is often equated with the misprediction penalty). We identify and quantify five contributors to the branch misprediction penalty: (i) the frontend pipeline length, (ii) the number of instructions since the last miss event (branch misprediction, I-cache miss, long D-cache miss)-this is related to the burstiness of miss events, (iii) the inherent ILP of the program, (iv) the functional unit latencies, and (v) the number of short (LI) D-cache misses. The characterizations done in this paper are driven by 'interval analysis', an analytical approach that models superscalar processor performance as a sequence of inter-miss intervals. },
}

@inproceedings{1620788,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Nagarajan, R. and Xia Chen and McDonald, R.G. and Burger, D. and Keckler, S.W.},
 year = {2006},
 pages = { 37-- 47},
 publisher = {IEEE},
 title = {Critical path analysis of the TRIPS architecture},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620788},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620788},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620788.pdf?arnumber=1620788},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { TRIPS architecture,  concurrent processors,  critical path analysis,  high-ILP architecture,  microprocessor chips,  multiprocessing systems,  parallel architectures,  performance analysis,  performance evaluation,  processor architectures, Abstracts, Analytical models, Application software, Computational modeling, Computer architecture, Hardware, Laboratories, Microarchitecture, Performance analysis, Process design, },
 abstract = {Fast, accurate, and effective performance analysis is essential for the design of modern processor architectures and improving application performance. Recent trends toward highly concurrent processors make this goal increasingly difficult. Conventional techniques, based on simulators and performance monitors, are ill-equipped to analyze how a plethora of concurrent events interact and how they affect performance. Prior research has shown the utility of critical path analysis in solving this problem. This analysis abstracts the execution of a program with a dependence graph. With simple manipulations on the graph, designers can gain insights into the bottlenecks of a design. This paper extends critical path analysis to understand the performance of a next-generation, high-ILP architecture. The TRIPS architecture introduces new features not present in conventional superscalar architectures. We show how dependence constraints introduced by these features, specifically the execution model and operand communication links, can be modeled with a dependence graph. We describe a new algorithm that tracks critical path information at a fine-grained level and yet can deliver an order of magnitude (30x) improvement in performance over previously proposed techniques. Finally, we provide a breakdown of the critical path for a select set of benchmarks and show an example where we use this information to improve the performance of a heavily-hand-optimized program by as much as 11\%. },
}

@inproceedings{990691,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Manjikian, N.},
 year = {2001},
 pages = {147--151},
 publisher = {IEEE},
 title = {Parallel simulation of multiprocessor execution: implementation and results for simplescalar},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990691},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990691},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990691.pdf?arnumber=990691},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Application software, Computational modeling, Computer architecture, Computer simulation, Concurrent computing, Out of order, Predictive models, Software tools, Sun, Velocity measurement, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990691.png" border="0"> },
}

@inproceedings{1620784,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Patterson, D.A.},
 year = {2006},
 publisher = {IEEE},
 title = {RAMP: research accelerator for multiple processors - a community vision for a shared experimental parallel HW/SW platform},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620784},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620784},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620784.pdf?arnumber=1620784},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { Berkeley Emulation Engine,  Moore law,  RAMP,  field programmable gate arrays,  hardware-software codesign,  large scale multiprocessor,  large-scale computer systems,  microprocessor,  microprocessor chips,  multiboard FPGA systems,  multicore chips,  multiple processors,  multiprocessing systems,  multiprocessor research,  parallel architectures,  parallel computing,  research accelerator,  shared experimental parallel HW/SW platform, Application software, Computer architecture, Computer languages, Field programmable gate arrays, File systems, Hardware, Large-scale systems, Microprocessors, Operating systems, Program processors, },
 abstract = {Summary form only given. The vast majority of computer architects believe the future of the microprocessor is hundreds to thousands of processors ("cores") on a chip. Given such widespread agreement, it's surprising how much research remains to be done in algorithms, computer architecture, networks, operating systems, file systems, compilers, programming languages, applications, and so on to realize this vision. Fortunately, Moore's law has not only enabled dense multi-core chips, it has also enabled extremely dense FPGAs. Today, one to two dozen soft cores can be programmed into a single FPGA. With multiple FPGAs on a board and multiple boards in a system, 1000-processor designs can be economically and rapidly explored. To make this happen, however, requires a significant amount of infrastructure in hardware, software, and what we call "gateware", the register-transfer level models that fill the FGPAs. By using the Berkeley Emulation Engine boards that were created for other purposes, the hardware is already done. A group of architects plan to design the gateware, create this infrastructure, and share the results in an open-source fashion so that every institution could have their own. Such a system would not just invigorate multiprocessors research in the architecture community. Since processors cores can run at 100 to 200 MHz, a large scale multiprocessor would be fast enough to run operating systems and large programs at speeds sufficient to support software research. Moreover, there is a new generation of FPGAs every 18 months with capacity for twice as many cores and run them faster, so future multiboard FPGA systems are even more attractive. Hence, we believe such a system would accelerate research across all the fields that touch multiple processors. Thus the acronynm RAMP, for Research Accelerator for Multiple Processors. RAMP has the potential to transform the parallel computing community in computer science from a simulation-driven to a prototype-driven discipline, leading to rapid iteration across interfaces of the many fields of multiple processors, and thereby moving much more quickly to a parallel foundation for large-scale computer systems research in the 21st century. },
}

@inproceedings{1620787,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Barr, K.C. and Asanovic, K.},
 year = {2006},
 pages = { 25-- 36},
 publisher = {IEEE},
 title = {Branch trace compression for snapshot-based simulation},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620787},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620787},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620787.pdf?arnumber=1620787},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { branch trace compression,  branch-predictor based compression,  compressed trace file,  computer architecture,  data compression,  microarchitecture simulation,  program compilers,  program debugging,  snapshot-based simulation,  software branch predictor,  virtual machines, Analytical models, Artificial intelligence, Computational modeling, Computer science, Computer simulation, Concrete, Laboratories, Microarchitecture, Phase detection, Predictive models, },
 abstract = {We present a scheme to compress branch trace information for use in snapshot-based microarchitecture simulation. The compressed trace can be used to warm any arbitrary branch predictor's state before detailed microarchitecture simulation of the snapshot. We show that compressed branch traces require less space than snapshots of concrete predictor state. Our branch-predictor based compression (BPC) technique uses a software branch predictor to provide an accurate model of the input branch trace, requiring only mispredictions to be stored in the compressed trace file. The decompressor constructs a matching software branch predictor to help reconstruct the original branch trace from the record of mispredictions. Evaluations using traces from the Journal of ILP branch predictor competition show we achieve compression rates of 0.013-0.72 bits/branch (depending on workload), which is up to 210\&times; better than gzip; up to 52\&times; better than the best general-purpose compression techniques; and up to 4.4\&times; better than recently-published, more general trace compression techniques. Moreover, BPC-compressed traces can be decompressed in less time than corresponding traces compressed with other methods. },
}

@inproceedings{1620786,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Liu, R.F. and Asanovic, K.},
 year = {2006},
 pages = { 13-- 24},
 publisher = {IEEE},
 title = {Accelerating architectural exploration using canonical instruction segments},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620786},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620786},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620786.pdf?arnumber=1620786},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { AXCIS framework,  architectural exploration acceleration,  canonical instruction segments,  computer architecture,  design space exploration,  dynamic instructions,  microarchitectural simulation,  microarchitecture configuration,  performance evaluation,  performance metrics,  virtual machines, Acceleration, Artificial intelligence, Computational modeling, Computer science, Computer simulation, Laboratories, Measurement, Microarchitecture, Sampling methods, Space exploration, },
 abstract = {Detailed microarchitectural simulators are not well suited for exploring large design spaces due to their excessive simulation times. We introduce AXCIS, a framework for fast and accurate design space exploration. AXCIS achieves fast simulation times by exploiting repetitions in program behavior to reduce the number of instructions simulated. For each dynamic instruction encountered during an initial full run of a benchmark, AXCIS builds an instruction segment, which concisely represents performance-critical information. AXCIS then compresses the string of dynamic segments into a table of canonical instruction segments (CIST) to give a compact representation of the entire benchmark trace. Given a precompiled CIST and a target microarchitecture configuration, AXCIS can quickly and accurately estimate performance metrics such as instructions per cycle (IPC). For the SPEC CPU2000 benchmarks and all simulated configurations, AXCIS achieves an average IPC error of 2.6\%. While cycle-accurate simulators can take many hours to simulate billions of dynamic instructions, AXCIS can complete the same simulation on the corresponding CIST within seconds. },
}

@inproceedings{990695,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Kun Luo and Gummaraju, J. and Franklin, M.},
 year = {2001},
 pages = {164--171},
 publisher = {IEEE},
 title = {Balancing thoughput and fairness in SMT processors},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990695},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990695},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990695.pdf?arnumber=990695},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Context modeling, Delay, Educational institutions, Multithreading, Pipelines, Resource management, Surface-mount technology, Throughput, Yarn, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990695.png" border="0"> },
}

@inproceedings{1291372,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {},
 year = {2004},
 pages = { 172-- 172},
 publisher = {IEEE},
 title = {Author Index},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291372},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291372},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291372.pdf?arnumber=1291372},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 abstract = {},
}

@inproceedings{1620783,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {},
 year = {2006},
 pages = { viii-- x},
 publisher = {IEEE},
 title = {Table of Contents},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620783},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620783},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620783.pdf?arnumber=1620783},
 isbn = {1-4244-0186-0},
 language = {English},
 abstract = {},
}

@inproceedings{1620782,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {},
 year = {2006},
 publisher = {IEEE},
 title = {ISPASS 2006. IEEE International Symposium on Performance Analysis of Systems Software (IEEE Cat. No. 06EX1308)},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620782},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620782},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620782.pdf?arnumber=1620782},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { accelerating simulation,  computer architecture,  digital simulation,  microarchitecture performance evaluation,  performance evaluation,  software performance analysis,  statistical analysis,  statistical models,  system performance analysis,  workload analysis, },
 abstract = {},
}

@inproceedings{1190245,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Jann, J. and Pattnaik, P. and Dubey, N. and Burugula, R.S.},
 year = {2003},
 pages = { 186-- 194},
 publisher = {IEEE},
 title = {Web applications and dynamic reconfiguration in UNIX servers},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190245},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190245},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190245.pdf?arnumber=1190245},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { UNIX Servers,  Unix,  WebSphere H7TP server,  ab initio study,  dynamic resource management,  file servers,  nonparametric estimation,  nonparametric statistics,  partitioning,  resource allocation,  resource management,  resource reconfiguration,  resource utilization,  workloads, Databases, Delay effects, Fluctuations, Hardware, Hysteresis, Jitter, Middleware, Operating systems, Resource management, Web server, },
 abstract = {In recent years, several large UNIX SMP Servers have added support for dynamic resource management through partitioning and dynamic resource reconfiguration. In this paper we study the ability of Dynamic Reconfiguration (DR) to accommodate fluctuating workloads and changes in operational priorities for a commercial web application. We use a WebSphere HTTP server, a WebSphere Application Server, and a DB2 Database for the application. This combination represents a popular platform for commercial computing deployments, and supports a number of common web-based application scenarios. In our study, we treat this application as a black box to provide a realistic measurement of the efficacy of the DR technology in UNIX Servers. We also use nonparametric estimation techniques to obtain an ab initio and unbiased study of the jitters in our experimental data. Our main conclusions are: (1) Resource allocations for the application (even for a complex and function-rich middleware system such as WebSphere) can be efficiently managed by DR, without the need for explicit accommodation of the DR features by the application, and (2) To obtain efficient resource utilization, the resource management system has to empirically monitor the throughput obtained from the application, rather than rely primarily on long time-scale estimations. },
}

@inproceedings{990667,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {},
 year = {2001},
 pages = {i--ix},
 publisher = {IEEE},
 title = {2001 IEEE International Symposium on Performance Analysis of Systems and Software},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990667},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990667},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990667.pdf?arnumber=990667},
 isbn = {0-7695-7230-1},
 language = {English},
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990667.png" border="0"> },
}

@inproceedings{1620785,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Wenisch, T.F. and Wunderlich, R.E. and Falsafi, B. and Hoe, J.C.},
 year = {2006},
 pages = { 2-- 12},
 publisher = {IEEE},
 title = {Simulation sampling with live-points},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620785},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620785},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620785.pdf?arnumber=1620785},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { computer architecture,  functional simulation,  functional warming,  microarchitectural structures,  performance bottleneck,  sampling methods,  simulation sampling,  statistical confidence,  virtual machines, Computational modeling, Computer architecture, Computer simulation, Current measurement, Hardware, Libraries, Microarchitecture, Predictive models, Runtime, Sampling methods, },
 abstract = {Current simulation-sampling techniques construct accurate model state for each measurement by continuously warming large microarchitectural structures (e.g., caches and the branch predictor) while functionally simulating the billions of instructions between measurements. This approach, called functional warming, is the main performance bottleneck of simulation sampling and requires hours of runtime while the detailed simulation of the sample requires only minutes. Existing simulators can avoid functional simulation by jumping directly to particular instruction stream locations with architectural state checkpoints. To replace functional warming, these checkpoints must additionally provide microarchitectural model state that is accurate and reusable across experiments while meeting tight storage constraints. In this paper, we present a simulation-sampling framework that replaces functional warming with live-points without sacrificing accuracy. A live-point stores the bare minimum of functionally-warmed state for accurate simulation of a limited execution window while placing minimal restrictions on microarchitectural configuration. Live-points can be processed in random rather than program order, allowing simulation results and their statistical confidence to be reported while simulations are in progress. Our framework matches the accuracy of prior simulation-sampling techniques (i.e., \&plusmn;3\% error with 99.7\% confidence), while estimating the performance of an 8-way out-of-order superscalar processor running SPEC CPU2000 in 91 seconds per benchmark, on average, using a 12 GB live-point library. },
}

@inproceedings{1291358,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Tran, L. and Nelson, N. and Fung Ngai and Dropsho, S. and Huang, M.},
 year = {2004},
 pages = { 78-- 87},
 publisher = {IEEE},
 title = {Dynamically reducing pressure on the physical register file through simple register sharing},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291358},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291358},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291358.pdf?arnumber=1291358},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { SMT architecture,  cache storage,  dynamical pressure reduction,  false data dependence elimination,  frequent values,  hardware complexity,  instruction set reuse,  instruction-level parallelism,  logical register,  logical registers,  microprocessors,  multi-threading,  parallel architectures,  physical register file,  physical register storage sharing,  physical registers,  pipelines,  processor scheduling,  register pressure reduction,  register renaming,  register sharing,  register usage reduction,  simultaneous multithreading, Clocks, Data engineering, Hardware, Modems, Multithreading, Parallel processing, Physics computing, Pipelines, Registers, Surface-mount technology, },
 abstract = {Using register renaming and physical registers, modern microprocessors eliminate false data dependences from reuse of the instruction set defined registers (logical registers). High performance processors that have longer pipelines and a greater capacity to exploit instruction-level parallelism have more instructions in-flight and require more physical registers. Simultaneous multithreading architectures further exacerbate this register pressure. This paper evaluates two register sharing techniques for reducing register usage. The first technique dynamically combines physical registers having the same value the second technique combines the demand of several instructions updating the same logical register and share physical register storage among them. While similar techniques have been proposed previously, an important contribution of this paper is to exploit only special cases that provide most of the benefits of more general solutions but at a very low hardware complexity. Despite the simplicity, our design reduces the required number of physical registers by more than 10\% on some applications, and provides almost half of the total benefits of an aggressive (complex) scheme. More importantly, we show the simpler design to reduce register pressure has significant performance effects in a simultaneous multithreaded (SMT) architecture where register availability can be a bottleneck. Our results show an average of 25.6\% performance improvement for an SMT architecture with 160 registers or, equivalently, similar performance as an SMT with 200 registers (25\% more) but no register sharing. },
}

@inproceedings{1291359,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Ying Zheng and Davis, B.T. and Jordan, M.},
 year = {2004},
 pages = { 89-- 96},
 publisher = {IEEE},
 title = {Performance evaluation of exclusive cache hierarchies},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291359},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291359},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291359.pdf?arnumber=1291359},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { benchmark testing,  benchmarks,  cache configuration,  cache memory capacity,  cache storage,  exclusive cache hierarchy,  execution time increase,  execution time metrics,  inclusive cache hierarchy,  memory architecture,  memory hierarchy performance,  performance evaluation,  performance evaluation,  performance improvement,  system performance exclusive caching,  two-level cache memory simulations,  victim buffer,  victim cache, Benchmark testing, Cache memory, Cache storage, Circuits, Computational modeling, Delay, Microprocessors, Modems, Random access memory, System performance, },
 abstract = {Memory hierarchy performance, specifically cache memory capacity, is a constraining factor in the performance of modern computers. This paper presents the results of two-level cache memory simulations and examines the impact of exclusive caching on system performance. Exclusive caching enables higher capacity with the same cache area by eliminating redundant copies. The experiments presented compare an exclusive cache hierarchy with an inclusive cache hierarchy utilizing similar L1 and L2 parameters. Experiments indicate that significant performance advantages can be gained for some benchmark through the use of an exclusive organization. The performance differences are illustrated using the L2 cache misses and execution time metrics. The most significant improvement shown is a 16\% reduction in execution time, with an average reduction of 8\% for the smallest cache configuration tested. With equal size victim buffer and victim cache for exclusive and inclusive cache hierarchies respectively, some benchmarks show increased execution time for exclusive caches because a victim cache can reduce conflict misses significantly while a victim buffer can introduce worst-case penalties. Considering the inconsistent performance improvement, the increased complexity of an exclusive cache hierarchy needs to be justified based upon the specifics of the application and system. },
}

@inproceedings{1291352,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Berg, E. and Hagersten, E.},
 year = {2004},
 pages = { 20-- 27},
 publisher = {IEEE},
 title = {StatCache: a probabilistic approach to efficient and accurate data locality analysis},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291352},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291352},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291352.pdf?arnumber=1291352},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { SPEC CPU2000 benchmarks,  StatCache,  benchmark testing,  cache memories,  cache storage,  data locality analysis,  data structures,  optimization,  performance evaluation,  probabilistic model,  probability,  sampling methods,  sampling-based method,  statistics,  working-set graphs, Application software, Cache memory, Data analysis, High performance computing, Information analysis, Information technology, Modems, Runtime, Sampling methods, Statistics, },
 abstract = {The widening memory gap reduces performance of applications with poor data locality. Therefore, there is a need for methods to analyze data locality and help application optimization. In this paper we present StatCache, a novel sampling-based method for performing data-locality analysis on realistic workloads. StatCache is based on a probabilistic model of the cache, rather than a functional cache simulator. It uses statistics from a single run to accurately estimate miss ratios of fully-associative caches of arbitrary sizes and generate working-set graphs. We evaluate StatCache using the SPEC CPU2000 benchmarks and show that StatCache gives accurate results with a sampling rate as low as 10<sup>-4</sup>. We also provide a proof-of-concept implementation, and discuss potentially very fast implementation alternatives. },
}

@inproceedings{1291353,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Balaji, P. and Narravula, S. and Vaidyanathan, K. and Krishnamoorthy, S. and Wu, J. and Panda, D.K.},
 year = {2004},
 pages = { 28-- 35},
 publisher = {IEEE},
 title = {Sockets Direct Protocol over InfiniBand in clusters: is it beneficial?},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291353},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291353},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291353.pdf?arnumber=1291353},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { InfiniBand architecture,  Parallel Virtual File System,  Sockets Direct Protocol,  benchmark testing,  cluster systems,  file transfers,  message passing,  message transfers,  microbenchmarks,  multitier data center,  performance evaluation,  transport protocols,  virtual storage,  workstation clusters, Application software, Communication industry, Computer architecture, Context, Delay, File systems, Information science, Kernel, Protocols, Sockets, },
 abstract = {The Sockets Direct Protocol (SDP) had been proposed recently in order to enable sockets based applications to take advantage of the enhanced features provided by InfiniBand architecture. In this paper, we study the benefits and limitations of an implementation of SDP. We first analyze the performance of SDP based on a detailed suite of micro-benchmarks. Next, we evaluate it on two different real application domains: (1) A multitier data-center environment and (2) A Parallel Virtual File System (PVFS). Our micro-benchmark results show that SDP is able to provide up to 2.7 times better bandwidth as compared to the native sockets implementation over InfiniBand (IPoIB) and significantly better latency for large message sizes. Our experimental results also show that SDP is able to achieve a considerably higher performance (improvement of up to 2.4 times) as compared to IPoIB in the PVFS environment. In the data-center environment, SDP outperforms IPoIB for large file transfers inspite of currently being limited by a high connection setup time. However, this limitation is entirely implementation specific and as the InfiniBand software and hardware products are rapidly maturing, we expect this limitation to be overcome soon. Based on this, we have shown that the projected performance for SDP, without the connection setup time, can outperform IPoIB for small message transfers as well. },
}

@inproceedings{1291350,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Vandierendonck, H. and De Bosschere, K.},
 year = {2004},
 pages = { 2-- 11},
 publisher = {IEEE},
 title = {Eccentric and fragile benchmarks},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291350},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291350},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291350.pdf?arnumber=1291350},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { CPU2000 benchmark suite,  SPEC CPU95 benchmark suite,  benchmark testing,  computer architecture,  computer architecture,  eccentric benchmarks,  fragile benchmarks,  performance evaluation,  performance evaluation,  principal component analysis,  principal components analysis,  program testing,  statistical analysis,  workload characterization, Benchmark testing, Computer architecture, Data analysis, Information systems, Prefetching, Stress, Tail, Velocity measurement, },
 abstract = {Benchmarks are essential for computer architecture research and performance evaluation. Constructing a good benchmark suite is, however, non-trivial: it must be representative, show different types of behavior and the benchmarks should not be easily tweaked. This paper uses principal components analysis, a statistical data analysis technique, to detect differences in behavior between benchmarks. Two specific types of benchmarks are identified. Eccentric benchmarks have a behavior that differs significantly from the other benchmarks. They are useful to incorporate different types of behavior in a suite. Fragile benchmarks are weak benchmarks: their execution time is determined almost entirely by a single bottleneck. Removing that bottleneck reduces their execution time excessively. This paper argues that fragile benchmarks are not useful and shows how they can be detected by means of workload characterization techniques. These techniques are applied to the SPEC CPU95 and CPU2000 benchmark suites. It is shown that these suites contain both eccentric and fragile benchmarks. The notions of eccentric and fragile benchmarks are important when composing a benchmark suite and to guide the sub-setting of a benchmark suite. },
}

@inproceedings{1291351,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Patwardhan, J.P. and Lebeck, A.R. and Sorin, D.J.},
 year = {2004},
 pages = { 12-- 19},
 publisher = {IEEE},
 title = {Communication breakdown: analyzing CPU usage in commercial Web workloads},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291351},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291351},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291351.pdf?arnumber=1291351},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { CPU usage,  Internet,  Web servers,  business communication,  commerce,  commercial workloads,  communication breakdown,  data handling,  data processing,  networking overhead,  performance evaluation,  server workloads,  static Web workloads, Analytical models, Computer science, Data processing, Electric breakdown, Intelligent networks, Java, Network servers, Protocols, Throughput, Web server, },
 abstract = {There is increasing concern among developers that future Web servers running commercial workloads may be limited by network processing overhead in the CPU as 10Gb Ethernet becomes prevalent. We analyze CPU usage of real hardware running popular commercial workloads, with an emphasis on identifying networking overhead. Contrary to much popular belief, our experiments show that network processing is unlikely to be a problem for workloads that perform significant data processing. For the dynamic Web serving workloads we examine, networking overhead is negligible (3\% or less), and data processing limits performance. However, for Web servers that serve static content, networking processing can significantly impact performance (up to 25\% of CPU cycles). With an analytical model, we calculate the maximum possible improvement in throughput due to protocol offload to be 50\% for the static Web workloads. },
}

@inproceedings{1291356,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Lau, J. and Schoemackers, S. and Calder, B.},
 year = {2004},
 pages = { 57-- 67},
 publisher = {IEEE},
 title = {Structures for phase classification},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291356},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291356},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291356.pdf?arnumber=1291356},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { SimPoint,  architecture performance metrics,  basic blocks,  hardware designs,  instruction sets,  loop branches,  memory address information,  opcodes,  phase classification,  program behavior,  program compilers,  program control structures,  program profiling,  program structures,  register usage,  same instruction set, Analytical models, Atomic measurements, Computer science, Frequency, Hardware, Instruction sets, Performance analysis, Phase detection, Registers, Statistics, },
 abstract = {Most programs are repetitive, where similar behavior can be seen at different execution times. Proposed algorithms automatically group these similar intervals of execution into phases, where all he intervals in a phase have homogeneous behavior and similar resource requirements. In this paper we examine different program structures for capturing phase behavior. The goal is to compare the size and accuracy of these structures for performing phase classification. We focus on profiling the frequency of program level structures that are independent from underlying architecture performance metrics. This allows the phase classification to be used across different hardware designs that support the same instruction set (ISA). We compare using basic blocks, loop branches, procedures, opcodes, register usage, and memory address information for guiding phase classification. We compare these different structures in terms of their ability to create homogeneous phases, and evaluate the accuracy of using these structures to pick simulation points for SimPoint. },
}

@inproceedings{1291357,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Bell, G.B. and Lipasti, M.H.},
 year = {2004},
 pages = { 68-- 77},
 publisher = {IEEE},
 title = {Deconstructing commit},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291357},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291357},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291357.pdf?arnumber=1291357},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { clock frequencies,  commit deconstruction,  cycle-time limiting resources,  floating point,  in-order commit,  instruction sets,  instruction-level parallelism,  integer benchmarks,  microarchitectural modifications,  out-of-order commit,  out-of-order processor,  processor resources,  processor scheduling,  processor scheduling,  program compilers,  program order,  resource utilization,  safety mechanism, Clocks, Computer aided instruction, Dynamic scheduling, Microarchitecture, Out of order, Parallel processing, Processor scheduling, Protection, Resource management, Safety, },
 abstract = {Many modern processors execute instructions out of their original program order to exploit instruction-level parallelism and achieve higher performance. However even though instructions can execute in an arbitrary order, they must eventually commit, or retire from execution, in program order. This constraint provides a safety mechanism to ensure that mis-speculated instructions are not inadvertently committed, but can consume valuable processor resources and severely limit the degree of parallelism exposed in a program. We assert that such a constraint is overly conservative, and propose conditions under which it can be relaxed. This paper deconstructs the notion of commit in an out-of-order processor, and examines the set of necessary conditions under which instructions can be permitted to retire out of program order. It provides a detailed analysis of the frequency and relative importance of these conditions, and discusses microarchitectural modifications that relax the in-order commit requirement. Overall, we found that for a given set of processor resources our technique achieves speedups of up to 68\% and 8\% for floating point and integer benchmarks, respectively. Conversely, because out-of-order commit allows more efficient utilization of cycle-time limiting resources, it can alternatively enable simpler designs with potentially higher clock frequencies. },
}

@inproceedings{1291354,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Bachega, L.R. and Brunheroto, J.R. and DeRose, L. and Mindlin, P. and Moreira, J.E.},
 year = {2004},
 pages = { 36-- 44},
 publisher = {IEEE},
 title = {The BlueGene/L pseudo cycle-accurate simulator},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291354},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291354},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291354.pdf?arnumber=1291354},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { BlueGene/L functional simulator,  BlueGene/L supercomputer,  DAXPY kernel,  computer system,  digital simulation,  parallel architectures,  parallel machines,  processor architecture,  pseudo cycle-accurate simulator,  software development,  software engineering,  software engineering,  software tuning, Analytical models, Application software, Computational modeling, Computer architecture, Hardware, Kernel, Supercomputers, System software, Testing, Timing, },
 abstract = {The design and development of a new computer system is a lengthy process, with a considerable amount of time elapsed between the beginning of development and first hardware availability. Hence, fast and reasonably accurate simulation of processor architecture has become critical as an enabling mechanism for software engineers to develop and tune system software and applications. In this paper, we present the time-stamped timing model extensions to the BlueGene/L functional simulator. These extensions were implemented to create a pseudo cycle-accurate simulator capable of providing tracing capabilities for detection of bottlenecks and for performance tuning of applications, before the actual hardware became available. Our validation tests, using the DAXPY kernel and the serial version of the NAS benchmarks, show that our pseudo cycle-accurate simulator provides timing information within 15\% of the times measured using the actual BlueGene/L hardware. In addition, we present a couple of case studies, which describes how this simulator can be used for identification of performance bottlenecks and for application tuning. },
}

@inproceedings{1291355,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Van Biesbrouck, M. and Sherwood, T. and Calder, B.},
 year = {2004},
 pages = { 45-- 56},
 publisher = {IEEE},
 title = {A co-phase matrix to guide simultaneous multithreading simulation},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291355},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291355},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291355.pdf?arnumber=1291355},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { SMT machine,  architectural configurations,  commercial processors,  computer architecture,  computer architecture,  cophase matrix,  four-threaded workloads,  multi-threading,  multiprocessing programs,  program simulation,  simultaneous multithreading simulation,  thread interactions,  virtual machines, Computational modeling, Computer architecture, Computer science, Computer simulation, Error analysis, Force measurement, Modems, Multithreading, Surface-mount technology, Yarn, },
 abstract = {Several commercial processors have architectures that include support for simultaneous multithreading (SMT), yet there is still not a validated methodology for estimating the performance of an SMT machine that does not rely on full program simulation. To create an efficient sampling approach for SMT we must determine how far to fast-forward each individual thread between samples. The fast-forwarding distance for each thread will vary according to execution phases, thread interactions and changes to the architectural configuration. We examine using individual program phase information to guide SMT simulation. This is accomplished by creating what we call a co-phase matrix. The co-phase matrix is populated by collecting samples of the programs' phase combinations, and is used to guide fastforwarding between samples. We show for 28 pairs of SPEC programs that using the co-phase matrix provides an average error rate of 4\% while requiring that only 1\% of the full simulation be performed. The methods are also validated using a variety of architectural configurations and four-threaded workloads. },
}

@inproceedings{1620814,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {},
 year = {2006},
 pages = { vii-- vii},
 publisher = {IEEE},
 title = {Reviewers},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620814},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620814},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620814.pdf?arnumber=1620814},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = {IEEE, },
 abstract = {},
}

@inproceedings{1620811,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Lilja, D.J.},
 year = {2006},
 pages = { iii-- iii},
 publisher = {IEEE},
 title = {Message from the General Chair},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620811},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620811},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620811.pdf?arnumber=1620811},
 isbn = {1-4244-0186-0},
 language = {English},
 abstract = {},
}

@inproceedings{5452080,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Adamoli, A. and Jovic, M. and Hauswirth, M.},
 year = {2010},
 pages = {13--22},
 publisher = {IEEE},
 title = {LagAlyzer: A latency profile analysis and visualization tool},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452080},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452080},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452080.pdf?arnumber=5452080},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Delay, Graphical user interfaces, Humans, Java, Java, Keyboards, LagAlyzer, Libraries, Mice, Productivity, Visualization, computer graphics, data visualisation, garbage collection, human users, interactive Java applications, interactive software, interactive systems, latency profile analysis, runtime libraries, synchronization bottlenecks, user interfaces, visualization tool, },
 abstract = {Many computer systems are interactive in some way, that means they are used by human users. A human user perceives the performance of a computer system primarily in terms of its response time. If a system does not respond to a user's input, such as a key press, a mouse motion, or a gesture on a touch screen, within roughly 100 ms, a user perceives the system as sluggish. Developers of interactive software and systems thus are interested in keeping response times below this perceptibility threshold. Existing tools allow the measurement of interactive response times, and the tracing of application behavior. In this paper we present a tool, LagAlyzer, which analyzes and visualizes the information gathered by such latency measurement tools. LagAlyzer enables the characterization of perceptible lag, for example by quantifying to what degree perceptible performance was caused by synchronization bottlenecks, by garbage collection, by the runtime libraries, or by the application. We use LagAlyzer to characterize the perceptible latency found in commonly used interactive Java applications. We believe that this is the first study giving insight into why interactive Java applications sometimes are perceived as sluggish. },
}

@inproceedings{1620813,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {},
 year = {2006},
 pages = { vi-- vi},
 publisher = {IEEE},
 title = {ISPASS 2006 Committees},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620813},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620813},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620813.pdf?arnumber=1620813},
 isbn = {1-4244-0186-0},
 language = {English},
 abstract = {},
}

@inproceedings{1190227,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Jianwei Chen and Dubois, M. and Stenstrom, P.},
 year = {2003},
 pages = { 1-- 10},
 publisher = {IEEE},
 title = {Integrating complete-system and user-level performance/power simulators: the SimWattch approach},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190227},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190227},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190227.pdf?arnumber=1190227},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { SPEC JVM98 applications,  SPEC95,  SimWattch approach,  SimpleScalar,  architectural impact,  digital simulation,  microarchitectural user-level simulation,  operating system,  operating system interaction,  operating systems (computers),  power modeling user-level simulation tool,  software performance evaluation,  system-level simulation tools,  system-simulation tool, Application software, Computational modeling, Computer applications, Energy consumption, Information processing, Microarchitecture, Operating systems, Power system modeling, Predictive models, Timing, },
 abstract = {Evaluating architectural impact of applications with a significant operating system interaction calls for integrating detailed microarchitectural user-level simulation with system-level simulation tools. This paper reports on our experience in integrating Simics - a system-simulation tool - with Wattch - a microarchitectural performance and power modeling user-level simulation tool built on top of SimpleScalar We first present the technical challenges we had to resolve in designing SimWattch - the integrated tool. We then use it to identify the type of errors a user-level simulator typically does when predicting performance and power consumption while omitting operating system activity. This case study is based on SPEC95, and SPEC JVM98 applications and TPC-B. We find that if operating system effects are omitted, performance is usually overestimated while energy used is underestimated. However a surprising result is that IPC, power and resource occupancy predictions from a user-level simulator often follow the trends of predictions from simulations factoring in operating system effects. },
}

@inproceedings{1190228,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Hong Wang and Manor, S. and LaFollette, D. and Nesher, N. and Ku-jei King},
 year = {2003},
 pages = { 11-- 21},
 publisher = {IEEE},
 title = {Inferno: a functional simulation infrastructure for modeling microarchitectural data speculations},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190228},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190228},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190228.pdf?arnumber=1190228},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Inferno,  application program interfaces,  design rationales,  functional model convergence APIs,  functional simulation construction framework,  functional simulation infrastructure,  instruction semantics,  logic simulation,  microarchitectural data speculations modelling,  multi-threading,  processor designs,  relational database, Clocks, Context modeling, Frequency, Microarchitecture, Modular construction, Pipelines, Process design, Processor scheduling, Productivity, Yarn, },
 abstract = {This paper presents key insights and design rationales behind Inferno, a functional simulation construction framework developed at Intel to support execution-driven cycle-accurate performance modeling and simulation of advanced microarchitectural data speculation techniques for future processor designs and explorations. Inferno divides the task of functional simulation into three essential components, namely: (1) context manager of in-flight speculatively executed instructions, (2) stateless emulator of instruction semantics, and (3) a high speed functional simulator capable of booting OS and running large-scale system workloads. These building block components work together in concert via a set of well-architected functional model convergence APIs. With a novel abstraction called speculative domain, the context manager serves effectively as a relational database about the in-flight instructions and on-going speculations. Through a set of functional model usage APIs, the context manager enables performance models to express arbitrary microarchitectural data speculation scenarios. The contribution of this paper is to demonstrate the importance of providing a functional model with modular construction, proper abstraction and expressive APIs for speculative state management. Inferno is such a functional model construction framework and has significantly improved productivity in modeling a variety of sophisticated data speculation microarchitecture techniques. },
}

@inproceedings{1190229,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Youfeng Wu and Li-Ling Chen and Ju, R. and Fang, J.},
 year = {2003},
 pages = { 22-- 31},
 publisher = {IEEE},
 title = {Performance potentials of compiler-directed data speculation},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190229},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190229},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190229.pdf?arnumber=1190229},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { EPIC architecture,  alias analysis,  cache miss,  compiler,  data dependency,  data speculation,  instruction scheduler,  performance evaluation,  performance gain,  program compilers,  scheduling,  software performance evaluation, Delay, Educational institutions, Performance analysis, Performance evaluation, Performance gain, Processor scheduling, Runtime, Statistics, },
 abstract = {Compiler-directed data speculation has been implemented on Itanium systems to allow for a compiler to move a load across a store even when the two operations are potentially aliased This not only breaks data dependency to reduce critical path length, but also allows a load to be scheduled far apart from its uses to hide cache miss latencies. However, the effectiveness of data speculation is affected by the sophistication of alias analysis technique as well as the aggressiveness of the instruction scheduler. In general, the more sophisticated is the alias analysis technique, the less performance gain is from data speculation, and the more aggressive is the instruction scheduler, the more opportunity is for data speculation. In this paper we evaluate in various scenarios the performance potentials of data speculation for SPEC2000C benchmarks. For each scenario, we determine the performance contributions of data speculation due to both critical path reduction and cache miss latency reduction. We also show interesting statistics about the effects of scheduling constraints, the percentage of critical dependencies, the impacts of cache miss latencies, and the distances between the load locations before and after data speculation. },
}

@inproceedings{1430575,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Foong, A. and Fung, J. and Newell, D. and Abraham, S. and Irelan, P. and Lopez-Estrada, A.},
 year = {2005},
 pages = {207--218},
 publisher = {IEEE},
 title = {Architectural Characterization of Processor Affinity in Network Processing},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430575},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430575},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430575.pdf?arnumber=1430575},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Bandwidth, Fabrics, Intelligent networks, Operating systems, Performance gain, Processor scheduling, Protocols, SMP, TCP-IP software implementation, TCPIP, Throughput, Yarn, computer architecture, monolithic operating system, multi-threading, multiprocessing systems, network operating systems, network processing, network protocol stacks, performance evaluation, processor affinity architectural characterization, processor scheduling, transport protocols, user-defined affinity, },
 abstract = {Network protocol stacks, in particular TCP/IP software implementations, are known for its inability to scale well in general-purpose monolithic operating systems (OS) for SMP. Previous researchers have experimented with affinitizing processes/thread, as well as interrupts from devices, to specific processors in a SMP system. However, general purpose operating systems have minimal consideration of user-defined affinity in their schedulers. Our goal is to expose the full potential of affinity by in-depth characterization of the reasons behind performance gains. We conducted an experimental study of TCP performance under various affinity modes on IA-based servers. Results showed that interrupt affinity alone provided a throughput gain of up to 25\%, and combined thread/process and interrupt affinity can achieve gains of 30\%. In particular, calling out the impact of affinity on machine clears (in addition to cache misses) is characterization that has not been done before },
}

@inproceedings{842272,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {},
 year = {2000},
 publisher = {IEEE},
 title = {2000 IEEE International Symposium on Performance Analysis of Systems and Software. ISPASS (Cat. No.00EX422)},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842272},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842272},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842272.pdf?arnumber=842272},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {World Wide Web enabled software, disc storage, disk subsystems, information resources, input-output programs, multiprocessing systems, multiprocessor systems, performance analysis, performance evaluation, real time systems, real-time systems, software systems, trace generation, workload characterization, },
 abstract = {The following topics are dealt with: performance analysis of systems of software; real time systems; workload characterization; multiprocessor systems; World Wide Web enabled software and systems; trace generation; and disk subsystems },
}

@inproceedings{4211034,
 booktitle = {Performance Analysis of Systems and Software, 2007. ISPASS 2007. IEEE International Symposium on},
 author = {Perelman, E. and Lau, J. and Patil, H. and Jaleel, A. and Hamerly, G. and Calder, B.},
 year = {2007},
 pages = {179--189},
 publisher = {IEEE},
 title = {Cross Binary Simulation Points},
 date = {25-27 April 2007},
 doi = {10.1109/ISPASS.2007.363748},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4211034},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4211006/4211007/04211034.pdf?arnumber=4211034},
 isbn = {1-4244-1081-9},
 language = {English},
 keywords = {Clustering algorithms, Computational modeling, Computer architecture, Computer science, Computer simulation, Costs, Instruction sets, Optimizing compilers, Program processors, SimPoint, Space exploration, architectural design space exploration, compiler optimization evaluation, cross binary simulation point, program compilers, program diagnostics, program evaluation, program execution, software performance evaluation, },
 abstract = {Architectures are usually compared by running the same workload on each architecture and comparing performance. When a single compiled binary of a program is executed on many different architectures, techniques like SimPoint can be used to find a small set of samples that represent the majority of the program's execution. Architectures can be compared by simulating their behavior on the code samples selected by SimPoint, to quickly determine which architecture has the best performance. Architectural design space exploration becomes more difficult when different binaries must be used for the same program. These cases arise when evaluating architectures that include ISA extensions, and when evaluating compiler optimizations. This problem domain is the focus of our paper. When multiple binaries are used to evaluate a program, one approach is to create a separate set of simulation points for each binary. This approach works reasonably well for many applications, but breaks down when the simulation points chosen for the different binaries emphasize different parts of the program's execution. This problem can be avoided if simulation points are selected consistently across the different binaries, to ensure that the same parts of program execution are represented in all binaries. In this paper we present an approach that finds a single set of simulation points to be used across all binaries for a single program. This allows for simulation of the same parts of program execution despite changes in the binary due to ISA changes or compiler optimizations },
}

@inproceedings{1620798,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Hamerly, G. and Perelman, E. and Calder, B.},
 year = {2006},
 pages = { 131-- 142},
 publisher = {IEEE},
 title = {Comparing multinomial and k-means clustering for SimPoint},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620798},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620798},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620798.pdf?arnumber=1620798},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { SimPoint,  automatic repetitive pattern finding,  data clustering,  data flow analysis,  k-means clustering,  learning (artificial intelligence),  machine learning,  multinomial clustering,  pattern clustering,  program execution simulation, Algorithm design and analysis, Clustering algorithms, Clustering methods, Computational modeling, Computer science, Computer simulation, Error analysis, Intelligent structures, Machine learning, Machine learning algorithms, },
 abstract = {SimPoint is a technique used to pick what parts of the program's execution to simulate in order to have a complete picture of execution. SimPoint uses data clustering algorithms from machine learning to automatically find repetitive (similar) patterns in a program's execution, and it chooses one sample to represent each unique repetitive behavior. Together these samples represent an accurate picture of the complete execution of the program. SimPoint is based on the k-means clustering algorithm; recent work proposed using a different clustering method based on multinomial models, but only provided a preliminary comparison and analysis. In this work we provide a detailed comparison of using k-means and multinomial clustering for SimPoint. We show that k-means performs better than the recently proposed multinomial clustering approach. We then propose two improvements to the prior multinomial clustering approach in the areas of feature reduction and the picking of simulation points which allow multinomial clustering to perform as well as k-means. We then conclude by examining how to potentially combine multinomial clustering with k-means. },
}

@inproceedings{1620799,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Van Biesbrouckt, M. and Eeckhout, L. and Calder, B.},
 year = {2006},
 pages = { 143-- 153},
 publisher = {IEEE},
 title = {Considering all starting points for simultaneous multithreading simulation},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620799},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620799},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620799.pdf?arnumber=1620799},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { CPI estimate,  SMT architecture optimization,  SMT processor,  SMT simulation,  architecture behavior,  cophase matrix phase analysis,  digital simulation,  matrix algebra,  microprocessor chips,  multi-threading,  multiprocessing programs,  simultaneous multithreading simulation, Analytical models, Computational modeling, Computer architecture, Computer simulation, Microarchitecture, Multithreading, Phase estimation, Surface-mount technology, Throughput, Yarn, },
 abstract = {Commercial processors have support for simultaneous multithreading (SMT), yet little work has been done to provide representative simulation results for SMT. Given a workload, current simulation techniques typically run one combination of those programs from a specific starting offset, or just run one combination of samples across the benchmarks. We have found that the architecture behavior and overall throughput seen can vary drastically based upon the starting points of the different benchmarks. Therefore, to completely evaluate the effect of an SMT architecture optimization on a workload, one would need to simulate many or all of the program combinations from different starting offsets. But exhaustively running all program combinations from many starting offsets is infeasible - even running single programs to completion is often infeasible with modern benchmarks. In this paper we propose an SMT simulation methodology that estimates the average performance over all possible starting points when running multiple programs concurrently on an SMT processor. This is based on our prior co-phase matrix phase analysis and simulation infrastructure. This approach samples all of the unique phase combinations for a set of benchmarks to be run together. Once these phase combinations are sampled, our approach uses these samples, along with a trace of the phase behavior for each program, to provide a CPI estimate of all starting points. This all starting point CPI estimate is precisely calculated in just minutes. },
}

@inproceedings{1430546,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { 0_1-- 0_1},
 publisher = {IEEE},
 title = {ISPASS 2005 IEEE International Symposium on Performance Analysis of Systems and Software},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430546},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430546},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430546.pdf?arnumber=1430546},
 isbn = {0-7803-8965-4},
 language = {English},
 abstract = {},
}

@inproceedings{4919638,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Loh, G.H. and Subramaniam, S. and Yuejian Xie},
 year = {2009},
 pages = {53--64},
 publisher = {IEEE},
 title = {Zesto: A cycle-level simulator for highly detailed microarchitecture exploration},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919638},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919638},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919638.pdf?arnumber=4919638},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {ALU, Coherence, Computational modeling, Computer architecture, Computer simulation, Microarchitecture, Out of order, Pipelines, Processor scheduling, Resource management, Timing, Zesto, bypass network contention, cache storage, cache/memory hierarchy, computer architecture, computer architecture, cycle-level simulator, microarchitecture exploration, multicore cache coherence designs, out-of-order scheduling, pipeline model, pipeline processing, processor organizations, processor pipeline, processor scheduling, resource management, timing simulator, },
 abstract = {For academic computer architecture research, a large number of publicly available simulators make use of relatively simple abstractions for the microarchitecture of the processor pipeline. For some types of studies, such as those for multi-core cache coherence designs, a simple pipeline model may suffice. For detailed microarchitecture research, such as those that are sensitive to the exact behavior of out-of-order scheduling, ALU and bypass network contention, and resource management (e.g., RS and ROB entries), an over-simplified model is not representative of modern processor organizations. We present a new timing simulator that models a modern x86 microarchitecture at a very low level, including out-of-order scheduling and execution that much more closely mirrors current implementations, a detailed cache/memory hierarchy, as well as many x86-specific microarchitecture features (e.g., simple vs. complex decoders, micro-op decomposition and fusion, microcode lookup overhead for long/complex x86 instructions). },
}

@inproceedings{1620792,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Nookala, V. and Ying Chen and Lilja, D.J. and Sapatnekar, S.S.},
 year = {2006},
 pages = { 80-- 88},
 publisher = {IEEE},
 title = {Comparing simulation techniques for microarchitecture-aware floorplanning},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620792},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620792},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620792.pdf?arnumber=1620792},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { IPC-optimal global placement,  circuit layout CAD,  computer architecture,  discrete optimization problem,  floorplanning optimization,  microarchitecture enhancement,  microarchitecture optimization,  microarchitecture-aware floorplanning,  microprocessor,  microprocessor chips,  optimisation,  physical design,  runtime reduction,  simulation technique,  statistical sampling,  virtual machines, Delay, Flip-flops, Microarchitecture, Microprocessors, Pipeline processing, Runtime, Sampling methods, System buses, System performance, Wires, },
 abstract = {Due to the long simulation times of the reference input sets, microarchitects resort to alternative techniques to speed up cycle-accurate simulations. However, the reduction in the runtimes comes with an associated loss of accuracy in replicating the characteristics of the reference sets. In addition, the effect of these inaccuracies on the overall performance can vary across different microarchitecture optimizations or enhancements. In this work, we study and compare two such techniques, reduced input sets and statistical sampling, in the context of microarchitecture-aware floorplanning, a physical design stage, where the objective is to find an IPC-optimal global placement of the blocks of a microprocessor. The variation in the IPC results due the insertion of additional flip-flops on some across-chip wires of the processor that have multicycle delays in nanometer technology nodes. The objective of IPC-aware floorplanning is to minimize the amount of pipelining required by the system buses that are critical in determining the system performance. Our results indicate that, although the two techniques exhibit contrasting behavior in quantifying the criticality of bus latencies, the ensuing floorplanning optimization process results in almost identical performance improvements for both reduced input sets and sampling. The reason behind this is that, for discrete optimization problems such as IPC-aware floorplanning, a reasonably accurate relative ordering of performance bottlenecks is sufficient, absolute accuracy is not necessary. },
}

@inproceedings{1620793,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Berg, E. and Zeffer, H. and Hagersten, E.},
 year = {2006},
 pages = { 89-- 99},
 publisher = {IEEE},
 title = {A statistical multiprocessor cache model},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620793},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620793},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620793.pdf?arnumber=1620793},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { architecture simulation,  cache storage,  data locality analysis,  general-purpose microprocessors,  huge memory-system design space,  mathematical memory-system model,  microprocessor chips,  multi-threading,  multiprocessing systems,  multithreaded application,  parallel application,  statistical analysis,  statistical multiprocessor cache model, Application software, Data analysis, Feedback, Hardware, Mathematical model, Microprocessors, Predictive models, Programming profession, Software tools, Yarn, },
 abstract = {The introduction of general-purpose microprocessors running multiple threads will put a focus on methods and tools helping a programmer to write efficient parallel applications. Such a tool should be fast enough to meet a software developer's need for short turn-around time, but also be accurate and flexible enough to provide trend-correct and intuitive feedback. This paper presents a novel sample-based method for analyzing the data locality of a multithreaded application. Very sparse data is collected during a single execution of the studied application. The architectural-independent information collected during the execution is fed to a mathematical memory-system model for predicting the cache miss ratio. The sparse data can be used to characterize the application's data locality with respect to almost any possible memory system, such as complicated multiprocessor multilevel cache hierarchies. Any combination of cache size, cache-line size and degree of sharing can be modeled. Each modeled design point takes only a fraction of a second to evaluate, even though the application from which the sampled data was collected may have executed for hours. This makes the tool not just usable for software developers, but also for hardware developers who need to evaluate a huge memory-system design space. The accuracy of the method is evaluated using a large number of commercial and technical multi-threaded applications. The result produced by the algorithm is shown to be consistent with results from a traditional (and much slower) architecture simulation. },
}

@inproceedings{1620790,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Loh, G.H.},
 year = {2006},
 pages = { 59-- 69},
 publisher = {IEEE},
 title = {Revisiting the performance impact of branch predictor latencies},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620790},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620790},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620790.pdf?arnumber=1620790},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { branch prediction latency,  hardware complexity,  parallel architectures,  performance evaluation,  performance impact,  pipeline processing,  pipelined processors,  processor performance,  update latency, Accuracy, Circuits, Clocks, Delay, Educational institutions, Feeds, Frequency, Hardware, Pipeline processing, },
 abstract = {Branch predictors play a critical role in the performance of modern processors, and the prediction accuracy is known to be the most important attribute of such predictors. However, the latency of the predictor can also have a profound impact on performance as well. In past studies that have considered branch prediction latency, most only consider the latency required to make a prediction. However, in deeply pipelined processors, the latency between prediction and update can also greatly affect performance. In this study, we revisit the performance impact of both of these latencies and demonstrate that update latency can also have a significant impact on performance. We then describe two techniques, multi-overriding and hierarchical updates, to address both latencies which provide 4.4\% and 5.7\% IPC improvements on moderately (20-stage) and deeply (40-stage) pipelined processors, respectively, for minimal hardware complexity. },
}

@inproceedings{1430547,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { i-- i},
 publisher = {IEEE},
 title = {Copyright page},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430547},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430547},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430547.pdf?arnumber=1430547},
 isbn = {0-7803-8965-4},
 language = {English},
 abstract = {},
}

@inproceedings{1620796,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Agrawal, B. and Sherwood, T.},
 year = {2006},
 pages = { 120-- 129},
 publisher = {IEEE},
 title = {Modeling TCAM power for next generation network devices},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620796},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620796},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620796.pdf?arnumber=1620796},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { ASIC,  SRAM,  SRAM chips,  TCAM power modeling,  Ternary CAM,  advanced algorithms,  computer networks,  content addressable memory,  content-addressable storage,  dynamic power consumption,  general purpose machines,  industrial TCAM datasheets,  large TCAM,  large data structures,  network algorithms,  network processors,  next generation network devices,  next-generation network devices,  power consumption,  power management, Application software, Classification algorithms, Computer networks, Data structures, Energy consumption, Energy management, Next generation networking, Pattern analysis, Performance analysis, Throughput, },
 abstract = {Applications in computer networks often require high throughput access to large data structures for lookup and classification. Many advanced algorithms exist to speed these search primitives on network processors, general purpose machines, and even custom ASICs. However, supporting these applications with standard memories requires very careful analysis of access patterns, and achieving worst case performance can be quite difficult and complex. A simple solution is often possible if a Ternary CAM (content addressable memory) is used to perform a fully parallel search across the entire data set. Unfortunately, this parallelism means that large portions of the chip are switching during each cycle, causing large amounts of power to be consumed. While researchers have begun to explore new ways of managing the power consumption, quantifying design alternatives is difficult due to a lack of available models. In this paper, we examine the structure inside a modern TCAM and present a simple, yet accurate, power model. We present techniques to estimate the dynamic power consumption of a large TCAM. We validate the model using industrial TCAM datasheets and prior published works. We present an extensive analysis of the model by varying various architectural parameters. We also describe how new network algorithms have the potential to address the growing problem of power management in next-generation network devices. },
}

@inproceedings{1620797,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Vernon, M.K.},
 year = {2006},
 publisher = {IEEE},
 title = {Quantitative system design},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620797},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620797},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620797.pdf?arnumber=1620797},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { analytic models,  client large-scale Internet applications,  commercially important architectures,  commercially important systems,  communication protocols,  competitive systems engineering,  complex behavior,  complex large-scale grid applications,  complex message routing,  computer networks,  correlated packet arrivals,  highly bursty packet arrivals,  message blocking,  message passing,  packet switching,  protocols,  quantitative system design,  workload models, Board of Directors, Computer networks, Computer science, Concurrent computing, Distributed computing, High performance computing, Large-scale systems, Modeling, Performance analysis, Routing protocols, },
 abstract = {Summary form only given. This talk provides a 20-year perspective on the use of analytic models to design of a wide range of commercially important architectures and systems with complex behavior. These systems include resources with highly bursty and/or correlated packet arrivals, communication protocols with complex routing and blocking of messages, resources that are configured for a very high probability (e.g., 0.9999) of providing immediate service to each arriving client, and complex large-scale grid/Internet applications. The examples illustrate some guiding principles for model development, and show that the models can be relatively easy to develop. More importantly, the models can be highly accurate - often more accurate than simulation, and sometimes more accurate than the system implementation! The examples also illustrate that the models can provide unique insight into system design as well as significant new system functionality. In other words, analytic models are a key tool for competitive systems engineering. Time permitting, the talk includes some important observations about workload models, and some ways to avoid key pitfalls in simulation. },
}

@inproceedings{1620794,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Muralimanohar, N. and Ramani, K. and Balasubramonian, R.},
 year = {2006},
 pages = { 100-- 111},
 publisher = {IEEE},
 title = {Power efficient resource scaling in partitioned architectures through dynamic heterogeneity},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620794},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620794},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620794.pdf?arnumber=1620794},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { clustered architecture,  computer architecture,  computer power supplies,  dynamic frequency scaling,  dynamic heterogeneity,  microprocessor chips,  partitioned architecture,  peak temperature reduction,  power consumption,  power efficient resource scaling,  processor power dissipation, Clocks, Computer architecture, Delay, Energy consumption, Frequency, Microprocessors, Power dissipation, Registers, Scalability, Temperature, },
 abstract = {The ever increasing demand for high clock speeds and the desire to exploit abundant transistor budgets have resulted in alarming increases in processor power dissipation. Partitioned (or clustered) architectures have been proposed in recent years to address scalability concerns in future billion-transistor microprocessors. Our analysis shows that increasing processor resources in a clustered architecture results in a linear increase in power consumption, while providing diminishing improvements in single-thread performance. To preserve high performance to power ratios, we claim that the power consumption of additional resources should be in proportion to the performance improvements they yield. Hence, in this paper, we propose the implementation of heterogeneous clusters that have varying delay and power characteristics. A cluster's performance and power characteristic is tuned by scaling its frequency and novel policies dynamically assign frequencies to clusters, while attempting to either meet a fixed power budget or minimize a metric such as Energy \&times; Delay<sup>2</sup> (ED<sup>2</sup>). By increasing resources in a power-efficient manner, we observe an 11\% improvement in ED<sup>2</sup> and a 22.4\% average reduction in peak temperature, when compared to a processor with homogeneous units. Our proposed processor model also provides strategies to handle thermal emergencies that have a relatively low impact on performance. },
}

@inproceedings{1620795,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Huaping Wang and Yao Guo and Koren, I. and Krishna, C.M.},
 year = {2006},
 pages = { 112-- 119},
 publisher = {IEEE},
 title = {Compiler-based adaptive fetch throttling for energy-efficiency},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620795},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620795},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620795.pdf?arnumber=1620795},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { chip-wide energy consumption,  compiler-based adaptive fetch throttling,  decode/issue difference,  dynamically scheduled superscalar processors,  flow-based throttling,  front-end instruction delivery,  program compilers,  redundant fetching,  software fetch throttling,  storage management, Decoding, Degradation, Dynamic scheduling, Energy consumption, Energy efficiency, Out of order, Performance loss, Pipelines, Processor scheduling, Runtime, },
 abstract = {Front-end instruction delivery accounts for a significant fraction of energy consumption in dynamically scheduled superscalar processors. Different front-end throttling techniques have been introduced to reduce the chip-wide energy consumption caused by redundant fetching. Hardware-based techniques, such as flow-based throttling, could reduce the energy consumption considerably, but with a high performance loss. On the other hand, compiler-based IPC-estimation-driven software fetch throttling (CFT) techniques result in relatively low performance degradation, which is desirable for high-performance processors. However, their energy savings are limited by the fact that they typically use a predefined fixed low IPC-threshold to control throttling. In this paper, we propose a compiler-based adaptive fetch throttling (CAFT) technique that allows changing the throttling threshold dynamically at runtime. Instead of using a fixed threshold, our technique uses the decode/issue difference (DID) to assist the fetch throttling decision based on the statically estimated IPC. Changing the threshold dynamically makes it possible to throttle at a higher estimated IPC, thus increasing the throttling opportunities and resulting in larger energy savings. We demonstrate that CAFT could increase the energy savings significantly compared to CFT, while preserving its benefit of low performance loss. Our simulation results show that the proposed technique doubles the energy-delay product (EDP) savings compared to the fixed threshold throttling and achieves a 6.1\% average EDP saving. },
}

@inproceedings{1430548,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { ii-- iii},
 publisher = {IEEE},
 title = {General chairs' message},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430548},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430548},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430548.pdf?arnumber=1430548},
 isbn = {0-7803-8965-4},
 language = {English},
 abstract = {},
}

@inproceedings{1430549,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { iv-- iv},
 publisher = {IEEE},
 title = {Message from the program chair},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430549},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430549},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430549.pdf?arnumber=1430549},
 isbn = {0-7803-8965-4},
 language = {English},
 abstract = {},
}

@inproceedings{1620812,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Albonesi, D.H.},
 year = {2006},
 pages = { iv-- v},
 publisher = {IEEE},
 title = {Message from the Program Chair},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620812},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620812},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620812.pdf?arnumber=1620812},
 isbn = {1-4244-0186-0},
 language = {English},
 abstract = {},
}

@inproceedings{1430574,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Li Zhao and Iyer, R. and Makineni, S. and Bhuyan, L.},
 year = {2005},
 pages = {197--206},
 publisher = {IEEE},
 title = {Anatomy and Performance of SSL Processing},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430574},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430574},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430574.pdf?arnumber=1430574},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Algorithm design and analysis, Anatomy, Authentication, Banking, Costs, Cryptographic protocols, Cryptography, ISA-hardware support, Internet, Performance analysis, Privacy, Secure Sockets Layer protocol, Sockets, architectural analysis, client-server systems, computer architecture, cryptographic algorithms, cryptography, data privacy, data transfer, e-commerce, instruction sets, message authentication, open systems, protocols, secure communications, session negotiation, },
 abstract = {A wide spectrum of e-commerce (B2B/B2C), banking, financial trading and other business applications require the exchange of data to be highly secure. The Secure Sockets Layer (SSL) protocol provides the essential ingredients of secure communications - privacy, integrity and authentication. Though it is well-understood that security always comes at the cost of performance, these costs depend on the cryptographic algorithms. In this paper, we present a detailed description of the anatomy of a secure session. We analyze the time spent on the various cryptographic operations (symmetric, asymmetric and hashing) during the session negotiation and data transfer. We then analyze the most frequently used cryptographic algorithms (RSA, AES, DES, 3DES, RC4, MD5 and SHA-1). We determine the key components of these algorithms (setting up key schedules, encryption rounds, substitutions, permutations, etc) and determine where most of the time is spent. We also provide an architectural analysis of these algorithms, show the frequently executed instructions and discuss the ISA/hardware support that may be beneficial to improving SSL performance. We believe that the performance data presented in this paper is useful to performance analysts and processor architects to help accelerate SSL performance in future processors },
}

@inproceedings{842288,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Ramos, L. and Ibanez, P. and Vinals, V. and Llaberia, J.M.},
 year = {2000},
 pages = {101--108},
 publisher = {IEEE},
 title = {Modeling load address behaviour through recurrences},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842288},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842288},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842288.pdf?arnumber=842288},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Data structures, Delay, Ear, High level languages, Instruction sets, Load modeling, Out of order, Proposals, Reduced instruction set computing, Statistics, address predictor, address streams, compressed sparse arrays, data prefetches, data structures, dense linked data structures, linear link, load address behaviour modelling, load instruction, memory hierarchy design, processor hierarchy design, recurrences, scientific applications, sparse applications, symbolic applications, },
 abstract = {Addresses of load instructions exhibit regularity in their behaviour which is modelled through several models (locality repetitive patterns, etc.) and exploited in processor and memory hierarchy design. Nevertheless, sparse and symbolic applications are intensive in addressing patterns not entirely covered by current models. In this work we introduce a new recurrence among load pairs called ``linear link" in order to identify more regularity from such applications. A linear link is a type of recurrence between the value read by a (producer) load and the address issued by a (consumer) load, which is detected tracking on-the-fly dependencies among loads. We consider a broad workload (Nas, Olden, Perfect, Spec95 and IAbench) and conclude that linear links together with stride recurrences can identify many address streams in symbolic and scientific applications traversing either dense, linked data structures or compressed forms of sparse arrays. The two recurrence combinations identify more than 90\% of the addresses in more than a half the programs (in 24 our of 55), and more than 75\% of the addresses in 90\% of the programs (50 our of 55). Finally, we show several measures related to the use of linear links as address predictors for executing loads speculatively and for issuing data prefetches (prediction distance ahead capacity, etc.) },
}

@inproceedings{5452084,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Mitchell, N.},
 year = {2010},
 pages = {1--1},
 publisher = {IEEE},
 title = {The big pileup},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452084},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452084},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452084.pdf?arnumber=5452084},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Assembly, Databases, Information retrieval, Java, Java optimizers, Large-scale systems, Libraries, Programming profession, Scalability, Systems engineering and theory, Visualization, database records, garbage collectors, large-scale artifacts programming, local coding decisions, pileup, programming, reusable libraries, software tools, },
 abstract = {Programmers no longer write monolithic applications, they assemble code from a sea of reusable libraries and frameworks. This layered process of construction has a magnifying effect on local coding decisions. Piece by innocent piece, seemingly harmless constant factors pile up. They become part of an interstitial excess, marbled throughout the code and APIs, and difficult to remove. It is not uncommon for large applications to miss their performance targets by an order of magnitude. We commonly see web requests create objects and invoke methods by the hundreds of thousands to retrieve and format a few database records. Current Java optimizers and garbage collectors don't address many of these systemic problems. This talk discusses these issues, via many examples, with a goal of motivating research on the programming of large-scale artifacts in a way that local, often ad hoc, decisions can be unwound, rather then pile up, in the large. },
}

@inproceedings{990668,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Larson, E. and Chatterjee, S. and Austin, T.},
 year = {2001},
 pages = {1--9},
 publisher = {IEEE},
 title = {MASE: a novel infrastructure for detailed microarchitectural modeling},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990668},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990668},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990668.pdf?arnumber=990668},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Computational modeling, Computer aided instruction, Computer architecture, Computer science, Computer simulation, Emulation, Hardware, Microarchitecture, Space technology, Timing, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990668.png" border="0"> },
}

@inproceedings{990669,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Eeckhout, L. and De Bosschere, K.},
 year = {2001},
 pages = {10--17},
 publisher = {IEEE},
 title = {Early design phase power/performance modeling through statistical simulation},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990669},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990669},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990669.pdf?arnumber=990669},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Aerospace industry, Cooling, Design methodology, Energy consumption, Information systems, Microprocessors, Packaging, Power system modeling, Space exploration, Time to market, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990669.png" border="0"> },
}

@inproceedings{842299,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Junehwa Song and Levy-Abegnoli, E. and Iyengar, A. and Dias, D.},
 year = {2000},
 pages = {184--192},
 publisher = {IEEE},
 title = {Design alternatives for scalable Web server accelerators},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842299},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842299},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842299.pdf?arnumber=842299},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Acceleration, Application software, Availability, Cache memory, File systems, Kernel, Operating systems, TCP router, TCP routing techniques, Throughput, Uniform resource locators, Web server, Web server performance, aggregate throughput, cache memory distribution, cache node CPU cycles, cache replacement algorithm, cache replacement policies, cache storage, cached object, content based routing, content router, data caching, data delivery methods, design alternatives, distributed memory systems, embedded operating system, embedded systems, file servers, hot object replication, information resources, operating systems (computers), scalable Web server accelerators, throughput ranges, transport protocols, },
 abstract = {We study design alternatives for, and describe implementations and performance of, a scalable and highly available Web server accelerator. The accelerator runs under an embedded operating system and improves Web server performance by caching data. The basic design alternatives include a content router or a TCP router (without content routing) in front of a set of Web cache accelerator nodes, with the cache memory distributed across the accelerator nodes. Content based routing reduces cache node CPU cycles but can make the front-end router a bottleneck. With the TCP router, a request for a cached object may initially be sent to the wrong cache node; this results in larger cache node CPU cycles, but can provide a higher aggregate throughput, because the TCP router becomes a bottleneck at a higher throughput than the content router. Based on measurement of implementations, we quantify the throughput ranges in which different designs are preferable. We also examine a combination of content based and TCP routing techniques. We examine optimizations, such as different communication and data delivery methods, replication of hot objects, and cache replacement policies that take into account the fact that there might be different bottlenecks in the system at different times; depending upon which resource is likely to become a bottleneck, a different cache replacement algorithm is applied },
}

@inproceedings{5452013,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Wong, H. and Papadopoulou, M.-M. and Sadooghi-Alvandi, M. and Moshovos, A.},
 year = {2010},
 pages = {235--246},
 publisher = {IEEE},
 title = {Demystifying GPU microarchitecture through microbenchmarking},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452013},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452013},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452013.pdf?arnumber=5452013},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Clocks, Computer architecture, Delay, GPU microarchitecture, Hardware, Kernel, Microarchitecture, Nvidia GT200 GPU, Performance analysis, Registers, Samarium, Yarn, computer graphics, coprocessors, graphics processors, microbenchmarking, },
 abstract = {Graphics processors (GPU) offer the promise of more than an order of magnitude speedup over conventional processors for certain non-graphics computations. Because the GPU is often presented as a C-like abstraction (e.g., Nvidia's CUDA), little is known about the characteristics of the GPU's architecture beyond what the manufacturer has documented. This work develops a microbechmark suite and measures the CUDA-visible architectural characteristics of the Nvidia GT200 (GTX280) GPU. Various undisclosed characteristics of the processing elements and the memory hierarchies are measured. This analysis exposes undocumented features that impact program performance and correctness. These measurements can be useful for improving performance optimization, analysis, and modeling on this architecture and offer additional insight on the decisions made in developing this GPU. },
}

@inproceedings{5452016,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Ozturk, C. and Sendag, R.},
 year = {2010},
 pages = {213--222},
 publisher = {IEEE},
 title = {An analysis of hard to predict branches},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452016},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452016},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452016.pdf?arnumber=5452016},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Accuracy, Biomedical computing, Biomedical engineering, Graphics, High performance computing, History, Mibench benchmarks, Performance analysis, Power engineering computing, Runtime, SPEC CPU 2000, Taxonomy, branch predictors, computer architecture, data structures, linked list data structures, pattern classification, source code analysis, },
 abstract = {Branch prediction accuracy remains to be critical for high performance and low power. Prior work has studied causes of branch mispredictions in order to provide insights into how better branch predictors can be designed. However, most of the previous works have only considered run-time classification of branch mispredictions, leaving a large number of mispredictions in an unknown category. For more comprehensive analysis, in this paper, we present a detailed source code analysis of branch mispredictions for SPEC CPU 2000 and Mibench benchmarks. Our analysis show that constant loop exits, insufficient history lengths, wrong-type history, array access/pointer references, complex linked list data structures, changing function inputs, and varying loop counts are the major causes for most of the branch mispredictions. We further show that most mispredictions have repetitive patterns that suggest different design strategies for future branch predictors. },
}

@inproceedings{1190244,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Iyer, R.},
 year = {2003},
 pages = { 176-- 185},
 publisher = {IEEE},
 title = {Performance implications of chipset caches in web servers},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190244},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190244},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190244.pdf?arnumber=1190244},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { Internet,  Internet,  Internet servers,  cache storage,  chipset caches,  file servers,  memory requests,  performance,  performance evaluation,  prefetching,  server chipset,  storage management,  web server, Councils, Delay, Internet, Network servers, Prefetching, Process design, Read-write memory, Standards development, Throughput, Web server, },
 abstract = {As Internet usage continues to expand rapidly, careful attention needs to be paid to the design of Internet servers for achieving high performance and end-user satisfaction. In this paper, with the aim of improving memory system performance of Internet servers, we propose and evaluate various design alternatives for "chipset caches", a shared cache layer embedded within a server chipset. Using our trace-based cache simulation framework (CASPER) and SPECweb99 as a representative workload for web servers, we present the performance implications of chipset caches in a front-end dual-processor web server. We start by analyzing the improvement gained by caching the data from processor-initiated requests alone. We study the sensitivity to basic cache parameters (such as cache size and associativity) and also study the impact of prefetching into the chipset cache. We then present the performance implications of routing memory requests initiated by I/O devices through the chipset cache. Finally, we also study the implications of making the chipset cache inclusive. Based on detailed simulation data and its implications on system level performance, this paper shows that chipset caches have significant potential for future Internet servers. },
}

@inproceedings{5452014,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {},
 year = {2010},
 pages = {247--248},
 publisher = {IEEE},
 title = {Author index},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452014},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452014},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452014.pdf?arnumber=5452014},
 isbn = {978-1-4244-6023-6},
 language = {English},
 abstract = {},
}

@inproceedings{842283,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Chia-Tien Dan Lo and Srisa-An, W. and Chang, J.M.},
 year = {2000},
 pages = {64--69},
 publisher = {IEEE},
 title = {A quantitative simulator for dynamic memory managers},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842283},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842283},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842283.pdf?arnumber=842283},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Application software, Art, Computational modeling, Computer science, Java, Libraries, Memory management, Robustness, Software performance, Software systems, allocation, dynamic memory management schemes, dynamic memory management traces, memory tracing techniques, object-oriented programming, performance metrics, quantitative simulator, software engineering, storage allocation, storage management, system performance evaluation, virtual machines, },
 abstract = {In the last thirty years, several dynamic memory management schemes have been proposed. Such schemes include first fit, best fit, segregated fit, and buddy systems. Because the performance (speed and memory utilization) of each scheme differs, software engineers often face difficult choices in selecting the most suitable approach for their applications. In this paper, a quantitative simulator for dynamic memory management and memory tracing techniques are presented. This simulator receives dynamic memory management traces and performs allocations according to schemes (first fit, best fit, buddy systems, and segregated fit) defined by the user. At the end of each simulation run, different performance metrics are reported to the users. By using this approach, software engineers can evaluate system performance and decide which algorithm is the most suitable for their applications },
}

@inproceedings{1620802,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Jerger, N.D.E. and Hill, E.L. and Lipasti, M.H.},
 year = {2006},
 pages = { 177-- 188},
 publisher = {IEEE},
 title = {Friendly fire: understanding the effects of multiprocessor prefetches},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620802},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620802},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620802.pdf?arnumber=1620802},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { content-directed data prefetching,  exclusive prefetching,  hardware prefetching,  memory latency,  multiprocessing systems,  multiprocessor prefetches,  multiprocessor system,  performance degradation,  permission thrashing,  prefetching scheme,  sequential prefetching,  storage management,  wrong path prefetching, Degradation, Delay, Filtering algorithms, Fires, Hardware, Multiprocessing systems, Permission, Prefetching, Taxonomy, Upper bound, },
 abstract = {Modern processors attempt to overcome increasing memory latencies by anticipating future references and prefetching those blocks from memory. The behavior and possible negative side effects of prefetching schemes are fairly well understood for uniprocessor systems. However, in a multiprocessor system a prefetch can steal read and/or write permissions for shared blocks from other processors, leading to permission thrashing and overall performance degradation. In this paper, we present a taxonomy that classifies the effects of multiprocessor prefetches. We also present a characterization of the effects of four different hardware prefetching schemes - sequential prefetching, content-directed data prefetching, wrong path prefetching and exclusive prefetching - in a bus-based multiprocessor system. We show that accuracy and coverage are inadequate metrics for describing prefetching in a multiprocessor; rather, we also need to understand what fraction of prefetches interferes with remote processors. We present an upper bound on the performance of various prefetching algorithms if no harmful prefetches are issued, and suggest prefetch filtering schemes that can accomplish this goal. },
}

@inproceedings{1291349,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Patt, Y.},
 year = {2004},
 pages = { 1-- 1},
 publisher = {IEEE},
 title = {Opening and keynote 1},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291349},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291349},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291349.pdf?arnumber=1291349},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = {Biographies, Computer architecture, Education, Microarchitecture, Microprocessors, Performance analysis, },
 abstract = {},
}

@inproceedings{1620800,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Bell, R.H., Jr. and Bhatia, R.R. and John, L.K. and Stuecheli, J. and Griswell, J. and Tu, P. and Capps, L. and Blanchard, A. and Thai, R.},
 year = {2006},
 pages = { 154-- 165},
 publisher = {IEEE},
 title = {Automatic testcase synthesis and performance model validation for high performance PowerPC processors},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620800},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620800},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620800.pdf?arnumber=1620800},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { IBM PowerPC microprocessor,  POWERS chip,  automatic testcase synthesis,  automatic testing,  high performance PowerPC processors,  microcomputers,  microprocessor chips,  performance evaluation,  performance model validation, Automatic testing, Bandwidth, Benchmark testing, Delay, Hardware, High performance computing, Microprocessors, Power engineering computing, Power system modeling, Runtime, },
 abstract = {The latest high-performance IBM PowerPC microprocessor, the POWERS chip, poses challenges for performance model validation. The current state-of-the-art is to use simple hand-coded bandwidth and latency testcases, but these are not comprehensive for processors as complex as the POWER5 chip. Applications and benchmark suites such as SPEC CPU are difficult to set up or take too long to execute on functional models or even on detailed performance models. We present an automatic testcase synthesis methodology to address these concerns. By basing testcase synthesis on the workload characteristics of an application, source code is created that largely represents the performance of the application, but which executes in a fraction of the runtime. We synthesize representative PowerPC versions of the SPEC2000, STREAM, TPC-C and Java benchmarks, compile and execute them, and obtain an average IPC within 2.4\% of the average IPC of the original benchmarks and with many similar average workload characteristics. The synthetic testcases often execute two orders of magnitude faster than the original applications, typically in less than 300K instructions, making performance model validation for today's complex processors feasible. },
}

@inproceedings{4919636,
 booktitle = {Performance Analysis of Systems and Software, 2009. ISPASS 2009. IEEE International Symposium on},
 author = {Agarwal, N. and Krishna, T. and Li-Shiuan Peh and Jha, N.K.},
 year = {2009},
 pages = {33--42},
 publisher = {IEEE},
 title = {GARNET: A detailed on-chip network model inside a full-system simulator},
 date = {26-28 April 2009},
 doi = {10.1109/ISPASS.2009.4919636},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4919636},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4907867/4919623/04919636.pdf?arnumber=4919636},
 isbn = {978-1-4244-4184-6},
 language = {English},
 keywords = {Computational modeling, GARNET, GEMS full-system simulation framework, Garnets, Microprocessors, Multiprocessor interconnection networks, Network-on-a-chip, Power system interconnection, Proposals, Switches, System-on-a-chip, Wire, chip multiprocessors, computation-centric design, cycle-accurate interconnection network model, detailed on-chip network model, full-system evaluation framework, full-system simulator, interconnect power, memory hierarchy, microprocessor chips, microprocessor design, multiprocessing systems, multiprocessor interconnection networks, single-cycle on-chip communication, transistor miniaturization, transistor power, uniprocessor design, virtual channel flow control, wire delay, },
 abstract = {Until very recently, microprocessor designs were computation-centric. On-chip communication was frequently ignored. This was because of fast, single-cycle on-chip communication. The interconnect power was also insignificant compared to the transistor power. With uniprocessor designs providing diminishing returns and the advent of chip multiprocessors (CMPs) in mainstream systems, the on-chip network that connects different processing cores has become a critical part of the design. Transistor miniaturization has led to high global wire delay, and interconnect power comparable to transistor power. CMP design proposals can no longer ignore the interaction between the memory hierarchy and the interconnection network that connects various elements. This necessitates a detailed and accurate interconnection network model within a full-system evaluation framework. Ignoring the interconnect details might lead to inaccurate results when simulating a CMP architecture. It also becomes important to analyze the impact of interconnection network optimization techniques on full system behavior. In this light, we developed a detailed cycle-accurate interconnection network model (GARNET), inside the GEMS full-system simulation framework. GARNET models a classic five-stage pipelined router with virtual channel (VC) flow control. Microarchitectural details, such as flit-level input buffers, routing logic, allocators and the crossbar switch, are modeled. GARNET, along with GEMS, provides a detailed and accurate memory system timing model. To demonstrate the importance and potential impact of GARNET, we evaluate a shared and private L2 CMP with a realistic state-of-the-art interconnection network against the original GEMS simple network. The objective of the evaluation was to figure out which configuration is better for a particular workload. We show that not modeling the interconnect in detail might lead to an incorrect outcome. We also evaluate Express Virtual Channels (EVCs), an on-ch- ip network flow control proposal, in a full-system fashion. We show that in improving on-chip network latency-throughput, EVCs do lead to better overall system runtime, however, the impact varies widely across applications. },
}

@inproceedings{1620806,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Feitelson, D.G. and Tsafrir, D.},
 year = {2006},
 pages = { 221-- 230},
 publisher = {IEEE},
 title = {Workload sanitation for performance evaluation},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620806},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620806},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620806.pdf?arnumber=1620806},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { multiclass workloads,  performance evaluation,  performance evaluation,  productions systems,  resource allocation,  workload anomalies,  workload flurries,  workload modeling,  workload sanitation, Character recognition, Computer science, Design optimization, Large-scale systems, Monitoring, Production systems, Reliability engineering, Sanitary engineering, Statistical analysis, Surges, },
 abstract = {The performance of computer systems depends, among other things, on the workload. Performance evaluations are therefore often done using logs of workloads on current productions systems, under the assumption that such real workloads are representative and reliable; likewise, workload modeling is typically based on real workloads. We show, however, that real workloads may also contain anomalies that make them non-representative and unreliable. This is a special case of multi-class workloads, where one class is the "real" workload which we wish to use in the evaluation, and the other class contaminates the log with "bogus" data. We provide several examples of this situation, including a previously unrecognized type of anomaly we call "workload flurries": surges of activity with a repetitive nature, caused by a single user, that dominate the workload for a relatively short period. Using a workload with such anomalies in effect emphasizes rare and unique events (e.g. occurring for a few days out of two years of logged data), and risks optimizing the design decision for the anomalous workload at the expense of the normal workload. Thus we claim that such anomalies should be removed from the workload before it is used in evaluations, and that ignoring them is actually an unjustifiable approach. },
}

@inproceedings{1620807,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {del Barrio, V.M. and Gonzalez, C. and Roca, J. and Fernandez, A. and Espasa E},
 year = {2006},
 pages = { 231-- 241},
 publisher = {IEEE},
 title = {ATTILA: a cycle-level execution-driven simulator for modern GPU architectures},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620807},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620807},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620807.pdf?arnumber=1620807},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { ATTILA,  GPU simulation model,  Open GL framework,  computer graphic equipment,  computer graphics,  cycle-level execution-driven simulator,  functional emulator,  modern GPU architectures,  performance debugging tool,  performance evaluation,  program debugging,  signal trace visualizer,  timing simulator, Computational modeling, Computer architecture, Feeds, Graphics, Hardware, Kernel, Layout, Microarchitecture, Rendering (computer graphics), Timing, },
 abstract = {The present work presents a cycle-level execution-driven simulator for modern GPU architectures. We discuss the simulation model used for our GPU simulator, based in the concept of boxes and signals, and the relation between the timing simulator and the functional emulator. The simulation model we use helps to increase the accuracy and reduce the number of errors in the timing simulator while allowing for an easy extensibility of the simulated GPU architecture. We also introduce the OpenGL framework used to feed the simulator with traces from real applications (UT2004, Doom3) and a performance debugging tool (Signal Trace Visualizer). The presented ATTILA simulator supports the simulation of a whole range of GPU configurations and architectures, from the embedded segment to the high end PC segment, supporting both the unified and non unified shader architectural models. },
}

@inproceedings{1620804,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Rui Zhang and Budimlic, Z. and Kennedy, K.},
 year = {2006},
 pages = { 199-- 210},
 publisher = {IEEE},
 title = {Performance modeling and prediction for scientific Java applications},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620804},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620804},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620804.pdf?arnumber=1620804},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { Java,  Java execution model,  algorithm complexity model,  distributed computing,  garbage collection,  grid computing,  load balancing,  memory hierarchy,  natural sciences computing,  performance modeling,  performance prediction,  platform-independent execution model,  predictability point,  resource allocation,  scientific Java application,  scientific computing,  software performance evaluation,  storage management,  unpredictability point,  virtual machine execution model, Distributed computing, Grid computing, Hardware, Internet, Java, Load management, Predictive models, Processor scheduling, Scientific computing, Virtual machining, },
 abstract = {With the expansion of the Internet, the grid has become an attractive platform for scientific computing. Java, with a platform-independent execution model and built-in support for distributed computing is an inviting choice for implementation of applications intended for grid execution. Recent work has shown that an accurate performance model combined with a load-balancing scheduling strategy can significantly improve the performance of distributed applications on a heterogeneous computing platform, such as the grid. However, current performance modeling techniques are not suitable for Java applications, as the virtual machine execution model presents several difficulties: 1) a significant amount of time is spent on compilation at the beginning of the execution, 2) the virtual machine continuously profiles and recompiles the code during the execution, 3) garbage collection can have unpredictable effects on memory hierarchy, 4) some applications can spend more time garbage collecting than computing for certain heap sizes and 5) small variations in virtual machine implementation can have a large impact on the application's behavior. In this paper, we present a practical profile-based strategy for performance modeling of Java scientific applications intended for execution on the grid. We introduce two novel concepts for the Java execution model: point of predictability (PoP) and point of unpredictability (PoU). PoP accounts for the volatile nature of the effects of the virtual machine on execution time for small problem sizes. PoU accounts for the effects of garbage collection on certain applications that have a memory footprint that approaches the total heap size. We present an algorithm for determining PoP and PoU for Java applications, given the hardware platform, virtual machine and heap size. We also present a code-instrumentation-based mechanism for building the algorithm complexity model for a given application. We introduce a technique for calibrating this model that is able to accurately predict the execution time of Java programs for problem sizes between PoP and PoU. Our preliminary experiments show that techniques can achieve load balancing with more than 90\% average CPU utilization. },
}

@inproceedings{990690,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Abdelkhalek, A. and Bilas, A. and Moshovos, A.},
 year = {2001},
 pages = {137--146},
 publisher = {IEEE},
 title = {Behavior and performance of interactive multi-player game servers},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990690},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990690},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990690.pdf?arnumber=990690},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Bandwidth, Computer architecture, Delay, Educational institutions, Explosions, Network servers, Scalability, Toy industry, Web and internet services, Web server, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990690.png" border="0"> },
}

@inproceedings{1430577,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Ramaswamy, R. and Ning Weng and Wolf, T.},
 year = {2005},
 pages = {226--235},
 publisher = {IEEE},
 title = {Analysis of Network Processing Workloads},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430577},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430577},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430577.pdf?arnumber=1430577},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computer architecture, Embedded system, IP networks, Internet, Internet, Memory management, Microarchitecture, Network servers, PacketBench, Payloads, Search engines, Statistics, Workstations, embedded systems, microprocessor chips, network processing workloads, packet memory management, parallel architectures, parallel embedded systems, resource allocation, statistical analysis, statistics, storage management, telecommunication network routing, },
 abstract = {Network processing is becoming an increasingly important paradigm as the Internet moves towards an architecture with more complex functionality inside the network. Modern routers not only forward packets, but also process headers and payloads to implement a variety of functions related to security, performance, and customization. It is important to get a detailed understanding of the workloads associated with this processing in order to be able to develop efficient network processing engines. We present a tool called PacketBench, which provides a framework for implementing network processing applications and obtaining an extensive set of workload characteristics. PacketBench provides the support functions to handle various packet traces and manage packet memory. For statistics collection, PacketBench provides the ability to derive a number of microarchitectural and networking related metrics. The understanding of workload details of network processing has many practical applications. As network processing systems move towards highly parallel embedded systems, it is becoming increasingly important to explore the processing requirements of individual packets rather than averaged statistics. We show a range of workload results that focus on individual packets and the variation between them },
}

@inproceedings{1620808,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Albert, S. and Kalms, S. and Weiss, C. and Schramm, A.},
 year = {2006},
 pages = { 242-- 250},
 publisher = {IEEE},
 title = {Acquisition and evaluation of long DDR2-SDRAM access sequences},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620808},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620808},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620808.pdf?arnumber=1620808},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { DDR2-SDRAM access sequences,  DRAM chips,  benchmark characterization,  circuit simulation,  direct memory access,  memory system evaluation,  performance evaluation,  shared memory graphics,  trace driven simulation, Analytical models, Computational modeling, Computer aided manufacturing, Computer simulation, Current measurement, Graphics, Hardware, Logic, SDRAM, Sampling methods, },
 abstract = {Trace driven simulation is extensively used in memory system evaluation. Traditional measurement equipment such as logic analyzers currently lack of the capability to record long memory access sequences (e.g. multiple seconds or even entire benchmark runs) due to their limited sampling depth, without altering system behavior. This paper presents a system, that is capable of recording long access sequences in realtime without affecting system operation. For the first time, a classification of the SPEC CPU2000 benchmark suite along main memory access criteria is provided. Furthermore the impact of shared memory graphics on system performance affecting future system simulation methodology is investigated. },
}

@inproceedings{1620809,
 booktitle = {Performance Analysis of Systems and Software, 2006 IEEE International Symposium on},
 author = {Berube, P. and Amaral, J.N.},
 year = {2006},
 pages = { 251-- 260},
 publisher = {IEEE},
 title = {Aestimo: a feedback-directed optimization evaluation tool},
 date = {19-21 March 2006},
 doi = {10.1109/ISPASS.2006.1620809},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1620809},
 pdf_url = {http://ieeexplore.ieee.org/iel5/10781/33948/01620809.pdf?arnumber=1620809},
 isbn = {1-4244-0186-0},
 language = {English},
 keywords = { Aestimo,  code transformation,  feedback-directed optimization evaluation tool,  open research compiler,  optimising compilers,  optimization logs,  performance evaluation,  software performance evaluation, Large Hadron Collider, Management training, Optimizing compilers, Program processors, Radio access networks, Statistics, Testing, Tiles, Training data, },
 abstract = {Published studies that use feedback-directed optimization (FDO) techniques use either a single input for both training and performance evaluation, or a single input for training and a single input for evaluation. Thus an important question is if the FDO results published in the literature are sensitive to the training and testing input selection. Aestimo is a new evaluation tool that uses a workload of inputs to evaluate the sensitivity of specific code transformations to the choice of inputs in the training and testing phases. Aestimo uses optimization logs to isolate the effects of individual code transformations. It incorporates metrics to determine the effect of training input selection on individual compiler decisions. Besides describing the structure of Aestimo, this paper presents a case study that uses SPEC CINT2000 benchmark programs with the Open Research Compiler (ORC) to investigate the effect of training/testing input selection on in-lining and if-conversion. The experimental results indicate that: (1) training input selection affects the compiler decisions made for these code transformation; (2) the choice of training/testing inputs can have a significant impact on measured performance. },
}

@inproceedings{842289,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Recio, R. and Boyd, W.T.},
 year = {2000},
 pages = {109--115},
 publisher = {IEEE},
 title = {Methodology to optimize the cost/performance of disk subsystems},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842289},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842289},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842289.pdf?arnumber=842289},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Ambient intelligence, Cache storage, Cellular neural networks, Cost function, Councils, Hardware, Ice, Optimization methods, Petroleum, RAID, RAID type, Radio access networks, cost/performance optimization, data analysis, disk configuration, disk size optimization, disk subsystems, file servers, future server systems, high-end enterprise servers, high-end server workloads, performance evaluation, storage hierarchy, storage subsystem, transaction processing, },
 abstract = {The storage hierarchy plays a major role in the price and performance of high-end enterprise servers. In fact, the total price of a high-end server's hardware is dominated by its memory and disk configuration. Similarly, the performance is significantly influenced by the design and configuration of the server's memory and disk subsystems. Given these realities, the design and development of future server systems requires special attention to the storage subsystem. The paper describes a methodology that can be applied to optimize the disk size and RAID type used in key high-end server workloads },
}

@inproceedings{990693,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Wolf, T. and Franklin, M.A.},
 year = {2001},
 pages = {152--159},
 publisher = {IEEE},
 title = {Locality-aware predictive scheduling of network processors},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990693},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990693},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990693.pdf?arnumber=990693},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Communication networks, Computer science, Processor scheduling, Real time systems, Robustness, Scheduling algorithm, System-on-a-chip, Telecommunication network reliability, Throughput, Time measurement, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990693.png" border="0"> },
}

@inproceedings{5452056,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Tournier, J.-C. and Naef, M.},
 year = {2010},
 pages = {109--110},
 publisher = {IEEE},
 title = {Influences of SIMD architectures for scattered data interpolation algorithm},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452056},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452056},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452056.pdf?arnumber=5452056},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Costs, Hardware, Image processing, Image reconstruction, Interpolation, Partial differential equations, SIMD architectures, Scattering, Size measurement, Surface reconstruction, Testing, data handling, data structures, datatypes, instruction sets, interpolation, scattered data interpolation algorithm, single instruction multiple data architecture, },
 abstract = {In this paper, we are investigating the performance of several IDW implementations on different SIMD architectures (Single Instruction Multiple Data). The SIMD architectures addressed in this paper are considered cost effective and readily available on the desktop as compared to super-computers such as the IBM Roadrunner or the Cray XT5. Two main classes of SIMD architectures can be identified from the range of products available now: (a) the architectures that are integrated in the CPU itself, such as SSE or AltiVec; and (b) the architectures located on a dedicated board such as the GPGPUs from Nvidia or ATI. This paper evaluates one SIMD architecture selected from each group. The evaluation is based on the performance measured on each architecture over various datatypes and different problem sizes. },
}

@inproceedings{842298,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Jagiello, J. and Tay, N. and Biddington, B. and Dacray, R.},
 year = {2000},
 pages = {178--183},
 publisher = {IEEE},
 title = {Mobile functionality in a pervasive world},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842298},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842298},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842298.pdf?arnumber=842298},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Asia, Australia, Collaboration, Collaborative work, Communication cables, Information systems, National security, Personal digital assistants, Printers, UIA, agent-like entity, human factors, interactive systems, mobile agent-like entities, mobile computing, mobile functionality, multiple UIA interactions, pervasive computing environment, pervasive world, software agents, tailored interfaces, universal information appliance, user interface, user interfaces, },
 abstract = {K. Eustice et al. (1999) presented the concept of a universal information appliance (UIA), a device capable of dynamically hosting tailored interfaces to the pervasive computing environment. The paper extends this concept by allowing the user to change, modify or improve the tailored interfaces available. This will enable an individual to dynamically create a user interface on the fly and to use it to interact with myriad devices. Alternatively, users will be able to create, also on the fly, mobile agent-like entities that will roam around the network to obtain specified data for the individual. Interactions between multiple UIAs will also be possible. Thus, we can envisage a scenario where an individual will create an agent-like entity tasked to roam around the network, delegating work to different devices, to achieve a desired goal },
}

@inproceedings{842296,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Driesen, K. and Colette, J. and Feng Ji and Jourdain, M. and Fahmi, M. and Ghuneim, A. and Hersi, E. and Kahwa, J. and Khan, H.R. and Kwan, C. and Mahyari, A. and Miecknikowski, J. and Oulmane, M. and Perucic, M. and Pirbay, A. and Solomon, L. and Taoko, J.J. and Lip Hooi Tan and Feng Qian and Honghao Zhang and Lingyan Zhang and Su Zhang and Renner, W.},
 year = {2000},
 pages = {163--171},
 publisher = {IEEE},
 title = {Simplified workload characterization using unified prediction},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842296},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842296},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842296.pdf?arnumber=842296},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Analytical models, Benchmark testing, Computational modeling, Computer aided instruction, Computer architecture, Computer science, High performance computing, Information analysis, Instruction sets, Poles and towers, Unified Prediction profile, abstract level, compiler technology target ISA, computer architecture, footprint, high performance computer architecture design, memory hierarchy, metrics, micro-architecture, modern architecture, multitasking regime, program behavior, program execution, quantitative results, quantitative workload characterization, simplified workload characterization, simulation efforts, software metrics, software performance evaluation, software reliability, source language, system aspects, unified prediction, },
 abstract = {Quantitative workload characterization is essential to high performance computer architecture design. Unfortunately, quantitative results are typically hard to interpret, reproduce and compare, due to the staggering amount of detail inherent in modern architecture. Source language, compiler technology target ISA, and micro-architecture, intertwined with system aspects such as memory hierarchy and multitasking regime, all add to the complexity of workload characterization. We propose two simple metrics to characterize program execution: a footprint measures the ``size" of a program, and a Unified Prediction profile shows its ``complexity". These metrics are architecture-independent, and allow meaningful comparisons of program behavior at a numerical but abstract level. We believe they can provide direction to subsequent, more detailed and costly simulation efforts },
}

@inproceedings{1291362,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Rong Xu and Zhiyuan Li},
 year = {2004},
 pages = { 106-- 114},
 publisher = {IEEE},
 title = {Using cache mapping to improve memory performance handheld devices},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291362},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291362},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291362.pdf?arnumber=1291362},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { NP-hard problem,  cache bypass,  cache management,  cache mapping policy,  cache mapping problem,  cache storage,  cache utilization,  computational complexity,  flexible control,  handheld devices,  memory architecture,  memory performance improvement,  memory profiling,  mini-cache,  multiple cache,  notebook computers,  optimal cache mapping,  page-based cache mapping,  performance enhancement,  performance evaluation, Clocks, Costs, Data structures, Embedded system, Handheld computers, Hardware, Monitoring, Probes, Program processors, Time measurement, },
 abstract = {Processors such as the Intel StrongARM SA-1110 and the Intel XScale provide flexible control over the cache management to achieve better cache utilization. Programs can specify the cache mapping policy for each virtual page, i.e. mapping it to the main cache, the mini-cache, or neither. For the latter case, the page is marked as non-cacheable. In this paper, we use memory profiling to guide such page-based cache mapping. We model the cache mapping problem and prove that finding the optimal cache mapping is NP-hard. We then present a heuristic to select the mapping. Execution time measurement shows that our heuristics can improve the performance from 1\% to 21\% for a set of test programs. As a byproduct of performance enhancement, we also save the energy by 4\% to 28\%. },
}

@inproceedings{5452049,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Drongowski, P. and Lei Yu and Swehosky, F. and Suthikulpanit, S. and Richter, R.},
 year = {2010},
 pages = {119--120},
 publisher = {IEEE},
 title = {Incorporating Instruction-Based Sampling into AMD CodeAnalyst},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452049},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452049},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452049.pdf?arnumber=5452049},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {AMD CodeAnalyst, AMD family processor, Application software, Counting circuits, Delay, Hardware, Microarchitecture, Performance analysis, Personal communication networks, Pipelines, Sampling methods, Software performance, fixed-width instruction, independent sampling mechanisms, instruction sets, instruction-based sampling, microprocessor chips, pipeline processing, pipeline processing, },
 abstract = {Instruction-Based Sampling (IBS) is a hardware mechanism that improves the accuracy of profiles. IBS is supported by AMD Family 10h processors. The processing pipeline of an AMD Family 10h processor is separated into two loosely coupled phases: A front-end phase that fetches AMD64 instruction bytes and a back-end phase that execute "ops" which issue from decoded AMD64 instructions. An op is an internal, fixed-width instruction which is executed by the pipeline stages in the execution phase. More than one op may issue from an instruction. Due to the decoupling, IBS samples fetches and ops separately, i.e., there are two independent sampling mechanisms. We will concentrate on IBS op sampling in this discussion. },
}

@inproceedings{1190238,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Rajamani, K. and Lefurgy, C.},
 year = {2003},
 pages = { 111-- 122},
 publisher = {IEEE},
 title = {On evaluating request-distribution schemes for saving energy in server clusters},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190238},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190238},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190238.pdf?arnumber=1190238},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { energy conservation,  energy efficiency,  energy management,  file servers,  power-performance optimization,  request distribution,  resource allocation,  scheduling,  server clusters,  web cluster, Databases, Delay, Energy conservation, Energy efficiency, Energy management, Energy measurement, Job shop scheduling, Load management, Measurement standards, Quality of service, },
 abstract = {Power-performance optimization is a relatively new problem area particularly in the context of server clusters. Power-aware request distribution is a method of scheduling service requests among servers in a cluster so that energy consumption is minimized, while maintaining a particular level of performance. Energy efficiency is obtained by powering-down some servers when the desired quality of service can be met with fewer servers. We have found that it is critical to take into account the system and workload factors during both the design and the evaluation of such request distribution schemes. We identify the key system and workload factors that impact such policies and their effectiveness in saving energy. We measure a web cluster running an industry-standard commercial web workload to demonstrate that understanding this system-workload context is critical to performing valid evaluations and even for improving the energy-saving schemes. },
}

@inproceedings{5452083,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {},
 year = {2010},
 pages = {i--x},
 publisher = {IEEE},
 title = {Title pages},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452083},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452083},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452083.pdf?arnumber=5452083},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {computer architecture, data center, microarchitecture analysis, microprocessor chips, multicore processor, multiprocessing systems, operating system, operating systems (computers), servers, },
 abstract = {The following topics are dealt with: operating system; multicore processor; data center; servers; and microarchitecture analysis. },
}

@inproceedings{990694,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Ost, A. and van Logchem, D.},
 year = {2001},
 pages = {160--163},
 publisher = {IEEE},
 title = {Statistical usage testing applied to mobile network verification},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990694},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990694},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990694.pdf?arnumber=990694},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Application software, Automatic testing, Automation, Cost benefit analysis, Performance evaluation, Petri nets, Software testing, Stochastic processes, System testing, Traffic control, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990694.png" border="0"> },
}

@inproceedings{1291360,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Anderson, C.},
 year = {2004},
 pages = { 97-- 97},
 publisher = {IEEE},
 title = {Keynote II},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291360},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291360},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291360.pdf?arnumber=1291360},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = {Bandwidth, CMOS technology, Circuit synthesis, Circuit testing, Computer displays, Hardware, Information processing, Information technology, Physics, Technology forecasting, },
 abstract = {},
}

@inproceedings{990697,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Sazeides, Y. and Juan, T.},
 year = {2001},
 pages = {180--183},
 publisher = {IEEE},
 title = {How to compare the performance of two SMT microarchitectures},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990697},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990697},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990697.pdf?arnumber=990697},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {Computational modeling, Computer science, Computer simulation, Measurement, Microarchitecture, Multithreading, Space exploration, Surface-mount technology, Throughput, Yarn, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990697.png" border="0"> },
}

@inproceedings{1430576,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Holanda, R. and Verdu, J. and Garcia, J. and Valero, M.},
 year = {2005},
 pages = {219--225},
 publisher = {IEEE},
 title = {Performance Analysis of a New Packet Trace Compressor based on TCP Flow Clustering},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430576},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430576},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430576.pdf?arnumber=1430576},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Computer architecture, IP networks, Internet, Internet, Performance analysis, Prototypes, Quality of service, Radix Tree algorithm, TCP flow clustering, TCPIP, Telecommunication traffic, Timing, Traffic control, cache miss ratio, cache storage, compression ratio, data compression, packet trace compressor, performance analysis, performance evaluation, statistical analysis, statistical properties, telecommunication traffic, transport protocols, tree data structures, },
 abstract = {In this paper we study the properties of a new packet trace compression method based on clustering of TCP flows. With our proposed method, the compression ratio that we achieve is around 3\%, reducing the file size, for instance, from 100 MB to 3 MB. Although this specification defines a lossy compressed data format, it preserves important statistical properties present into original trace. In order to validate the method, memory performance studies were done with the Radix Tree algorithm executing a trace generated by our method. To give support to these studies, measurements were taken of memory access and cache miss ratio. For the time, the results have showed that our proposed method provides a good solution for packet trace compression },
}

@inproceedings{1190232,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {McKee, S.A. and Zhen Fang and Valero, M.},
 year = {2003},
 pages = { 49-- 57},
 publisher = {IEEE},
 title = {An MPEG-4 performance study for non-SIMD, general purpose architectures},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190232},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190232},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190232.pdf?arnumber=1190232},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { ISO standards,  MPEG-4,  computer architecture,  digital television,  international standard,  internet streaming video,  mobile multimedia,  multimedia computing,  non-SIMD architectures,  standards,  video processing,  video signal processing, Bandwidth, Computer architecture, Cryptography, IEC standards, ISO standards, Layout, MPEG 4 Standard, Motion compensation, Streaming media, Transform coding, },
 abstract = {MPEG-4 is an important international standard with wide applicability. This paper focuses on MPEG-4's main profile, video, whose approach allows more efficiency in coding and more flexibility in managing heterogeneous media objects than previous MPEG standards. This study presents evidence to support the assertion that for non-SIMD architectures and computational models, most memory-system optimizations will have little effect on MPEG-4 performance. This paper makes two contributions. First, it serves as an independent confirmation that for current, general-purpose architectures, MPEG-4 video is computation bound (just like most other media processing applications). Second, our findings should prove useful to other researchers and practitioners considering how to (or how not to) optimize MPEG-4 performance. },
}

@inproceedings{4510755,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {},
 year = {2008},
 pages = {233--233},
 publisher = {IEEE},
 title = {Author Index},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510755},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510755},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510755.pdf?arnumber=4510755},
 isbn = {978-1-4244-2232-6},
 language = {English},
 abstract = {},
}

@inproceedings{1291367,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Joseph, R. and Martonosi, M. and Zhigang Hu},
 year = {2004},
 pages = { 151-- 160},
 publisher = {IEEE},
 title = {Spectral analysis for characterizing program power and performance},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291367},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291367},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291367.pdf?arnumber=1291367},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { Fourier analysis,  Fourier analysis,  dI/dT problem,  frequency analysis,  frequency domain,  granularity,  performance optimization,  power conversion,  power subproblem,  program performance characterization,  program power characterization,  program testing,  software performance evaluation,  spectral analysis,  spectral analysis, Analytical models, Energy management, Fourier transforms, Frequency domain analysis, Information analysis, Optimization, Pattern analysis, Performance analysis, Spectral analysis, Temperature, },
 abstract = {Performance and power analysis in modern processors requires managing a large amount of complex information across many time-scales. For a example, thermal control issues are a power subproblem with relevant time constants of millions of cycles or more, while the so-called dI/dT problem is also a power subproblem but occurs because of current variability on a much finer granularity: tens to hundreds of cycles. Likewise, for performance issues, program phase analysis for selecting simulation regions requires looking for periodicity on the order of millions of cycles or more, while some aspects of cache performance optimization requires understanding repetitive patterns on much finer granularities. Fourier analysis allows one to transform waveform into a sum of component (usually sinusoidal) waveforms in the frequency domain; in this way, the waveform's fundamental frequencies (periodicities of repetition) can be clearly identified. This paper shows how one can use Fourier analysis to produce frequency spectra for some of the time waveforms seen in processor execution. By working in the frequency domain, one can easily identify key application tendencies. For example, we demonstrate how to use spectral analysis to characterize the power behavior of real programs. As we show, this is useful for understanding both the temperature profile of a program and its voltage stability. These are particularly relevant issues for architects since thermal concerns and the dI/dT problem have significant influence on processor design. Frequency analysis can also be used to examine program performance. In particular, it can also identify periodic occurrences of important microarchitectural events like cache misses. Overall, the paper demonstrates the value of using frequency analysis in different research efforts related to characterizing and optimizing application performance and power. },
}

@inproceedings{842286,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Rupley, J., II and Holloway, D.},
 year = {2000},
 pages = {88--94},
 publisher = {IEEE},
 title = {Performance tradeoffs in sequencer design on a new G4 PowerPCTM microprocessor},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842286},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842286},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842286.pdf?arnumber=842286},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {AltiVec enhanced technology, Costs, Engines, Frequency, G4 PowerPC microprocessor, G4 instruction sequencer design, Graphics, Logic, Microarchitecture, Microprocessors, Pipelines, Power generation, Throughput, four-way superscalar design, high performance desktop systems, microcomputers, microprocessor chips, performance evaluation, performance simulator, performance tradeoffs, pipeline processing, pipelining, virtual machines, },
 abstract = {The microprocessor discussed in this paper is a new member of the G4 family of PowerPC microprocessors with AltiVec<sup>TM</sup> enhanced technology, intended for high performance desktop systems. This four-way superscalar design is more deeply pipelined than previous designs in order to achieve greater frequency. The challenge in increasing frequency is to translate most or all of that increase into performance increases, and this requires careful analysis from a performance simulator. This paper specifically looks at how the interaction between frequency and performance goals affected the design of the new G4 instruction sequencer },
}

@inproceedings{990696,
 booktitle = {Performance Analysis of Systems and Software, 2001. ISPASS. 2001 IEEE International Symposium on},
 author = {Aggarwal, A. and Franklin, M.},
 year = {2001},
 pages = {172--179},
 publisher = {IEEE},
 title = {An empirical study of the scalability aspects of instruction distribution algorithms for clustered processors},
 date = {2001},
 doi = {10.1109/ISPASS.2001.990696},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990696},
 pdf_url = {http://ieeexplore.ieee.org/iel5/7769/21354/00990696.pdf?arnumber=990696},
 isbn = {0-7695-7230-1},
 language = {English},
 keywords = {CMOS technology, Clocks, Clustering algorithms, Delay, Educational institutions, Hardware, Processor scheduling, Proposals, Scalability, Wires, },
 abstract = {<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article<img class="img-abs-container" style="width: 95\%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00990696.png" border="0"> },
}

@inproceedings{1291366,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Dmitriev, M.},
 year = {2004},
 pages = { 141-- 150},
 publisher = {IEEE},
 title = {Selective profiling of Java applications using dynamic bytecode instrumentation},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291366},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291366},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291366.pdf?arnumber=1291366},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { GUI tool,  JFluid,  Java,  Java applications,  Java virtual machine,  dynamic bytecode instrumentation,  graphical user interfaces,  object-oriented programming,  program diagnostics,  selective profiling,  software tool,  software tools, Application software, Instruments, Java, Laboratories, Modems, Sampling methods, Size measurement, Software measurement, Sun, Virtual manufacturing, },
 abstract = {Instrumentation-based profiling provides a number of benefits, but can also cause high performance overhead. The negative impact of this overhead could be mitigated considerably if only a small part of the target application (e.g. one that has previously been identified as a bottleneck) is instrumented, possibly for a short time only, while the rest of the application code runs at full speed. In this paper we present an experimental profiling system called JFluid, which includes a modified Java\&trade; VM and a GUI tool, and addresses both of the above issues. Our tool supports dynamic instrumentation of a group of methods defined as an arbitrary "root" method plus all methods that it calls (a call subgraph). Methods that belong to a call subgraph are revealed and instrumented lazily, to minimise the number of methods instrumented unnecessarily. Measurements that we obtain when performing full and partial program profiling show that the overhead can be reduced substantially using this technique, and that it is more beneficial when used for large server-side Java applications as opposed to small benchmarks. },
}

@inproceedings{1430557,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Cheng, A.C. and Tyson, G.S. and Mudge, T.N.},
 year = {2005},
 pages = {32--41},
 publisher = {IEEE},
 title = {PowerFITS: Reduce Dynamic and Static I-Cache Power Using Application Specific Instruction Set Synthesis},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430557},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430557},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430557.pdf?arnumber=1430557},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Application specific processors, Costs, Decoding, Embedded computing, Embedded system, Energy consumption, Handheld computers, Microprocessors, Portable computers, PowerFITS, Telecommunication computing, application specific microprocessor design, benchmark testing, benchmarking, cache storage, computer architecture, embedded systems, framework-based instruction-set tuning synthesis, general-purpose embedded processor, instruction cache, instruction sets, microprocessor chips, power consumption, power consumption, power reduction, programmable decoder, },
 abstract = {Power consumption, performance, area, and cost are critical concerns in designing microprocessors for embedded systems such as portable handheld computing and personal telecommunication devices. In previous work [A. Cheng et al., (2004)], we introduced the concept of framework-based instruction-set tuning synthesis (FITS), which is a new instruction synthesis paradigm that falls between a general-purpose embedded processor and a synthesized application specific processor (ASP). We address these design constraints through FITS by improving the code density. A FITS processor improves code density by tailoring the instruction set to the requirement of a target application to reduce the code size. This is achieved by replacing the fixed instruction and register decoding of general purpose embedded processor with programmable decoders that can achieve ASP performance, low power consumption, and compact chip area with the fabrication advantages of a mass produced single chip solution to amortize the cost. Instruction cache has been recognized as one of the most predominant source of power dissipation in a microprocessor. For instance, in Intel's StrongARMprocessor, 27\% of total chip power loss goes into the instruction cache [J. Montanaro et al., (1996)]. In this paper, we demonstrate how FITS can be applied to improve the instruction cache power efficiency. Experimental results show that our synthesized instruction sets result in significant power reduction in the instruction cache compared to ARM instructions. For 21 benchmarks from the MiBench suite [M. Guthaus et al., (2001)], our simulation results indicate on average: a 49.4\% saving for switching power; a 43.9\% saving for internal power; a 14.9\% saving for leakage power; a 46.6\% saving for total cache power with up to 60.3\% saving for peak power },
}

@inproceedings{842273,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Eeckhout, L. and de Bosschere, K. and Neefs, H.},
 year = {2000},
 pages = {1--6},
 publisher = {IEEE},
 title = {Performance analysis through synthetic trace generation},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842273},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842273},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842273.pdf?arnumber=842273},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Acceleration, Analytical models, Clocks, Information analysis, Information systems, Microarchitecture, Oils, Performance analysis, Process design, Sampling methods, computer program execution modelling, microarchitectural performance analysis, software performance evaluation, statistical profile, synthetic trace generation, virtual machines, },
 abstract = {Most research in the area of microarchitectural performance analysis is done using trace-driven simulations. Although trace-driven simulations are fairly accurate, they are both time- and space-consuming which makes them sometimes impractical. Modeling the execution of a computer program by a statistical profile and generating a synthetic benchmark trace from this statistical profile can be used to accelerate the design process. Thanks to the statistical nature of this technique, performance characteristics quickly converge to a steady state solution during simulation, which makes this technique suitable for fast design space explorations. In this paper, it is shown how more detailed statistical profiles can be obtained and how the synthetic trace generation mechanism should be designed to generate syntactically correct benchmark traces. As a result, the performance predictions in this paper are far more accurate than those reported in previous research },
}

@inproceedings{842291,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Kronstadt, E.},
 year = {2000},
 pages = {123--128},
 publisher = {IEEE},
 title = {Some observations based on simple models of MP scaling},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842291},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842291},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842291.pdf?arnumber=842291},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Delay, MP scaling, Milling machines, Packaging, Performance analysis, Scalability, important applications, large shared memory multiprocessor systems, mathematical models, performance evaluation, performance gains, shared memory systems, simple models, system performance, very large machines, virtual machines, workload scaling, },
 abstract = {The emergence of large shared memory multiprocessor systems offer the potential of accelerating the pace of ever increasing system performance. On the one hand, it seems simple: add more processors, get more performance. On the other hand, it is quite difficult, as efficient scaling of workloads to large numbers of processors is a nontrivial challenge. Nevertheless, the way we use these very large machines is intrinsically connected with our predictions of how well important applications scale. The author explores some of the consequences of simple mathematical models of MP scaling. He looks at the consequences of the projections these models give, both in terms of what performance gains we might expect to see, as well as the potential limits of scaling we may face },
}

@inproceedings{1430552,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { vii-- ix},
 publisher = {IEEE},
 title = {Table of contents},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430552},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430552},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430552.pdf?arnumber=1430552},
 isbn = {0-7803-8965-4},
 language = {English},
 abstract = {},
}

@inproceedings{4510737,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Dieter, W.R. and Dietz, H.G.},
 year = {2008},
 pages = {44--53},
 publisher = {IEEE},
 title = {Computer Aided Engineering of Cluster Computers},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510737},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510737},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510737.pdf?arnumber=4510737},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Aerospace engineering, Application software, Automotive engineering, Computational modeling, Computer aided engineering, Design engineering, Drugs, Predictive models, Supercomputers, Weather forecasting, application program interfaces, cluster design rules, cluster supercomputers, computer aided engineering, computer aided engineering, mainframes, parallel machines, programming interface, resource constraints, workstation clusters, },
 abstract = {There are many scientific and engineering applications that require the resources of a dedicated supercomputer: drug design, weather prediction, simulating vehicle crashes, fluid dynamics simulations of aircraft or even consumer products. Cluster supercomputers can leverage commodity parts with standard interfaces that allow them to be used interchangeably to build supercomputers customized for these and other applications. However, the best design for one application is not necessarily the best design for other applications. Supercomputer design is challenging, but this problem is harder due to the huge range of possible configurations, volatile component availability and pricing, and constraints on available power, cooling, and floor space. Cluster design rules (CDR) is a computer-aided engineering tool that uses resource constraints and application performance models to identify the few best designs among the trillions of designs that could be constructed using parts from a given database. It uses a branch-and-bound strategy based on cluster design principles that can eliminate many inferior designs from the search without evaluating them. For the millions of designs that remain, CDR measures fitness by one of several user-specified application performance models. New application performance models can be added by means of a programming interface. This paper details the concepts and mechanisms inside CDR and shows how it facilitates model-based engineering of custom clusters. },
}

@inproceedings{1291364,
 booktitle = {Performance Analysis of Systems and Software, 2004 IEEE International Symposium on - ISPASS},
 author = {Dysart, T.J. and Moore, B.J. and Schaelicke, L. and Kogge, P.M.},
 year = {2004},
 pages = { 123-- 132},
 publisher = {IEEE},
 title = {Cache implications of aggressively pipelined high performance microprocessors},
 date = {2004},
 doi = {10.1109/ISPASS.2004.1291364},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1291364},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9067/28758/01291364.pdf?arnumber=1291364},
 issn = {           },
 isbn = {0-7803-8385-0},
 language = {English},
 keywords = { access latency,  aggressively pipelined microprocessors,  cache implications,  cache storage,  clock rate determination,  high performance microprocessors,  level-1 cache designs,  level-1 cache size simulation,  memory architecture,  memory system design,  microprocessor chips,  microprocessor design,  optimal pipeline depth,  pipeline depth determination,  pipeline performance,  pipeline processing, Clocks, Computer science, Delay, Design engineering, Energy consumption, Frequency, Microprocessors, Performance analysis, Pipelines, Telephony, },
 abstract = {One of the major design decisions when developing a new microprocessor is determining the target pipeline depth and clock rate since both factors interact closely with one another. The optimal pipeline depth of a processor has been studied before, but the impact of the memory system on pipeline performance has received less attention. This study analyzes the affect of different level-1 cache designs across a range of pipeline depths to determine what role the memory system design plays in choosing a clock rate and pipeline depth for a microprocessor. The pipeline depths studied here range from those found in current processors to those predicted for future processors. For each pipeline depth a variety of level-1 cache sizes are simulated to explore the relationship between clock rate, pipeline depth, cache size and access latency. Results show that the larger caches afforded by shorter pipelines with slower clocks outperform longer pipelines with smaller caches and higher clock rates. },
}

@inproceedings{1430551,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { vi-- vi},
 publisher = {IEEE},
 title = {Reviewers},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430551},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430551},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430551.pdf?arnumber=1430551},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {IEEE, },
 abstract = {},
}

@inproceedings{842276,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Hsien-Hsin Lee and Youfeng Wu and Tyson, G.},
 year = {2000},
 pages = {21--27},
 publisher = {IEEE},
 title = {Quantifying instruction-level parallelism limits on an EPIC architecture},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842276},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842276},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842276.pdf?arnumber=842276},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Delay effects, EPIC architecture, Hardware, Instruction sets, Logic, Pipeline processing, Processor scheduling, function boundaries, instruction-level parallelism, instruction-level parallelism limits, inter-procedural code scheduling, intra-procedural code scheduling, loop boundaries, loop-confined code scheduling, optimal performance, optimising compilers, optimizing compiler, parallel programming, processor scheduling, static code schedule, },
 abstract = {EPIC architectures rely heavily on state-of-the-art compiler technology to deliver optimal performance while keeping hardware design simple. It is generally believed that an optimizing compiler has an enormous scheduling window to exploit instruction-level parallelism (ILP) since the compiler orchestrates the entire program. Many state-of-the-art compilers typically confine optimizations to loop boundaries (e.g. software pipelining, trace scheduling, and loop unrolling) and function boundaries (e.g. loop peeling, loop exchanges, invariant hoisting, and global optimizations). Although techniques such as function inlining and interprocedural optimizations can alleviate these constraints to a limited extent, loop and function boundaries are often the real scopes of the compiler scheduler. Several previous ILP studies have explored the limits of parallelism on dynamic superscalar machines; however, those results are not applicable to EPIC architectures since they rely on dynamic scheduling, not static code scheduling by the compiler, to reorder instructions. In this paper, we evaluate the limits in ILP obtained through compiler scheduling alone. We quantify these limits as more restrictive scheduling constraints are imposed-starting from inter-procedural code scheduling, to intra-procedural and finally to loop-confined code scheduling },
}

@inproceedings{4510736,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Schuff, D.L. and Yung Ryn Choe and Pai, V.S.},
 year = {2008},
 pages = {32--43},
 publisher = {IEEE},
 title = {Conservative vs. Optimistic Parallelization of Stateful Network Intrusion Detection},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510736},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510736},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510736.pdf?arnumber=4510736},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Concurrent computing, Inspection, Intrusion detection, Load management, Network servers, Open source software, Performance analysis, Scalability, TCP-IP flow, TCPIP, Yarn, computer networks, concurrency control, conservative parallelization, flow concurrency, flow concurrent scheme, flow partitioning, flow reassignment, inspection parallelization, interpacket dependence, load balancing, network packet, open-source Snort network intrusion detection system, optimistic parallelization, public domain software, resource allocation, security of data, stateful network intrusion, telecommunication security, transport protocols, },
 abstract = {This paper presents and experimentally analyzes the performance of three parallelization strategies for the popular open-source Snort network intrusion detection system (NIDS). The parallelizations include 2 conservative variants and 1 optimistic scheme. The conservative strategy parallelizes inspection at the level of TCP/IP flows, as any potential inter-packet dependences are confined to a single flow. The flows are partitioned among threads, and each flow is processed in-order at one thread. A second variation reassigns flows between threads to improve load balance but still requires that only one thread process a given flow at a time. The flow-concurrent scheme provides good performance for 3 of the 5 network packet traces studied, reaching as high as 4.1 speedup and 3.1 Gbps inspection rate on a commodity 8-core server. Dynamic reassignment does not improve performance scalability because it introduces locking overheads that offset any potential benefits of load balancing. Neither conservative version can achieve good performance, however, without enough concurrent networkflows. For this case, this paper presents an optimistic parallelization that exploits the observation that not all packets from a flow are actually connected by dependences. This system allows a single flow to be simultaneously processed by multiple threads, stalling if an actual dependence is found. The optimistic version has additional overheads that reduce speedup by 25\% for traces with flow concurrency, but its benefits allow one additional trace to see substantial speedup (2.4 on five cores). },
}

@inproceedings{4510734,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {Ratanaworabhan, P. and Burtscher, M.},
 year = {2008},
 pages = {11--21},
 publisher = {IEEE},
 title = {Program Phase Detection based on Critical Basic Block Transitions},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510734},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510734},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510734.pdf?arnumber=4510734},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Computational modeling, Computer architecture, Distributed computing, Energy consumption, Grid computing, Intrusion detection, L1 data cache, Laboratories, Performance loss, Phase detection, SimPoint method, Stability, cache reconfiguration schemes, cache storage, critical basic block transitions, digital simulation, lightweight profile-based phase detection technique, phase change decision, program phase detection, program phase simulation, software architecture, },
 abstract = {Many programs go through phases as they execute. Knowing where these phases begin and end can be beneficial. For example, adaptive architectures can exploit such information to lower their power consumption without much loss in performance. Architectural simulations can benefit from phase information by simulating only a small interval of each program phase, which significantly reduces the simulation time while still yielding results that are representative of complete simulations. This paper presents a lightweight profile-based phase detection technique that marks each phase change boundary in the program's binary at the basic block level with a critical basic block transition (CBBT). It is independent of execution windows and does not explicitly employ the notion of threshold to make a phase change decision. We evaluate the effectiveness of CBBTs for reconfiguring the LI data cache size and for guiding architectural simulations. Our CBBT method is as effective at dynamically reducing the L1 data cache size as idealized cache reconfiguration schemes are. Using CBBTs to statically determine simulation intervals yields as low a CPI error as the well-known SimPoint method does. In addition, experimental results indicate the CBBTs' effectiveness in both the self-trained and cross-trained inputs, demonstrating the CBBTs' stability across different program inputs. },
}

@inproceedings{1430550,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {},
 year = {2005},
 pages = { v-- v},
 publisher = {IEEE},
 title = {ISPASS 2005 people},
 date = {March 20-22, 2005},
 doi = {10.1109/ISPASS.2005.1430550},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430550},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430550.pdf?arnumber=1430550},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Bonding, Europe, Finance, Instruments, Organizing, Sun, },
 abstract = {},
}

@inproceedings{1430571,
 booktitle = {Performance Analysis of Systems and Software, 2005. ISPASS 2005. IEEE International Symposium on},
 author = {Sanchez, F. and Alvarez, M. and Salamf, E. and Ramirez, A. and Valero, M.},
 year = {2005},
 pages = {167--176},
 publisher = {IEEE},
 title = {On the Scalability of 1- and 2-Dimensional SIMD Extensions for Multimedia Applications},
 date = {20-22 March 2005},
 doi = {10.1109/ISPASS.2005.1430571},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1430571},
 pdf_url = {http://ieeexplore.ieee.org/iel5/9783/30850/01430571.pdf?arnumber=1430571},
 isbn = {0-7803-8965-4},
 language = {English},
 keywords = {Application software, Computer architecture, Digital signal processing, Hardware, Intel MMX, Kernel, Message-oriented middleware, Multimedia communication, Multimedia computing, Registers, SIMD extension, Scalability, matrix architecture, multimedia computing, multimedia computing, multimedia kernel, operating system kernels, parallel architectures, parallel hardware, program control structures, superscalar processor, },
 abstract = {SIMD extensions are the most common technique used in current processors for multimedia computing. In order to obtain more performance for emerging applications SIMD extensions need to be scaled. In this paper we perform a scalability analysis of SIMD extensions for multimedia applications. Scaling a 1-dimensional extension, like Intel MMX, was compared to scaling a 2-dimensional (matrix) extension. Evaluations have demonstrated that the 2-d architecture is able to use more parallel hardware than the 1-d extension. Speed-ups over a 2-way superscalar processor with MMX-like extension go up to 4X for kernels and up to 3.3X for complete applications and the matrix architecture can deliver, in some cases, more performance with simpler processor configurations. The experiments also show that the scaled matrix architecture is reaching the limits of the DLP available in the internal loops of common multimedia kernels },
}

@inproceedings{1190248,
 booktitle = {Performance Analysis of Systems and Software, 2003. ISPASS. 2003 IEEE International Symposium on},
 author = {Hasan, Y. and Morris Chang, J.},
 year = {2003},
 pages = { 214-- 222},
 publisher = {IEEE},
 title = {A hybrid allocator},
 date = {6-8 March 2003},
 doi = {10.1109/ISPASS.2003.1190248},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1190248},
 pdf_url = {http://ieeexplore.ieee.org/iel5/8467/26677/01190248.pdf?arnumber=1190248},
 issn = {           },
 isbn = {0-7803-7756-7},
 language = {English},
 keywords = { computer programs,  dynamic memory allocator,  dynamic memory management,  hybrid algorithm,  program execution time,  segregated storage,  storage management, Computer science, Costs, Degradation, Libraries, Memory management, Size measurement, Technology management, },
 abstract = {Dynamic memory management can make up to 30\% of total program execution time. Object oriented languages like C++ allocate and free dynamic memory prolifically. Since computer memory is a limited resource its efficient utilization is required to minimize wastage and keep costs down. Memory management algorithms such as best fit seem to perform most efficiently in terms of space cost while simple segregated storage seems to minimize the time cost. There is a trade-off between time and space costs. We have developed a new general purpose hybrid algorithm that shows excellent performance with respect to both time and space in comparison to the Doug Lea version 2.7.0 dynamic memory allocator. },
}

@inproceedings{5452069,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Eklov, D. and Hagersten, E.},
 year = {2010},
 pages = {55--65},
 publisher = {IEEE},
 title = {StatStack: Efficient modeling of LRU caches},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452069},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452069},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452069.pdf?arnumber=5452069},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Application software, Bandwidth, Counting circuits, Delay, Distance measurement, Hardware, Information technology, Instruments, LRU caches, Random access memory, Runtime, SPEC CPU2006 benchmark suite, cache storage, data collection, off-line algorithm, stack distance abstraction, stack distance measurements, },
 abstract = {Efficient execution on modern architectures requires good data locality, which can be measured by the powerful stack distance abstraction. Based on this abstraction, the miss rate for LRU caches of any size can be predicted. However, measuring stack distance requires the number of unique memory objects to be counted between successive accesses to the same data object, which requires complex and inefficient data collection. This paper presents a new efficient way of estimating the stack distances of an application. Instead of counting the number of unique memory objects touched between successive accesses to the same data, our scheme only requires the number of memory accesses to be counted, a task efficiently handled by existing builtin hardware counters. Furthermore, this information only needs to be captured for a small fraction of the memory accesses. A new efficient off-line algorithm is proposed to estimate the corresponding stack distance based on this sparse information. We evaluate the accuracy of the proposed estimation compared with full stack distance measurements for 28 of the applications in the SPEC CPU2006 benchmark suite. The estimation shows excellent accuracy based on information about only every 10,000th memory access. },
}

@inproceedings{5452068,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Desmet, V. and Girbal, S. and Temam, O.},
 year = {2010},
 pages = {45--54},
 publisher = {IEEE},
 title = {ArchExplorer.org: A methodology for facilitating a fair Comparison of research ideas},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452068},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452068},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452068.pdf?arnumber=5452068},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {ArchExplorer.org, Biological system modeling, Biology, Computational modeling, Computer architecture, Fixtures, Internet, Physics, Productivity, Reproducibility of results, Service oriented architecture, Web page design, architecture simulator complexity, cache storage, computer architecture, data cache mechanisms, server-side Web infrastructure, },
 abstract = {While reproducing the experimental results of research articles is standard practice in mature domains of science, such as physics or biology, it has not yet become mainstream in computer architecture. However, recent research shows that the lack of a fair and broad comparison of research ideas can be significantly detrimental to the progress, and thus the productivity, of research. At the same time, the complexity of architecture simulators and the fact that simulators are not systematically disseminated with novel ideas are largely responsible for this situation. While this methodology has a fundamental impact on research, it is by essence a practical issue. In this article, we present and set up an a typical approach to overcome this practical methodology issue, which takes the form of an open and continuous exploration through ArchExplorer, a server-side web infrastructure, that can significantly ease the process of fairly and quantitatively comparing research ideas. The web infrastructure ArchExplorer.org is now publicly open, and we demonstrate the approach with a set of data cache mechanisms. We show that this broad exploration can challenge some earlier assessments about data cache research, and even challenges the conclusions of an earlier but less thorough study on data cache comparison. },
}

@inproceedings{842287,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Annavaram, M. and Tyson, G.S. and Davidson, E.S.},
 year = {2000},
 pages = {95--100},
 publisher = {IEEE},
 title = {Instruction overhead and data locality effects in superscalar processors},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842287},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842287},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842287.pdf?arnumber=842287},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {C++, Computer science, Costs, Data engineering, Data structures, Degradation, Libraries, Operating systems, Programming profession, cache misses, data locality effects, data structures, dynamic memory allocation, flexible data structures, instruction overhead effects, linked lists, list traversals, memory copy overhead, node addition, node deletion, object oriented programming languages, object-oriented programming, programming flexibility, software development cost, software engineering, software maintenance cost, software performance evaluation, superscalar processors, underutilized resource, vector representation, wide-issue processors, },
 abstract = {To reduce software development and maintenance costs, programmers are increasingly using object oriented programming languages, such as C++, and relying on highly flexible data structures, such as linked lists. Object oriented programming languages provide features that help manage complex software systems, but object oriented programs tend to suffer increased instruction counts, e.g. due to generalized class implementations and many more calls to small functions. Using linked data structures increases programming flexibility by allowing easy addition and deletion of nodes, and by dynamically allocating memory to satisfy applications that use large memory space. However, successive elements in linked data structures may be allocated noncontinuously in memory, leading to poor spatial locality for list traversals which in turn increases cache misses and reduces performance. This paper evaluates the impact of both the increased instruction overhead and poor spatial locality on superscalar processor performance as issue width increases. We show that underutilized resources of wide-issue processors can partially alleviate the impact of the instruction overhead. However, poor locality tends to cause more performance degradation as the processor issue width increases. Finally we show that the spatial locality of some programs can be improved by using a vector representation to replace linked list structures. Vectors exhibit better spatial locality during list traversals, but suffer from instruction overhead and memory copy overhead when nodes are added to and deleted from the structure },
}

@inproceedings{842277,
 booktitle = {Performance Analysis of Systems and Software, 2000. ISPASS. 2000 IEEE International Symposium on},
 author = {Friedrich, L.F. and Cancian, R. and de Oliveira, R.S. and Corso, T.B.},
 year = {2000},
 pages = {28--33},
 publisher = {IEEE},
 title = {Performance evaluation of real-time scheduling on a multicomputer architecture},
 date = {2000},
 doi = {10.1109/ISPASS.2000.842277},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=842277},
 pdf_url = {http://ieeexplore.ieee.org/iel5/6790/18223/00842277.pdf?arnumber=842277},
 isbn = {0-7803-6418-X},
 language = {English},
 keywords = {Application software, Large Hadron Collider, Network topology, Peer to peer computing, Processor scheduling, Robustness, distributed environment, high performance computer architectures, multicomputer architecture, multiprocessing systems, parallel environment, parallel processing, performance evaluation, performance evaluation, processor scheduling, real-time applications, real-time scheduling, real-time systems, },
 abstract = {The complexity of some real-time applications demands high performance computer architectures. Multicomputer architectures have a potential for high performance and reliability because of their expressive number of processors and communication channels. Therefore, they are natural candidates for supporting complex real-time computing. This paper presents a performance evaluation of real-time scheduling in a parallel/distributed environment which is based on a multicomputer architecture },
}

@inproceedings{5452065,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Chi Xu and Xi Chen and Dick, R.P. and Mao, Z.M.},
 year = {2010},
 pages = {76--86},
 publisher = {IEEE},
 title = {Cache contention and application performance prediction for multi-core systems},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452065},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452065},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452065.pdf?arnumber=5452065},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {CAMP, Degradation, Energy consumption, Frequency estimation, Hardware, Histograms, Multicore processing, Operating systems, Power system modeling, Predictive models, SPEC CPU2000, Throughput, cache access frequencies, cache aware performance model, cache contention, cache miss rate, cache storage, chip multiprocessors, last-level cache, least-recently-used, multi-core systems, multiprocessing systems, operating system modification, performance evaluation, performance prediction, reuse distance histograms, },
 abstract = {The ongoing move to chip multiprocessors (CMPs) permits greater sharing of last-level cache by processor cores but this sharing aggravates the cache contention problem, potentially undermining performance improvements. Accurately modeling the impact of inter-process cache contention on performance and power consumption is required for optimized process assignment. However, techniques based on exhaustive consideration of process-to-processor mappings and cycle-accurate simulation are inefficient or intractable for CMPs, which often permit a large number of potential assignments. This paper proposes CAMP, a fast and accurate shared cache aware performance model for multi-core processors. CAMP estimates the performance degradation due to cache contention of processes running on CMPs. It uses reuse distance histograms, cache access frequencies, and the relationship between the throughput and cache miss rate of each process to predict its effective cache size when running concurrently and sharing cache with other processes, allowing instruction throughput estimation.We also provide an automated way to obtain process-dependent characteristics, such as reuse distance histograms, without offline simulation, operating system (OS) modification, or additional hardware. We tested the accuracy of CAMP using 55 different combinations of 10 SPEC CPU2000 benchmarks on a dual-core CMP machine. The average throughput prediction error was 1.57\%. },
}

@inproceedings{5452064,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Mandal, A. and Fowler, R. and Porterfield, A.},
 year = {2010},
 pages = {66--75},
 publisher = {IEEE},
 title = {Modeling memory concurrency for multi-socket multi-core systems},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452064},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452064},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452064.pdf?arnumber=5452064},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Bandwidth, Clocks, Concurrent computing, Delay, Hardware, Parallel processing, Pervasive computing, Random access memory, Semiconductor device measurement, Yarn, computer architecture, concurrency control, concurrency theory, concurrent memory access operations, concurrent memory references, hardware architecture, memory loads, multi-socket multi-core systems, multiprocessing systems, processor chips, single memory controller, },
 abstract = {Multi-core computers are ubiquitous and multi-socket versions dominate as nodes in compute clusters. Given the high level of parallelism inherent in processor chips, the ability of memory systems to serve a large number of concurrent memory access operations is becoming a critical performance problem. The most common model of memory performance uses just two numbers, peak bandwidth and typical access latency. We introduce concurrency as an explicit parameter of the measurement and modeling processes to characterize more accurately the complexity of memory behavior of multi-socket, multi-core systems. We present a detailed experimental multi-socket, multi-core memory study based on the PCHASE benchmark, which can vary memory loads by controlling the number of concurrent memory references per thread. The make-up and structure of the memory have a major impact on achievable bandwidth. Three discrete bottlenecks were observed at different levels of the hardware architecture: limits on the number of references outstanding per core; limits to the memory requests serviced by a single memory controller; and limits on the global memory concurrency. We use these results to build a memory performance model that ties concurrency, latency and bandwidth together to create a more accurate model of overall performance. We show that current commodity memory sub-systems cannot handle the load offered by high-end processor chips. },
}

@inproceedings{5452061,
 booktitle = {Performance Analysis of Systems and Software (ISPASS), 2010 IEEE International Symposium on},
 author = {Porter, D.E. and Witchel, E.},
 year = {2010},
 pages = {97--108},
 publisher = {IEEE},
 title = {Understanding transactional memory performance},
 date = {28-30 March 2010},
 doi = {10.1109/ISPASS.2010.5452061},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5452061},
 pdf_url = {http://ieeexplore.ieee.org/iel5/5446240/5452012/05452061.pdf?arnumber=5452061},
 isbn = {978-1-4244-6023-6},
 language = {English},
 keywords = {Data structures, Kernel, Linux, Linux, Memory architecture, Pathology, Performance analysis, Predictive models, Program processors, Programming profession, Syncchar, TxLinux kernel, Yarn, compiler, data structures, data structures, memory allocator, modified Andrew benchmark, operating system kernels, transaction processing, transactional memory system, transactional programming, user-level transactional programs, },
 abstract = {Transactional memory promises to generalize transactional programming to mainstream languages and data structures. The purported benefit of transactions is that they are easier to program correctly than fine-grained locking and perform just as well. This performance claim is not always borne out because an application may violate a common-case assumption of the TM designer or because of external system effects. This paper carefully studies a range of factors that can adversely influence transactional memory performance. In order to help programmers assess the suitability of their code for transactional memory, this paper introduces a formal model of transactional memory as well as a tool, called Syncchar. Syncchar can predict the speedup of a conversion from locks to transactions within 25 \% for the STAMP benchmarks. We also use the Syncchar tool to diagnose and eliminate a starvation pathology in the TxLinux kernel, improving the performance of the Modified Andrew Benchmark by 55\% over Linux. The paper also presents the first detailed study of how the performance of user-level transactional programs (from the STAMP benchmarks) are influenced by factors outside of the transactional memory system. The study includes data about the interaction of transactional programs with the architecture, memory allocator, and compiler. Because many factors influence the performance of transactional programs, getting good performance from transactions is more difficult than commonly appreciated. },
}

@inproceedings{4510728,
 booktitle = {Performance Analysis of Systems and software, 2008. ISPASS 2008. IEEE International Symposium on},
 author = {},
 year = {2008},
 pages = {i--ii},
 publisher = {IEEE},
 title = {Covers},
 date = {20-22 April 2008},
 doi = {10.1109/ISPASS.2008.4510728},
 abstract_html_url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4510728},
 pdf_url = {http://ieeexplore.ieee.org/iel5/4498398/4510727/04510728.pdf?arnumber=4510728},
 isbn = {978-1-4244-2232-6},
 language = {English},
 keywords = {Cell processor, benchmarks, networking, parallel processing, performance analysis, performance evaluation, scientific workloads, simulation, software reliability, },
 abstract = {The following topics are dealt with: performance analysis; simulation; parallel processing; networking; scientific workloads; benchmarks; software reliability; Cell processor. },
}

@inproceedings{empty,
 booktitle = {},
 author = {},
 year = {},
 abstract = {},
}

