@Book{Marx1887,
 author = "Karl Marx",
  title =	"Capital",
  year =	"1887",
  edition =	"English",
  publisher =   "www.marx.org"
}
@ARTICLE{Burges98atutorialSVM,
    author = {Christopher J. C. Burges},
    title = {A tutorial on support vector machines for pattern recognition},
    journal = {Data Mining and Knowledge Discovery},
    year = {1998},
    volume = {2},
    pages = {121--167},
    abstract = {support vector machines tutorial}
}
@ARTICLE{SVM2003Hornik,
  AUTHOR = {David Meyer and Friedrich Leisch and Kurt Hornik},
  TITLE = {The Support Vector Machine under Test},
  JOURNAL = {Neurocomputing},
  YEAR = 2003,
  MONTH = {September},
  PAGES = {169--186},
  VOLUME = 55
}
@inbook{svmlight2008,
	abstract = {SVM_LIGHT software. Training a support vector machine (SVM) leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples, off-the-shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVMlight is an...},
	author = {Joachims, T. },
	booktitle = {Advances in Kernel Methods: Support Vector Machines},
	citeulike-article-id = {227265},
	editor = {Sch\"olkopf, C. B. },
	keywords = {pattern\_recognition},
	posted-at = {2008-03-09 15:19:56},
	priority = {2},
	publisher = {MIT Press, Cambridge, MA},
	title = {Making large-scale support vector machine learning practical},
	url = {http://citeseer.ist.psu.edu/joachims98making.html},
	year = {1998}
}
@Article{Kitano2002,
 author = "H.~Kitano",
  title =	"Computational Systems Biology",
  journal =	"Nature",
  year =	"2002",
  volume =      "420",
  page =	"206--210",
  abstract = "Computational Systems Biology"
}
@Article{Leroy2001,
 author = "Trey Ideker and Timothy Galitski and Leroy Hood",
  title =	"A New Approach To Decoding Life: Systems Biology",
  journal =	"Annual Review of Genomics and Human Genetics",
  month = "Sep",
  year =	"2001",
  volume =      "2",
  abstract = "Computational Systems Biology"
}
@Article{Wolf2003,
 author = "D.~M.~Wolf and A.~P.~Arkin",
  title =	"Motifs, modules and games in bacteria",
  journal =	"Current Opinion in Microbiology",
  month = "Apr",
  year =	"2003",
  volume =      "6",
  number = "2",
  pages = "125--134",
  abstract = "Computational Systems Biology"
}

@Article{Prusi2000,
 author = "Przemyslaw Prusinkiewicz",
  title =	"Simulation Modelling of Plants and Plant Ecosystems",
  journal =	"Communications of the ACM",
  year =	"2000",
  volume =      "43",
  number = 	"7",
}
@InProceedings{Simms1994,
 author = "Karl Simms",
  title =	"Evolving 3{D} Morphology and Behaviour by Competition",
  booktitle =	"Artificial Life {IV}",
  publisher =	"MIT Press",
  editor =	"R.~Brooks and P.~Maes",
  pages = 	"28--39",
  year =	"1994"
}
@InProceedings{MarkHarris2002,
 author = "M.~J.~Harris and G.~Coombe and T.~Scheuermann and A.~Lastra",
  title =	"Physically-Based Visual Simulation on Graphics Hardware",
  booktitle =	"SIGGRAPH / Eurographics Workshop on Graphics Hardware",
  year =	"2002",
  abstract = "for general purpose GPU programming"
}
@techreport{likas01ias02,
 author = "A.~Likas and N.~Vlassis and J.~J.~Verbeek",
  title = "The global k-means clustering algorithm",
  institution = "Computer Science Institute, University of Amsterdam",
  address = "The Netherlands",
  year = 2001,
  month = feb,
  note = "IAS-UVA-01-02",
  postscript = "ftp://ftp.science.uva.nl/pub/computer-systems/aut-sys/reports/IAS-UVA-01-02.ps.gz",
  url = "citeseer.nj.nec.com/article/likas01global.html"
}

@Book{Aarts1989,
 author = "E.~Aarts and J.~Korst",
  title =	"Simulated Annealing and Boltzmann Machines",
  year =	"1989",
  publisher =   "Wiley",
  address =     "New York"
}

@Book{Motwani95,
 author = "R.~Motwani and P.~Raghavan",
  title =	"Randomized Algorithms",
  year =	"1995",
  publisher =   "Cambridge Univ Press"
}
@Book{MacKayBook,
 author = "David J.~C.~MacKay",
  title =	"Information Theory, Inference and Learning Algorithms",
  year =	"2002",
  edition =	"Draft 2.4.1 February 25, 2002",
  publisher =   "David J.C.~MacKay"
}
@Book{Arfken85,
 author = "G.~Arfken",
  title =	"Mathematical Methods for Physicists",
  year =	"1985",
  edition =	"$3^{rd}$",
  publisher =   "Academic Press, San Diego, CA",
  abstract =    "ref for steepest descent, pp 428-436"
}
@Book{StatisticsExplained,
 author = "P.~R.~Hinton",
  title =	"Statistics Explained",
  year =	"1995",
  edition =	"English",
  publisher =   "Routledge, New York",
}
@Book{SchaumStatistics,
 author = "M.~R.~Spiegel",
  title =	"Theory and problems of Statistics",
  year =	"1971",
  edition =	"English",
  publisher =   "McGraw-Hill Book Company (UK) Ltd"
}
@Book{BrookesAndDick,
 author = "B.~C.~Brookes and W.~F.~L.~Dick",
  title =	"Introduction to Statistical Method",
  year =	"1963",
  publisher =   "Heinemann Educational Books Ltd, London"
}
@Book{Misra92,
 author = "M.~Misra",
  title =	"Implementation of Neural Networks on Parallel Architectures",
  publisher =	"Doctoral Dissertation, Electrical Engineering, University of Southern California",
  year =	"1992"
}
@Book{Duda73,
 author = "R.~O.~Duda and P.~E.~Hart",
  title =	"Pattern Classification and Scence Analysis",
  publisher =	"John Wiley and Sons",
  year =	"1973",
  abstract =	"K-means clustering"
}
@Article{Tohka2003,
 author = "J.~Tohka and A.~Zijdenbos and U.~Ruotsalainen and A.~Evans",
  title =	"Overview on partial volume estimation in brain {MRI}: models and methods",
  journal =	"$1^{st}$ Nordic Workshop on Brain Imaging and Neuroinformatics",
  address =	"Tampere, Finland",
  year =	"2003",
  abstract =	"overview of PV modelling"
}
@Article{Pierpaoli96,
 author = "C.~Pierpaoli and P.~Jezzard and P.~J.~Basser and A.~Barnett and G.~Di Chiro",
  title =	"Diffusion tensor {MR} imaging of the human brain",
  journal =	"Radiology",
  volume =	"201",
  pages =	"637--648",
  year =	"1996",
  abstract =	"modern diffusion reference"
}
@Article{Masulli99,
 author = "F.~Masulli and A.~Schenone",
  title =	"A fuzzy clustering based segmentation system as support to diagnosis in medical imaging",
  journal =	"Artificial Intelligence in Medicine",
  volume =	"16",
  pages =	"129--147",
  year =	"1999",
  abstract =	"fuzzy clustering in mri segmentation"
}
@Article{Bezdek93,
 author = "J.~C.~Bezdek and L.~O.~Hall and L.~P.~Clarke",
  title =	"Review of {MR} image segmentation techniques using pattern recognition",
  journal =	"Medical Physics",
  volume =	"20",
  pages =	"1033--1048",
  year =	"1993",
  abstract =	"review of MRI segmentation"
}
@Article{Pham2000,
 author = "Dzung L.~Pham and Chenyang Xu and Jerry L.~Prince",
  title =	"current methods in medical image processing",
  journal =	"Annual Review of Biomedical Engineering",
  volume =	"2",
  pages =	"315--337",
  year =	"2000",
  abstract =	"review of MRI segmentation - not as outdated as Bezdek93"
}
@Article{Stevenson2000,
 author = "V.~L.~Stevenson and G.~J.~M.~Parker and G.~J.~Barker and K.~Birnie and P.~S.~Tofts and D.~H.~Miller and A.~J.~Thompson",
  title =	"Variations in $T_1$ and $T_2$ relaxation times of normal appearing white matter and lesions in multiple sclerosis",
  journal =	"Journal of Neurological Sciences",
  volume =	"178",
  pages =	"81--87",
  year =	"2000",
  abstract =	"T1 and T2 relaxation times in normal controls were longer in the infra-tentorial, than supra-tentorial, region. which means that T1/T2 on top of the brain are higher than bottom of brain.",
}
@Article{Choi91,
 author = "H.~S.~Choi and D.~R.~Haynor and Y.~M.~Kim",
  title =	"Partial volume tissue classification of multichannel magnetic resonance images -- a mixel model",
  journal =	"{IEEE} Transactions on Medical Images",
  volume =	"10",
  issue =	"3",
  pages =	"395--407",
  year =	"1991",
  abstract =	"a voxel is represented as a weighted sum of the basic tissue types"
}
@Article{Vincken97,
 author = "K.~L.~Vicken and A.~S.~E.~Koster and M.~A.~Viergever",
  title =	"Probabilistic multiscale image segmentation",
  journal =	"{IEEE} Transactions on Pattern Analysis and Machine Intelligence",
  volume =	"19",
  pages =	"109--120",
  issue =       "2",
  year =	"1997",
}
@Article{Nusbaum2000,
 author = "A.~O.~Nusbaum and C.~Y.~Tang and T.~Wei and M.~S.~Buchstaum and S.~W.~Atlas",
  title =	"Whole brain diffusion {MR} histograms differ between {MS} subtypes",
  journal =	"Neurology",
  volume =	"54",
  pages =	"1421--27",
  year =	"2000",
  abstract =	"for FA"
}
@InProceedings{Bensaid91,
 author = "A.~M.~Bensaid and L.~O.~Hall and L.~P.~Clarke and R.~P.~Velthuizen",
  title =	"{MRI} segmentation using supervised and unsupervised methods",
  booktitle =	"Proceedings of the $13^{th}$ Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society",
  address =	"Piscataway, NJ",
  volume =	"30",
  pages = 	"111--126",
  year =	"1991"
}
@InProceedings{Bensaid94,
 author = "A.~M.~Bensaid and L.~O.~Hall and J.~C.~Bezdek and L.~P.~Clarke",
  title =	"Fuzzy cluster validity in {MR} images",
  booktitle =	"Proceedings of SPIE",
  volume =	"2167",
  pages = 	"454--464",
  year =	"1994"
}
@Article{Pierpaoli96b,
 author = "C.~Pierpaoli and P.~J.~Basser",
  title =	"Toward a quantitative assessment of diffusion anisotropy",
  journal =	"Magnetic Resonance in Medicine",
  volume =	"36",
  number = 	"6",
  pages =	"893--906",
  year =	"1996",
  abstract =	"paper describing the statistical bias associated with certain diffusion measures and how they should be avoided to do segmentation etc."
}
@Article{Cohen2000,
 author = "M.~S.~Cohen and R.~M.~Dubois and M.~M.~Zeneith",
  title =	"Rapid and effective correction of {RF} inhomogeneity for high field magnetic resonance imaging",
  journal =	"Human Brain Mapping",
  volume =	"10",
  pages =	"204--211",
  year =	"2000",
  abstract =	"correction of RF"
}
@Article{Paulson77,
 author = "O.~B.~Paulson and M.~M.~Hertz and T.~G.~Bolwig and N.~A.~Lassen",
  title =	"Filtration and diffusion of water across blood-brain barrier in man",
  journal =	"Microvascular Research",
  volume =	"13",
  pages =	"113--124",
  year =	"1977",
  abstract =	"early diffusion reference"
}
@Article{Liang94,
 author = "Z.~Liang and J.~R.~Macfall",
  title =	"Parameter estimation and tissue segmentation from multispectral {MR} images",
  journal =	"{IEEE} Transactions on Medical Imaging",
  volume =	"13",
  number =	"3",
  pages =	"441--449",
  year =	"1994",
  abstract =	"maximum likelihood on MRI segmentation when multivariate gaussian distributions are assumed"
}
@Article{Cocosco97,
 author = "C.~A.~Cocosco and V.~Kollokian and R.~K.~-S.~ Kwan and  A.~C.~Evans",
  title =	"{B}rain{W}eb: Online Interface to a {3D} {MRI} Simulated Brain Database",
  journal =	"NeuroImage",
  volume =	"5",
  number =	"4 (S425)",
  year =	"1997"
}

@Article{Clarke93,
 author = "L.~P.~Clarke and R.~P.~Velthuizen  and S.~Phuphanich and J.~D.~Shellenberg and J.~A.~Arrington",
  title =	"Stability of three supervised segmentation techniques",
  journal =	"Magnetic Resonance Imaging",
  volume =	"11",
  pages =	"95--106",
  year =	"1993",
  abstract =	"parametric methods are  useful only when the distributions for different classes are well known.
		However, this is not necessarily the case for MR images. that is  what it says here"
}
@Article{Kamber93,
 author = "M.~Kamber and R.~Shinghal and A.~C.~Evans and D.~C.~Collins and G.~S.~Francis",
  title =	"Knowledge-based interpretation of magnetic resonance images: Detecting multiple sclerosis lesions",
  journal =	"Artificial Intelligence in Medicine",
  volume =	"10",
  pages =	"32--43",
  year =	"1993",
  abstract =	"detection of lesions using databases [...]"
}
@Article{Moon2002,
 author = "N.~Moon and E.~Bullitt and K.~van Leemput and G.~Gerig",
  title =	"Automatic Brain and Tumor Segmentation",
  journal =	"Proc. Medical Image Computing and Computer-Assisted Intervention MICCAI 2002",
  volume =	"2488",
  pages =	"372--379",
  year =	"2002",
  abstract =	"lesion detection in white matter"
}
@Article{Songyang2002,
 author = "S.~Yu and D.~Pham and D.~Shen and E.~H.~Herskovits and S.~M.~Resnick and C.~Davatzikos",
  title =	"Automatic Segmentation of White Matter Lesions in {$T_{1}$}-Weighted Brain {MR} Images",
  journal =	"IEEE International Symposium on Biomedical Imaging",
  pages =	"253--256",
  year =	"2002",
  abstract =	"lesion detection in white matter"
}
@Article{Arridge89,
 author = "S.~R.~Arridge and S.~R.~Grindrod and A.~D.~Linney and P.~S.~Tofts and D.~Wicks",
  title =	"Use of greyscale voxel databases for improved shading and segmentation",
  journal =	"Medical Informatics",
  volume =	"14",
  number =	"2",
  pages =	"157--171",
  year =	"1989",
  abstract =	"early lesion segmentation I"
}
@Article{Wicks92,
 author = "D.~A.~G.~Wicks and P.~S.~Tofts and D.~H.~Miller and G.~H.~du Boulay and A.~Feinstein and R.~P.~Sacares and I.~Harvey and R.~Brenner and W.~I.~MacDonald",
  title =	"Volume measurement of multiple sclerosis lesions with magnetic resonance images. A preliminary study",
  journal =	"Neuroradiology",
  volume =	"34",
  pages =	"475--479",
  year =	"1992",
  abstract =	"early lesion segmentation II"
}
@Article{Tofts91,
 author = "P.~S.~Tofts and D.~A.~G.~Wicks and G.~J.~Barker",
  title =	"The {MRI} measurement of {NMR} and physiological parameters in tissue to study disease process",
  journal =	"Progress in Clinical and Biological Research",
  volume =	"363",
  pages =	"313--326",
  year =	"1991",
  abstract =	"early lesion segmentation III"
}
@Article{Achiron98,
 author = "D.~Goldberg-Zimring and A.~Achiron and S.~Miron and M.~Faibel and H.~Azhari",
  title =	"Automated Detection and Characterization of Multiple Sclerosis Lesions in Brain {MR} Images",
  journal =	"Magnetic Resonance Imaging",
  volume =	"16",
  number =	"3",
  pages =	"311--318",
  year =	"1998",
  abstract =	"lesion segmentation using gandolinium, neural networks and ... manual input - not good.
		 also note that the use of Gd enhances newer lesions but fails for older lesions (where no blood flow)
		 this means that the algorithm needs to account for two kind of lesion brightness etc."
}
@Article{Vannier85,
 author = "M.~W.~Vannier and R.~L.~Butterfield and D.~Jordan and W.~A.~Murphy and R.~G.~Levitt and M.~Gado",
  title =	"Multispectral analysis of magnetic resonance images",
  journal =	"Radiology",
  volume =	"154",
  pages =	"221--224",
  year =	"1985",
  abstract =	"clustering of multi-spectral (e.g. many modalities) MRI"
}
@Article{Taxt92,
 author = "T.~Taxt and A.~Lundervold and B.~Fuglaas and H.~Lien and V.~Abele",
  title =	"Multispectral Analysis of Uterine corpus tumours in magnetic resonance imaging",
  journal =	"Magnetic Resonance in Medicine",
  volume =	"23",
  pages =	"55--76",
  year =	"1992",
  abstract =	"clustering of multi-spectral (e.g. many modalities) MRI"
}
@Article{Carr54,
 author = "H.~Y.~Carr and et al.",
  title =	"Effects of diffusion on free precession in nuclear magnetic resonance experiments",
  journal =	"Phys Rev",
  volume =	"94",
  pages =	"630--638",
  year =	"1954",
  abstract =	"early diffusion reference"
}
@Article{Dempster77,
 author = "A.~P.~Dempster and N.~M.~Laird and D.~B.~Rubin",
  title =	"Maximum-likelihood from incomplete data via the {EM} algorithm",
  journal =	"Journal of the Royal Statistical Society B",
  volume =	"39",
  pages =	"1--39",
  year =	"1977",
  abstract =	"Expectation Maximisation Clustering"
}
@Article{Woods98,
 author = "R.~P.~Woods and S.~T.~Grafton and C.~J.~Holmes and S.~R.~Cherry and J.~C.~Mazziotta",
  title = "Automated image registration: I. General methods and intrasubject, intramodality validation",
  journal = "Journal of Computer Assisted Tomography",
  volume =	"22",
  pages =	"139--152",
  year =	"1998",
  abstract =	"AIR image registration - used this software to register all images in a common space for lesion segmentation with neural networks"
}
@Article{Ashburner00,
 author = "J.~Ashburner and K.~J.~Friston",
  title =	"Voxel-based morphometry -- the methods",
  journal =	"NeuroImage",
  volume =	"11",
  pages =	"805--821",
  year =	"2000",
  abstract =	"SPM / image segmentation reference"
}
@Article{MacQueen67,
 author = "J.~MacQueen",
  title =	"Some methods for classification and analysis of multivariate observations",
  journal =	"Proceedings of the Fifth Berkeley Symposium on Mathematics, Statistics and Probability",
  volume =	"1",
  pages =	"281--296",
  year =	"1967",
}

@Article{WidrowHoff60,
 author = "B.~Widrow and M.~E.~Hoff",
  title =	"Adaptive switching circuits",
  journal =	"IRE WESCON Convention Record",
  volume =	"4",
  pages =	"96--104",
  year =	"1960",
}

@Article{Friston95,
 author = "K.~J.~Friston and J.~Ashburner and C.~D.~Frith and J.~B.~Poline",
  title =	"Spatial registration and normalization of images",
  journal =	"Human Brain Mapping",
  volume =	"2",
  pages =	"165--189",
  year =	"1995",
  abstract =	"also authors : K.J. Friston, J. Ashburner, C.D. Frith, J.B. Poline, J.D. Heather and R.S.J. Frackowiak",
}
@Article{Stafylopatis92,
 author = "D.~Kontoravdis and A.~Stafylopatis and S.~Kollias",
  title =	"Parallel Implementation of Structured Feedforward Neural Networks for Image Recognition",
  journal =	"International Journal of Neural Networks",
  volume =	"2",
  pages =	"91--99",
  year =	"1992",
}
@Article{Cover65,
 author = "T.~M.~Cover",
  title =	"Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition",
  journal =	"IEEE Transactions on Electronic Computers",
  volume =	"14",
  pages =	"326--334",
  year =	"1965",
  abstract =	"the probability of getting linear separable dichotomies of N patterns in M-dimensional space, through bishop's book"
}
@InProceedings{Lindsey94,
 author = "C.~Lindsey and T.~Lindblad",
  title =	"Review of hardware neural networks: a user's perspective",
  booktitle =	"Proceedings of ELBA94",
  year =	"1994"
}
@InProceedings{Zell93,
 author = "A.~Zell and N.~Mache and M.~Vogt and M.~Huettel",
  title =	"Problems of massive parallelism in neural network simulation",
  booktitle =	"Proceedings of the IEEE Int. Conf. on Neural Networks",
  address =	"San Francisco, CA",
  volume =	"3",
  pages = 	"1890--1895",
  month =	march,
  year =	"1993"
}
@InProceedings{Craven94,
 author = "M.~W.~Craven and J.~W.~Shavlik",
  title =	"Using sampling and queries to extract   rules   from   trained  neural  networks",
  booktitle =	"Machine Learning:  Proceedings   of   the   Eleventh   International Conference",
  address =	"San Francisco, CA",
  year =	"1994"
}
@Article{Murre93,
 author = "J.~M.~J.~Murre",
  title =	"Transputers and neural networks: An analysis of implementation constraints and performance",
  journal =	"IEEE Transactions on Neural Networks",
  volume =	"4",
  number =	"2",
  pages =	"284--292",
  month = 	March,
  year =	"1993",
}
@Article{Amari90,
 author = "S.~I.~Amari",
  title =	"Mathematical foundations of neurocomputing",
  journal =	"Proceedings of the IEEE",
  volume =	"78",
  number =	"9",
  pages =	"1443--1463",
  year =	"1990",
}
@Article{Sarkar95,
 author = "D.~Sarkar",
  title =	"Methods to speed up error back propagation learning algorithm",
  journal =	"ACM Computing Surveys",
  volume =	"27",
  number =	"4",
  pages =	"519--542",
  year =	"1995",
  abstract =	"a survey of improvements to the back prop for speed up",
}
@InBook{Hadjiprocopis2009b,
 author = "Nicos Angelopoulos and Andreas Hadjiprocopis and Malcolm D. Walkinshaw",
 title = "Chemoinformatics and Advanced Machine Learning Perspectives: Complex Computational Methods and Collaborative Techniques",
  chapter = "Learning binding affinity from augmented high throuput screening data (to appear)",
  editor = "Huma Lodhi and Yoshihiro Yamanishi",
  publisher = "IGI",
  series = "Book Series on Chemoinformatics",
  month = "Feb",
  year =	"2009"
}
@Article{Hadjiprocopis2009a,
 author = "Nicos Angelopoulos and Andreas Hadjiprocopis and Malcolm D. Walkinshaw",
  title = "Bayesian Model Averaging for Ligand Discovery (to appear)",
  journal =	"Journal of Chemical Information and Modeling",
  month = "Jan",
  year =	"2009"
}
@Article{Hadjiprocopis2007a,
 author = "G.~R.~Davies and A.~Hadjiprocopis and D.~R.~Altmann and D.~T.~Chard and C.~M.~Griffin and W.~Rashid and G.~J.~Parker and P.~S.~Tofts  and R.~Kapoor and A.~J.~Thompson and D.~H.~Miller",
  title = "Normal-appearing grey and white matter {T1} abnormality in early relapsing-remitting multiple sclerosis: a longitudinal study",
  journal =	"Multiple Sclerosis",
  month = "Mar",
  volume = "13",
  issue = "2",
  pages = "169--77",
  year =	"2007"
}
@Article{Hadjiprocopis2005a,
 author = "G.~R.~Davies and D.~R.~Altmann and A.~Hadjiprocopis and W.~Rashid and D.~T.~Chard and C.~M.~B.~Griffin and P.~S.~Tofts and G.~J.~Barker and R.~Kapoor and A.~J.~Thompson and D.~H.~Miller",
  title = "Increasing normal-appearing grey and white matter magnetisation transfer ratio abnormality in early relapsing-remitting multiple sclerosis",
  journal =	"Journal of Neurology",
  month = "Sep",
  volume = "252",
  issue = "9",
  pages = "1037--44",
  year =	"2005"
}
@Article{Hadjiprocopis2005b,
  author = "A.~Hadjiprocopis and W.~Rashid and P.~Tofts",
  title = "Unbiased segmentation of diffusion weighted Magnetic Resonance Images of the brain using iterative clustering",
  journal =	"Magnetic Resonance Imaging",
  month = "Oct",
  volume = "23",
  issue = "8",
  pages = "877--85",
  year =	"2005",
  abstract = "top-25 oct-dec 2005 for science direct website"
}
@Article{Hadjiprocopis2004b,
 author = "W.~Rashid and A.~Hadjiprocopis and C.~M.~Griffin and D.~T.~Chard and G.~R.~Davies and G.~J.~Barker and P.~S.~Tofts and A.~J.~Thompson and D.~H.~Miller",
  title = "Diffusion tensor imaging of early relapsing-remitting multiple sclerosis with histogram analysis using automated segmentation and brain volume correction",
  journal =	"Multiple Sclerosis",
  year =	"2004",
  month = "Feb",
  volume = "10",
  issue = "1",
  pages = "9--15",
  abstract = "paper"
}
@Article{Hadjiprocopis2004a,
 author = "G.~R.~Davies and L.~Rami\'{o}-Torrent\`{a} and A.~Hadjiprocopis and D.~T.~Chard and C.~M.~B.~Griffin and W.~Rashid and G.~J.~Barker and R.~Kapoor and A.~J.~Thompson and D.~H.~Miller",
  title = "Evidence for grey matter {MTR} abnormality in minimally disabled patients with early relapsing-remitting multiple sclerosis",
  journal =	"Journal of Neurology, Neurosurgery and Psychiatry",
  month = "Jul",
  volume = "75",
  issue = "7",
  pages = "998--1002",
  year =	"2004"
}
@Article{Hadjiprocopis2003a,
 author = "S.~Hickman and A.~Hadjiprocopis and O.~Coulon and D.~H.~Miller and G.~J.~Barker",
  title =	"Spinal Cord {MTR} Histograms in Multiple Sclerosis Using a {3D} Gradient Echo Acquisition",
  journal =	"$11^{th}$ Scientific Meeting of the International Society for Magnetic Resonance in Medicine",
  year =	"2003",
  month = 	"May",
}
@Article{Hadjiprocopis2003b,
 author = "A.~Hadjiprocopis and P.~Tofts",
  title =	"Towards an Automatic Lesion Segmentation Method on {FSE} Images using an Ensemble of Neural Networks",
  journal =	"$11^{th}$ Scientific Meeting of the International Society for Magnetic Resonance in Medicine",
  year =	"2003",
  month = 	"May",
}
@Article{Hadjiprocopis2003c,
 author = "A.~Hadjiprocopis and R.~Waqar and P.~Tofts",
  title =	"Segmentation of {$T_{2}$}-weighted {MRI} using an Ensemble of Neural Networks and Clustering Experts",
  journal =	"$11^{th}$ Scientific Meeting of the International Society for Magnetic Resonance in Medicine",
  year =	"2003",
  month = 	"May",
}
@Article{Hadjiprocopis2003d,
 author = "A.~Hadjiprocopis and P.~Tofts",
  title =	"An Automatic Lesion Segmentation Method for Fast Spin Echo Magnetic Resonance Images using an Ensemble of Neural Networks",
  journal =	"{IEEE} {I}nternational {W}orkshop on {N}eural {N}etworks for {S}ignal {P}rocessing ({NNSP})",
  year =	"2003",
  month = 	"Sep",
}
@Article{Hadjiprocopis2003f,
  author = "W.~Rashid and A.~Hadjiprocopis and C.~M.~Griffin and D.~T.~Chard and G.~R.~Davies and G.~J.~Barker and P.~S.~Tofts and A.~J.~Thompson and D.~H.~Miller",
  title = "Investigation of early relapsing-remitting multiple sclerosis using diffusion {MR} histograms",
  journal =	"$11^{th}$ Scientific Meeting of the International Society for Magnetic Resonance in Medicine",
  year =	"2003",
  month = 	"May"
}
@TechReport{Hadjiprocopis2002,
 author = "A.~Hadjiprocopis",
  title =	"Segmentation of {$T_{2}$}-weighted {MRI} using entropy minimisation by simulated annealing",
  type = "Technical Report",
  institution =	"NMR Research Unit, Institute of Neurology, London, UK",
  year =	"2002",
  month = 	"Dec",
}
@Article{Hadjiprocopis2003i,
  author = "S.~J.~Hickman and A.~Hadjiprocopis and O.~Coulon and D.~H.~Miller and G.~J.~Barker",
  title = "Cervical spinal cord {MTR} histogram analysis in multiple sclerosis using a {3D} acquisition and a {B}-spline active surface segmentation technique",
  journal =	"Magnetic Resonance Imaging",
  year =	"2004",
  volume = "22",
  number = "6",
  pages = "891--895"
}
@Article{Hadjiprocopis94,
 author = "A.~Hadjiprocopis and P.~Smith and R.~Comley and S.~Lakkos",
  title =	"A Neural Network Scheme for Earthquake prediction based on the Seismic Electric Signals",
  journal =	"{IEEE} Conference on Neural Networks and Signal Processing",
  year =	"1994"
}
@Article{CANCELHadjiprocopis95,
 author = "G.~Alusi and A.~Hadjiprocopis and A.~Linney and A.~Wright",
  title =	"Three Dimensional Tracking with Ultrasound for Virtual Reality applications in Surgery",
  journal =	"Digital Signal Processing",
  year =	"1995",
}
@InCollection{Hadjiprocopis97a,
 author = "A.~Hadjiprocopis and P.~Smith",
  title =	"Feed Forward Neural Network Entities",
  booktitle =	"Lecture Notes in Computer Science: Biological and Artificial Computation: From Neuroscience to Technology",
  editor =	"J.~Mira and R.~Moreno-Diaz and J.~Cabestany",
  publisher =	"Springer--Verlag",
  year =	"1997",
  pages =	"349--359",
  abstract =	"IWANN 97, Lanzarote"
}
@InProceedings{Hadjiprocopis97b,
 author = "A.~Hadjiprocopis and P.~Smith",
  title =	"Feed Forward Neural Network Entities in the analysis of high-dimensional data",
  booktitle =	"Proceedings of the $3^{rd}$ International Conference on Neural Networks and their Applications",
  year =	"1997",
  pages =	"147--154",
  abstract =	"NEURAP 97, Marseilles"
}
@InProceedings{Hadjiprocopis98,
 author = "A.~Hadjiprocopis and P.~Smith",
  title =	"Feed Forward Neural Network Entities in Time Series Prediction and Image Classification",
  booktitle =	"Proceeding of the International ICSC/IFAC Symposium on Neural Computation",
  year =	"1998",
  address = 	"Vienna",
  pages =	"1002--1008",
  abstract =	"NC 98, Vienna"
}
@misc{Hadjiprocopis93,
 author = "A.~Hadjiprocopis",
  title =	"A Neural Network Implementation on a Transputer System and Applications",
  school =	"Electrical Engineering Department, The City University",
  year =	"1993",
  address = 	"Northampton Square, London, EC1V 0HB",
  month =	"Apr",
  note =	"{B.Eng.} thesis"
}
@misc{Hadjiprocopis2000,
 author = "A.~Hadjiprocopis",
  title =	"Feed Forward Neural Network Entities",
  school =	"School of Informatics, The City University",
  year =	"2000",
  address = 	"Northampton Square, London, EC1V 0HB",
  month =	"Sep",
  note =	"{Ph.D.} thesis"
}
@manual{npmanual97,
  title =	"The {\em np\hspace{-1.33\fontdimen6\font} np\hspace{0.45\fontdimen6\font}} script language and interpreter",
 author = "A.~Hadjiprocopis",
  address =	"Room A528, The City University, London EC1V 0HB, livantes@@soi.city.ac.uk, http://www.soi.city.ac.uk\~livantes/home.html",
  year =	"1997",
  month =	"Jun"
}
@Book{Arbib87,
 author = "M.~A.~Arbib",
  title =	"Brains, Machines, and Mathematics",
  edition =	"2nd",
  publisher =	"Springer--Verlag",
  address =	"New York, NY",
  year =	"1987",
}
@Book{BoseLiang96,
 author = "N.~Bose and P.~Liang",
  title =	"Neural Network Fundamentals: graphs, algorithms and applications",
  publisher =	"McGraw-Hill",
  year =	"1996",
  abstract =	"Good mathematical analysis of the perceptron and FFNN, minsky's order of a predicate can be found here."
}
@Book{Haykin94,
 author = "S.~Haykin",
  title =	"Neural Networks",
  edition =	"1st",
  publisher =	"Macmillan",
  address =	"Canada",
  year =	"1994"
}
@InProceedings{Nielsen89,
 author = "R.~Hecht-Nielsen",
  title =	"Theory of the Backpropagation Neural Network",
  booktitle =	"Proceedings of the International Joint Conference on Neural Networks",
  volume =	"1",
  pages =	"593--606",
  year =	"1989",
}
@Book{Nielsen90,
 author = "R.~Hecht-Nielsen",
  title =	"Neurocomputing",
  publisher =	"Addison--Wesley",
  address =	"Menlo Park, CA",
  year =	"1990",
  abstract =	"Another good book on the theory of neural networks with a
		deep mathematical approach.",
}
@Article{Knight90,
 author = "K.~Knight",
  title =	"Connectionist ideas and algorithms",
  journal =	"Communications of the ACM",
  volume =	"33",
  number =	"11",
  pages =	"59--74",
  year =	"1990",
}
@InCollection{McClelland:Rumelhart:Hinton86,
 author = "J.~L.~McClelland D.~E.~Rumelhart and G.~E.~Hinton",
  editor =	"D.E.~Rumelhart and J.L.~McClelland",
  title =	"The Appeal of Parallel Distributed Processing",
  booktitle =	"Parallel Distributed Processing: {E}xplorations in the Microstructure of Cognition, Vol. 1: {F}oundations",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  pages =	"3--44",
  year =	"1986",
}
@Book{Minsky69,
 author = "M.~Minsky and S.~Papert",
  title =	"Perceptrons",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  year =	"1969",
  abstract =	"A neat hatchet job by the leaders of the 'Symbolic
		Programming' school of Artificial Intelligence, on the
		'Network' school; probably responsible for the latter
		appearing to be brain dead for the next decade.
		Contains extensive mathematical analysis of 1-layer networks.",
}
@Book{Minsky:Papert88,
 author = "M.~Minsky and S.~Papert",
  title =	"Perceptrons: {A}n Introduction to Computational Geometry",
  edition =	"Expanded",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  year =	"1988",
  abstract =	"A continuation of their first book but stronger. In a way an
		answer to McClelland's and Rumelhart's PDP book series.
		Pay special attention to the last chapter, the Epilog, where
		they make some suggestions about Connectionism",
}
@Book{Rumelhart:McClelland86a,
 author = "D.~E.~Rumelhart and J.~L.~McClelland",
  title =	"Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  volume =	"1",
  year =	"1986",
  abstract =	"This is {"}the Bible{"} in the field. Chapters by the
		authors, F.H.C. Crick, L. Elman, G. Hinton, M. Jordan,
		A.H. Kawamoto, P.W. Munro, D.A. Norman, D.E. Rabin, T.
		Sejnowski, P. Smolensky, G.Stone, R.J. Williams, D.
		Zipser. Partial contents list: Vol. 1 -- Part I: The PDP
		Perspective (4 chapters), Part II: Basic Mechanisms
		Part III: Formal Analyses Vol. 2 -- Part IV:
		Psychological processes, Part V: Biological Mechanisms,
		Part VI: Conclusion.",
}
@Book{Rumelhart:McClelland86b,
 author = "D.~E.~Rumelhart and J.~L.~McClelland",
  title =	"Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Psychological and Biological Models",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  volume = 	"2",
  year =	"1986",
}
@InCollection{Rumelhart:Hinton:McClelland86c,
 author = "D.~E.~Rumelhart and G.~E.~Hinton and J.~L.~McClelland",
  title =	"A general framework for parallel distributed processing",
  booktitle =	"Parallel Distributed Processing: Explorations in the Microstructure of Cognition",
  editor =	"D.E.~Rumelhart and J.L.~McClelland",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  pages =	"45--76",
  year =	"1986",
}
@InCollection{Rumelhart:Hinton:Williams86d,
 author = "D.~E.~Rumelhart and G.~E.~Hinton and R.~J.~Williams",
  title =	"Learning Internal Representations by Back-Propagating Errors",
  booktitle =	"Parallel Distributed Processing: Explorations in the Microstructure of Cognition",
  editor =	"D.E.~Rumelhart and J.L.~McClelland",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
  year =	"1986",
}
@Article{Rumelhart:Hinton:Williams86e,
 author = "D.~E.~Rumelhart and G.~E.~Hinton and R.~J.~Williams",
  title =	"Learning Representations by Back-Propagating Errors",
  pages =	"533--536",
  journal =	"Nature",
  volume =	"323",
  year =	"1986",
}
@InProceedings{Sietsma88,
 author = "J.~Sietsma and R.~J.~F.~Dow",
  title =	"Neural Net Pruning---Why and How",
  pages =	"325--333",
  booktitle =   "IEEE International Conference on Neural Networks",
  volume =	"1",
  address =	"San Diego",
  publisher =	"IEEE, New York",
  year =	"1988",
}
@InProceedings{Sutton86,
 author = "R.~S.~Sutton",
  title =	"Two Problems with Back--Propagation and Other Steepest--Descent Learning Procedures for Networks",
  booktitle =	"Proceedings of the Eighth Annual Conference of the Cognitive Science Society",
  pages =	"823--831",
  year =	"1986",
}
@InProceedings{Weigend:Rumelhart:Huberman90,
 author = "A.~S.~Weigend and D.~E.~Rumelhart and B.~A.~Huberman",
  title =	"Back--propagation, weight elimination and time series prediction",
  booktitle =	"Proceedings of the 1990 Connectionist Models Summer School",
  publisher =	"Morgan Kaufmann",
  pages =	"65--80",
  year =	"1990",
}
@InProceedings{Weigend91,
 author = "A.~S.~Weigend and B.~A.~Huberman and D.~E.~Rumelhart",
  title =	"Predicting sunspots and exchange rates with connectionist networks",
  booktitle =	"Nonlinear Modeling and Forecasting, SFI Studies in the Sciences of Complexity",
  volume =	"12",
  editor =	"M.~Casdagli and S.~Eubank",
  publisher =	"Addison--Wesley",
  year =	"1991",
}
@Book{Werbos74,
 author = "P.~J.~Werbos",
  title =	"Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences",
  publisher =	"Doctoral Dissertation, Applied Mathematics, Harvard University",
  address =	"Boston, MA",
  month =	nov,
  year =	"1974",
  abstract =	"This is an attempt to introduce and explore back-propagation. The emergence of this
		new learning algorithm for multilayer perceptrons initiated the new interest in neural nets.",
}
@InProceedings{Werbos88,
 author = "P.~JWerbos",
  title =	"Back-Propacation: Past and Future",
  booktitle =	"Proceedings of IEEE International Conference on Neural Networks",
  volume =	"1",
  pages =	"343--353",
  publisher =	"IEEE Press, New York",
  year =	"1988",
}
@Book{Anderson88,
  editor =	"J. A.~Anderson and E.~Rosenfeld",
  title =	"Neurocomputing: Foundations of Research",
  publisher =	"MIT Press",
  address =	"Cambridge",
  year =	"1988",
  abstract =	"A collection of fine papers and book-extracts on the field of Connectionism and Cognitive
		Science. It is in the City University Library.",
}
@Article{Baldi89,
 author = "P.~Baldi and K.~Hornik",
  title =	"Neural Networks and Principal Component Analysis: Learning from Examples Without Local Minima",
  pages =	"53--58",
  journal =	"Neural Networks",
  volume =       "2",
  year =         "1989",
}
@Article{Caianiello61,
 author = "E.~R.~Caianiello",
  title =	"Outline of a Theory of Thought and Thinking Machines",
  pages =	"204--235",
  journal =	"Journal of Theoretical Biology",
  volume =	"1",
  year =	"1961",
}
@Article{Feldman82,
 author = "J.~A.~Feldman and D.~H.~Ballard",
  title =	"Connectionist Models and Their Properties",
  journal =	"Cognitive Science",
  volume =	"6",
  year =	"1982",
}
@Book{Hebb49,
 author = "D.~O.~Hebb",
  title =	"The Organization of Behavior",
  publisher =	"Wiley",
  address =	"New York",
  year =	"1949",
  abstract =	"This is the book that started it all: Hebbian learning",
}
@InCollection{Hornik:Stinchcombe:White92,
 author = "K.~Hornik and M.~Stinchcombe and H.~White",
  title =	"Multilayer Feedforward Networks Are Universal Approximators",
  booktitle =	"Artificial Neural Networks: Approximation and Learning Theory",
  editor =	"Halber White",
  publisher =	"Blackwell",
  address =	"Oxford, UK",
  year =	"1992",
  pages =	"12--28"
}
@InCollection{Gallant:White92,
 author = "A.~R.~Gallant and H.~White",
  title =	"There Exists a Neural Network That Does Not Make Avoidable Mistakes",
  booktitle =	"Artificial Neural Networks: Approximation and Learning Theory",
  editor =	"Halber White",
  publisher =	"Blackwell",
  address =	"Oxford, UK",
  year =	"1992",
  pages =	"5--11"
}
@Book{Jolliffe86,
 author = "I.~T.~Jolliffe",
  title =	"Principal Component Analysis",
  publisher =	"Springer--Verlag",
  address =	"New York",
  year =	"1986",
}
@Article{Kirkpatrick83,
 author = "S.~Kirkpatrick and C.~D.~Gelatt Jr. and M.~P.~Vecchi",
  title =	"Optimization by Simulated Annealing",
  journal =	"Science",
  volume =	"220",
  year =	"1983",
  pages =	"671--680",
}
@Article{Metropolis53,
 author = "N.~A.~Rosenbluth and M.~Rosenbluth and A.~Teller and E.~Teller",
  title =	"Equation of State Calculations by Fast Computing Machines",
  journal =	"Journal of Chemical Physics",
  volume =	"21",
  number =	"6",
  year =	"1953",
  pages =	"1087--1092",
  abstract =	"the original simulated annealing ref"
}
@Article{Lippmann87,
 author = "R.~P.~Lippmann",
  title =	"An Introduction to Computing with Neural Nets",
  pages =	"4--22",
  journal =	"IEEE ASSP Magazine",
  month =	apr,
  year =	"1987",
}
@Article{McCulloch43,
 author = "W.~S.~McCulloch and W.~Pitts",
  title =	"A Logical Calculus of Ideas Immanent in Nervous Activity",
  journal =	"Bulletin of Mathematical Biophysics",
  volume =	"5",
  year =	"1943",
  abstract =	"These two were the first to introduce the neuronal unit but only with threshold or
		linear activation functions. There neural model could learn to calculate simple,
		linearly separable problems but could not suffice for the XOR problem where the
		training data is linearly inseparable. They started the hype of neural nets until
		Minsky and Papert realised the weakness of their model and burried the Connectionist
		movement at its birth. There were some politics involved as well, for example the
		DARPA reseacrh grants (symbolic AI or connectionism?).",
}
@Article{Mitchison89,
 author = "G.~J.~Mitchison and R.~M.~Durbin",
  title =	"Bounds on the Learning Capacity of Some Multi-Layer Networks",
  pages =	"345--356",
  journal =	"Biological Cybernetics",
  volume =	"60",
  year =	"1989",
}
@Article{Packard80,
 author = "N.~H.~Packard and J.~PCrutchfield and J.~D.~Farmer and R.~S.~Shaw",
  title =	"Geometry from a Time Series",
  pages =	"712--716",
  journal =	"Physical Review Letters",
  volume =	"45",
  year =	"1980",
}
@Book{Rosenblatt62,
 author = "F.~Rosenblatt",
  title =	"Principles of Neurodynamics",
  publisher =	"Spartan",
  address =	"New York",
  year =	"1962",
}
@Article{Rosenblatt,
 author = "F.~Rosenblatt",
  title =	"The perceptron: a probabilistic model for information storage and organization in the brain",
  pages =	"386--408",
  journal =	"Psychological Review",
  volume =	"65",
}
@Article{Calvin87,
 author = "W.~H.~Calvin",
  title =	"The Brain as a Darwin Machine",
  journal =	"Nature",
  pages =	"33--34",
  address =	"London",
  volume =	"330",
  month =	nov,
  year =	"1987",
  abstract =	"For parallel computers to simulate our brains, we must
		face the fact that human beings have a better claim on
		the title 'Homo seriatim' than 'Homo sapiens' - we're
		more consistently serial than wise.",
}
@Article{Varotsos84,
 author = "P.~Varotsos and K.~Alexopoulos",
  title =	"Physical Properties of the Variation of the Electric Field of the Earth Preceding Earthquakes 1 and 2",
  journal =	"Techtonophysics",
  volume =	"110",
  year =	"1984",
  abstract =	"A paper for the seismic prediction work, from a
		signal processing point of view",
}
@Book{vonNeumann,
 author = "J.~von Neumann",
  title =	"The Computer and the Brain",
  publisher =	"Yale University Press",
  pages	=	"66--82",
}
@Book{Freeman91,
 author = "J.~Freeman",
  title =	"Neural Networks: Theory and Practice",
  publisher =	"Addison--Wesley",
  year =	"1991",
  abstract =	"Excellent reference for the theory of Neural Networks and
		a description of many different models. A nice introduction
		to the gradient-descent algorithm and Delta-rule for training
		of the Feed Forward Model. Special attention to the first three
		chapters.",
}
@Book{Wasserman89,
 author = "P.~D.~Wasserman",
  title =	"Neural Computing: Theory and practice",
  publisher =	"Van Nostrand Reinhold",
  year =	"1989",
  abstract =	"A quite simple book but none-the-less a good introduction.",
}
@Book{Bechtel90,
 author = "W.~Bechtel and A.~Abrahamsen",
  title =	"Connectionism and the mind",
  publisher =	"Basil Blackwell",
  year =	"1990",
}
@Book{Anderson64,
 author = "A.~Anderson",
  title =	"Minds and machines",
  publisher =	"Prentice--Hall",
  year =	"1964",
}
@Book{Arnheim69,
 author = "R.~Arnheim",
  title =	"Visual thinking",
  publisher =	"University of California Press",
  year =	"1969",
  abstract =	"Mostly psychology and theory of cognition with a philosophical perspective",
}
@Article{Kohonen82,
 author = "T.~Kohonen",
  title =	"Self---organizing formation of topologically correct feature maps",
  journal =	"Biological Cybernetics",
  volume =	"43",
  pages =	"59--69",
  year =	"1982",
}
@Book{Kohonen84,
 author = "T.~Kohonen",
  title	=	"Self--Organization and Associative Memory",
  publisher =	"Springer--Verlag",
  edition =	"3rd",
  address =	"Berlin",
  year =	"1989",
  abstract =	"Kohonen is considered as one of the pioneers in Self--Organisational
		models of neural networks.",
}
@Article{Hopfield84,
 author = "J.~J.~Hopfield",
  title =	"Neurons with a graded response have collective computational properties like those of two--state neurons",
  journal =	"Proceedings of the National Academy of Science USA",
  volume =	"81",
  pages =	"3088--3092",
  month =	May,
  year =	"1984",
}
@TechReport{Burrows:Niranjan93,
 author = "T.~L.~Burrows and M.~Niranjan",
  title =	"The Use of Feed--forward and Recurrent Neural Networks for System Identification",
  type =	"Technical Report",
  institution =	"Cambridge University Engineering Department",
  year =	"1993",
}
@Article{Cybenko89,
 author = "G.~Cybenko",
  title =	"Approximation by superpositions of a sigmoidal function",
  journal =	"Mathematics of Control, Signals, and Systems",
  publisher =	"Springer--Verlag",
  volume =	"2",
  number =	"4",
  pages =	"303--314",
  year =	"1989",
}
@Article{White89,
 author = "H.~White",
  title =	"Learning in artificial neural networks: {A} statistical perspective",
  journal =	"Neural Computation",
  publisher =	"MIT Press",
  volume =	"1",
  number =	"4",
  pages =	"425--464",
  year =	"1989",
}
@Article{Ackley85,
 author = "D.~H.~Ackley and G.~E.~Hinton and T.~J.~Sejnowski",
  title =	"A Learning Algorithm for Boltzmann Machines",
  journal =	"Cognitive Science",
  volume =       "9",
  year =         "1985",
}
@Article{Hinton89,
 author = "G.~E.~Hinton",
  title =	"Connectionist learning procedures",
  journal =	"Artificial Intelligence",
  volume =      "40",
  pages =	"185--234",
  year =        "1989",
}
@Article{Fodor88,
 author = "J.~A.~Fodor and Z.~W.~Pylyshyn",
  title =	"Connectionism and cognitive architecture: {A} critical analysis",
  journal =	"Cognition",
  volume =	"28",
  pages =	"3--72",
  year =	"1988",
  abstract =	"Yet another publication critisizing the Connectionist approach
		to AI from a cognitive perspective this time.",
}
@Book{Lavine83,
 author = "R.~A.~Lavine",
  title	=	"Neurophysiology: The Fundamentals",
  publisher =	"The Collamore Press",
  address =	"Lexington, MA",
  year =	"1983",
  abstract =	"An introduction to the physiology of the brain.",
}
@Book{MacGregor87,
 author = "R.~J.~MacGregor",
  title	=	"Neural and Brain Modeling",
  publisher =	"Academic Press",
  address =	"San Diego, CA",
  year =	"1987",
  abstract =	"A text on how to model the brain and its functions.",
}
@Article{Yao93,
 author = "X.~Yao",
  title =	"A Review of Evolutionary Artificial Neural Networks",
  journal =	"International Journal of Intelligent Systems",
  volume =	"8",
  pages =	"539--567",
  year =	"1993",
  abstract =	"An excellent review of the current methods of applying genetic
		algorithms in neural networks in many dfferent ways, i.e.
		architecture, training and learning rules.",
}
@Book{Goldberg89,
 author = "D.~E.~Goldberg",
  title =	"Genetic Algorithms in Search, Optimization, and Machine Learning",
  publisher =	"Addison--Wesley",
  address =	"Reading",
  year =	"1989",
  abstract =	"One of the best books on genetic algorithms. Very comprehensive.",
}
@Book{Reeves95,
 author = "R.~R.~Reeves",
  title =	"Modern Heuristic Techniques for Combinatorial Problems",
  publisher =	"McGraw--Hill",
  year =	"1995",
  abstract =	"A good and comprehensive review of the current trends in
		optimisation by non-exhaustive search."
}
@Book{Bishop95,
 author = "C.~Bishop",
  title =	"Neural Networks for Pattern Recognition",
  publisher =	"Clarendon Press",
  address =	"Oxford",
  year =	"1995",
  abstract =	"A very nice book on neural networks, error minimisation and pattern
		recognition. Mention of entities in Chapter 9, page 364.",
}
@inproceedings{Krogh95,
    author = "Anders Krogh and Jesper Vedelsby",
    title = "Neural Network Ensembles, Cross Validation, and Active Learning",
    booktitle = "Advances in Neural Information Processing Systems",
    volume = "7",
    publisher = "The {MIT} Press",
    editor = "G. Tesauro and D. Touretzky and T. Leen",
    pages = "231--238",
    year = "1995",
    url = "citeseer.ist.psu.edu/krogh95neural.html",
   abstract = "Learning of continuous valued functions using neural network ensembles"
}
@article{Jacobs95,
  author = "R.~A.~Jacobs",
  title = "Methods for combining experts' probability assessment",
  journal = "Neural Computation",
  volume = "7",
  pages = "867--888",
  year = "1995",
  abstract = "proper overview of modular nn"
}
@article{Xu1992,
  author = "L.~Xu and A.~Krzyzak and C.~Y.~Suen",
  title = "Methods of combining multiple classifiers and their applications to handwriting recognition",
  journal = "EEE Transactions on Systems, Man, and Cybernetics",
  volume = "22",
  number = "3",
  pages = "418--435",
  year = "1992",
  abstract = "proper overview of modular nn"
}
@article{Sharkey96,
  author = "A.~Sharkey",
  title = "On combining artificial neural nets",
  journal = "Connection Science",
  volume = "8",
  pages = "299--313",
  year = "1996",
  abstract = "some review of modular nn",
  url = "citeseer.nj.nec.com/sharkey96combining.html"
}
@inproceedings{Sharkey98,
  author = "A.~Sharkey and N.~Sharkey and S.~Cross",
  title = "Adapting an Ensemble Approach for the Diagnosis of Breast Cancer",
  year = "1998",
  booktitle = "{ICANN}",
  publisher = "Springer-Verlag",
  pages = "281--286",
  abstract = "neural network ensembles in medicine, more",
  url = "citeseer.nj.nec.com/sharkey98adapting.html"
}
@article{Zhou2002,
  author = "Z.~H.~Zhou and Y.~Jiang, Y.~B.~Yang, S.~F.~Chen",
  title = "Lung Cancer Cell Identification Based on Artificial Neural Network Ensembles",
    journal = "Artificial Intelligence in Medicine, 2002, 24(1): 25-36",
    volume = "24",
    number = "1",
    pages = "25--36",
    year = "2002",
    absract = "neural network ensembles in medicine",
  url = "citeseer.nj.nec.com/zhou02lung.html" 
}
@Article{Hansen1990,
  author = "L.~K.~Hansen and P.~Salamon",
  title = "Neural network ensembles",
    journal = "IEEE Transactions in Pattern Analysis and Machine Intelligence",
    volume = "12",
    number = "10",
    pages = "993--1001",
    year = "2002",
}
@Article{Wolpert92,
 author = "D.~H.~Wolpert",
  title =	"Stacked generalisation",
  journal =	"Neural Networks",
  volume =	"5",
  pages =	"241--259",
  year =	"1992",
  abstract =	"Mentioned by Bishop95 for using several neural networks to obtain an
		alternative to a single neural network.",
}
@Book{Weigend93,
 author = "A.~S.~Weigend",
  title =	"Time Series Prediction : Forecasting the Future and Understanding the Past",
  publisher =	"Addison--Wesley",
  year =	"1993",
  abstract =	"A case study of applications of neural networks in the field of time series prediction."
}
@Book{Gately96,
 author = "E.~Gately",
  title =	"Neural Networks for Financial Forecasting,",
  publisher =	"John Wiley",
  year =	"1996",
  address =	"New York",
}
@Article{Nielsen87,
 author = "R.~Hecht--Nielsen",
  title =	"Kolmogorov's mapping neural network existence theorem",
  journal =	"IEEE First International Conference on Neural Networks, San Diego",
  publisher =	"SOS Printing",
  volume =	"3",
  pages =	"11-14",
  year =	"1987",
  abstract =	"Use this instead of kolmogorov's original (1957) because it is in russian!!!"
}
@Article{Kolmogorov57,
 author = "A.~N.~Kolmogorov",
  title =	"On the representation of continuous functions of many variables by superposition of continuous functions of one variable and addition.",
  journal =	"Doklady Akademii Nauk SSR",
  volume =	"114",
  pages =	"953--956",
  year =	"1957",
  abstract =	"Kolmogorov's original work"
}
@Article{Hilbert00,
 author = "D.~Hilbert",
  title =	"Mathematical Problems",
  journal =	"Bulletin of the American Mathematical Society",
  volume =	"8",
  pages =	"437--479",
  year =	"1902",
  abstract =	"Hilbert setting problems to mathematicians, this is a translation
		to english of the original lecture delivered by hilbert before
		the International Congress of Mathematicians at Paris, 1900.
		Problem 13 is the one related to neural networks. Solution
		by Kolmogorov and Lorenz(later?)."
}
@Article{Funahashi89,
 author = "K.~Funahashi",
  title =	"On the approximate realization of continuous mappings by neural networks",
  journal =	"Neural Networks",
  volume =	"2",
  pages =	"183--192",
  year =	"1989",
  abstract =	"Funahashi, Cybenko, Hornik - the trio"
}
@Article{Hornik91,
 author = "K.~Hornik",
  title =	"Approximation capabilities of Multilayer Feedforward Networks",
  journal =	"Neural Networks",
  volume =	"4",
  pages =	"251--257",
  year =	"1991",
  abstract =	"Funahashi, Cybenko, Hornik - the trio"
}
@Article{Gori:Tesi90,
 author = "M.~Gori and A.~Tesi",
  title =	"Some Examples of Local Minima during Learning with Back-propagation",
  journal =	"Parallel Architectures and Neural Networks",
  year =	"1990",
  address =	"Vietri sul Mare(IT)",  
  abstract =	"Back prop related"
}
@InCollection{Frasconi:Gori:Tesi,
 author = "P.~Frasconi and M.~Gori and A.~Tesi",
  title =	"Susccesses and failures of backpropagation: a theoretical investigation",
  booktitle =	"Progress in Neural Networks",
  editor =	"O.~Omidvar",
  publisher =	"Ablex Publishing",
  abstract =	"Back prop related"
}
@Article{Brady:Raghavan:Slawny89,
 author = "M.~L.~Brady and R.~Raghavan and J.~Slawny",
  title =	"Back-Propagation fails to Separate Where Perceptrons Succeed",
  journal =	"IEEE Transactions on Circuits and Systems",
  year =	"1989",
  volume =	"36",
  pages =	"665--674",
  abstract =	"Back prop related"
}
@InCollection{Mozer:Smolensky89,
 author = "M.~C.~Mozer and P.~Smolensky",
  title =	"Skeletonization: a technique for trimming the fat from a network via relevance assessment",
  booktitle =	"Advances in Neural Information Processing Systems",
  editor =	"D.~S.~Touretzky",
  publisher =	"Morgan Kaufmann",
  address =	"San Mateo, CA",
  volume =	"1",
  year =	"1989",
  pages =	"107--115",
  abstract = 	"Pruning from bishop"
}
@InCollection{Hanson:Pratt89,
 author = "S.~J.~Hanson and L.~Y.~Pratt",
  title =	"Comparing biases for minimal network construction with back-propagation",
  booktitle =	"Advances in Neural Information Processing Systems",
  editor =	"D.~S.~Touretzky",
  publisher =	"Morgan Kaufmann",
  address =	"San Mateo, CA",
  volume =	"1",
  year =	"1989",
  pages =	"177--185",
  abstract = 	"Pruning from bishop"
}
@InCollection{Chauvin89,
 author = "Y.~Chauvin",
  title =	"A back-propagation algorithm with optimal use of hidden units",
  booktitle =	"Advances in Neural Information Processing Systems",
  editor =	"D.~S.~Touretzky",
  publisher =	"Morgan Kaufmann",
  address =	"San Mateo, CA",
  volume =	"1",
  year =	"1989",
  pages =	"519--526",
  abstract = 	"Pruning from bishop"
}
@Article{Prechelt96,
 author = "L.~Prechelt",
  title =	"A Quantative Study of Experimental Evaluations of Neural Network Learning Algorithms: Current Research Practice",
  journal =	"Neural Networks",
  volume =	"9",
  year =	"1996",
  abstract = 	"Mentioned by Flexer96 because it says that not many journal papers make experiments. crap",
}
@InProceedings{Flexer96,
 author = "A.~Flexer",
  title =	"Statistical Evaluation of Neural Network Experiments: Minimum Requirements and Current Practice",
  booktitle =	"Cybernetics and Systems 1996, Proceedings of the $13^{th}$ European Meeting on Cybernetics and Systems Research",
  pages =	"1005--1008",
  editor =	"R.~Trappl",
  address =	"Austrian Society for Cybernetic Studies",
  year =	"1996",
  abstract =	"the t-test is mentioned as a good test for statistical significance of neural nets results"
}
@InProceedings{Perrone94,
 author = "M.~P.~Perrone",
  title =	"General averaging results for convex optimization",
  booktitle =	"Proceedings 1993 Connectionist Models Summer School",
  pages =	"364--371",
  editor =	"M.~C.~Mozer",
  address =	"Hillsdale, NJ",
  publisher =	"Lawrence Erlbaum",
  year =	"1994",
  abstract =	"Averaging nns"
}
@Article{Perrone:Cooper93,
 author = "M.~P.~Perrone and L.~N.~Cooper",
  title =	"When networks disagree: ensemble methods for hybrid neural networks",
  journal =	"Artificial Neural Networks for Speech and Vision",
  editor =	"R.~J.~Mammone",
  pages =	"126--142",
  year	= 	"1993",
  address =	"London",
  publisher =	"Chapman and Hall",
  abstract =	"Averaging nns, a first paper, see also Bishop's book for nns and pattern recognition page 364"
}
@Article{Jacobs:Jordan:Nowlan:Hinton91,
 author = "R.~A.~Jacobs and M.~I.~Jordan and S.~J.~Nowlan and G.~E.~Hinton",
  title =	"Adaptive mixture of local experts",
  journal =	"Neural Computation",
  volume =	"3",
  pages =	"79--87",
  abstract =	"gating nns",
  year	= 	"1991"
}
@Book{Rudin64,
 author = "W.~Rudin",
  title =	"Principles of Mathematical Analysis",
  publisher =	"McGraw-Hill",
  address =	"New York",
  year =	"1964",
}
@Book{Bellman61,
 author = "R.~Bellman",
  title =	"Adaptive Control Processes: A Guided Tour",
  publisher =	"Princeton University Press",
  year =	"1961",
  abstract =	"The curse of dimensionality also in http://acrux.fmi.uni-passau.de/~sick/FAQ2.html#A_curse"
}
@Article{Levy:Montalvo85,
 author = "A.~V.~Levy and A.~Montalvo",
  title =	"The Tunnelling Algorithm for the Global Minimization of Functions",
  journal =	"SIAM J. Sci. Stat. Comput.",
  volume =	"6",
  pages =	"15--29",
  year =	"1985",
  abstract =	"the levy6 function for benchmark"
}
@Article{Wang:Hsu91,
 author = "S.~Wang and C.~HHsu",
  title =	"Terminal attractor learning algorithms for backpropagation neural networks",
  journal =	"International Joint Conference on Neural Networks",
  place =	"Singapore",
  pages =	"183--189",
  year =	"1991",
  month =	nov,
  publisher =	"IEEE Press",
  abstract =	"avoid local minima suggestions"
}
@Article{Yu92,
 author = "X.~Yu",
  title =	"Can backpropagation error surface not have local minima?",
  journal =	"IEEE Transactions on Neural Networks",
  pages =	"1019--1020",
  year =	"1992",
  volume =	"3",
  number =	"6",
  abstract =	"avoid local minima with as many hidden units as required"
}
@Article{Dybowski96,
 author = "R.~Dybowski and P.~Weller and R.~Chang and V.~Gant",
  title =	"Prediction of outcome in critically ill patients using artificial neural networks synthesised by genetic algorithm",
  journal =	"The Lancet",
  volume =	"347",
  pages =	"1146--50",
  year =	"1996"
}
@Article{Chiu93,
 author = "C.-T.~Chiu and K.~Mehrotra and C.~Mohan and S.~Ranka",
  title	=	"Robustness of Feedforward Neural Networks",
  journal =	"Second IEEE International Conf. on Neural Networks",
  volume =	"2",
  pages =	"783--788",
  month =	mar,
  year =	"1993"
}
@TechReport{McKelvey92,
 author = "T.~McKelvey",
  title =	"Neural networks applied to optimal flight control",
  type =	"Technical Report",
  institution =	"Link$\ddot{o}$ping University, Sweeden",
  year =	"1992",
}
@TechReport{Musen96,
 author = "L.~Ohno--Machado and M.~A.~Musen",
  title =	"Modular Neural Networks for Medical Prognosis: Quantifying the Benefits of Combining Neural Networks for Survival Prediction",
  type =	"Technical Report",
  institution =	"Knowledge Systems Laboratory, Medical Computer Science, Stanford University",
  year =	"1996",
  month =	feb
}
@Article{Papik98,
 author = "K.~Papik and B.~Molnar and R.~Schaefer and Z.~Dombovari and Z.~Tulassay and J.Feher",
  title = "Application of neural networks in medicine - a review",
  journal = "Medical Science Monitor", 
  year = "1998", 
  volume = "4", 
  number = "3", 
  pages = "538--546",
  url = "http://medscimonit.com/pub/vol_4/no_3/694.pdf"
}
@Article{Cenys88, 
 author = "A.~Cenys and K.~Pyragas",
  title = "Estimation of the Number of Degrees of Freedom from Chaotic Time Series", 
  journal = "Physics Letters A", 
  year = "1988", 
  volume = "129", 
  number = "4", 
  pages = "227--230", 
  month = "May", 
  abstract = "A method for the chaotic time series analysis is proposed. It allows one to
		determine the number of degrees of freedom involved in oscillations from a single observable. The
		method has been verified for some known stochastic models."
}
@Article{Pi94, 
 author = "H.~Pi and C.~Peterson",
  title = "Finding the Embedding Dimension and Variable Dependencies in Time Series", 
  journal = "Neural Computation", 
  year = "1994", 
  volume = "6", 
  pages = "509--520", 
  abstract = "We present a general method, the delta-test, which establishes functional
		dependencies given a sequence of measurements. The approach is based on calculating conditional
		probabilities from vector component distances. Imposing the requirement of continuity of the
		underlying function, the obtained values of the conditional probabilities carry information on the
		embedding dimension and variable dependencies. The power of the method is illustrated on
		synthetic time-series with different time-lag dependencies and noise levels and on the sunspot
		data. The virtue of the method for preprocessing data in the context of feedforward neural
		networks is demonstrated. Also, its applicability for tracking residual errors in output units is
		stressed."
}
@article{JordanJacobs94, 
 author = "M.~I.~Jordan and R.~A.~Jacobs",
  title="Hierarchical Mixtures of Experts and the EM Algorithm", 
  year="1994", 
  journal="Neural Computation", 
  volume=6, 
  number="2", 
  pages="181--214",
  abstract =	"We present a tree-structured architecture for supervised learning. The statistical model
		underlying the architecture is a hierarchical mixture model in which both the mixture
		coefficients and the mixture components are generalized linear models (GLIM's). Learning is
		treated as a maximum likelihood problem; in particular, we present an
		Expectation-Maximization (EM) algorithm for adjusting the parameters of the architecture. We
		also develop an on-line learning algorithm in which the parameters are updated incrementally.
		Comparative simulation results are presented in the robot dynamics domain."
} 
@article{JacobsJordanNowlanHinton91, 
 author = "R.~A.~Jacobs and M.~I.~Jordan and S.~J.~Nowlan and G.~E.~Hinton",
  title="Adaptive Mixtures of Local Experts", 
  journal="Neural Computation", 
  volume="3", 
  number="1", 
  year=1991, 
  pages="79-87",
  abstract = "We present a new supervised learning procedure for systems composed of many separate
		networks, each of which learns to handle a subset of the complete set of training cases. The new
		procedure can be viewed either as modular version of a multilayer supervised network, or as an
		associative version of competitive learning. It therefore provides a new link between these two
		apparently different approaches. We demonstrate that the learning procedure divides up a vowel
		discrimination task into appropriate subtasks, each of which can be solved by a very simple expert
		network."
}
@incollection{JordanJacobs92, 
 author = "M.~I.~Jordan and R.~A.~Jacobs",
  title="Hierarchies of Adaptive Experts", 
  year="1992", 
  booktitle="NIPS",
  volume= 4,
  editor="R.~P.~Lippmann and J.~Moody and D.~S.~Touretzky", 
  publisher="Morgan Kaufmann", 
  pages="985-992"
}
@article{JacobsJordanBarto91, 
 author = "R.~A.~Jacobs and M.~I.~Jordan and A.~G.~Barto",
  title="Task Decomposition through competition in a modular connectionist architecture: The what and where vision tasks.", 
  journal="Cognitive Science", 
  year=1991
} 
@inproceedings{WaterhouseRobinson94,
 author = "S.~R.~Waterhouse and A.~J.~Robinson",
  title="Classification using Hierarchical Mixtures of Experts", 
  booktitle="IEEE Workshop on Neural Networks for Signal Processing", 
  year=1994, 
  pages="177-186"
}
@inproceedings{XuHintonJordan95, 
 author = "Lei Xu and Geoff Hinton and Michael I.~Jordan",
  title ="An alternative model for mixtures of experts", 
  year = 1994, 
  booktitle= "NIPS",
  volume = 7,
  editor="G.~Tesauro and D.~S.~Touretzky and T.~K.~Leen", 
  publisher="MIT Press"
}
@Article{Baxt90,
 author = "W.~G.~Baxt",
  title =	"Use of an artificial neural network for data analysis in clinical decision-making: The diagnosis of acute coronary occlusion",
  journal =	"Neural Computation",
  pages =	"480--490",
  year =	"1990",
  volume =	"2",
}
@Article{Baxt94,
 author = "W.~G.~Baxt",
  title =	"Complexity, chaos and human physiology: the justification for non-linear neural computational analysis",
  journal =	"Cancer Let (IRELAND)",
  pages =	"85--93",
  year =	"1994",
  volume =	"77",
}
@Article{Rogers94,
 author = "S.~K.~Rogers and D.~W.~Ruck and M.~Kabrisky",
  title =	"Artificial neural networks for early detection and diagnosis of cancer",
  journal =	"Cancer Let (IRELAND)",
  pages =	"79--83",
  year =	"1994",
  volume =	"77",
  month =	mar
}
@Article{Doig93,
 author = "G.~S.~Doig and K.~J.~Inman and W.~J.~Sibbald and C.~M.~Martin and J.~M.~Robertson",
  title =	"Modeling mortality in the intensive care unit: comparing the performance of a back-propagation, associative-learning neural network with multivariate logistic regression",
  journal =	"Proc Annu Symp Comput Appl Med Care",
  pages =	"361--5",
  year =	"1993"
}
@Article{Baxt91,
 author = "W.~G.~Baxt",
  title =	"Use of an artificial neural network for the diagnosis of myocardial infarction",
  journal =	"Ann Intern Med",
  pages =	"843--8",
  year =	"1991",
  month =	dec,
  volume =	115,
  number =	11
}
@Article{SapsII,
 author = "J.~R.~le Gall and  S.~Lemeshow and F.~Saulnier",
  title =	"A new simplified acute physiology score (SAPS II) based on a European/North American multicentre study",
  journal =	"JAMA",
  pages =	"2957--63",
  year =	"1993",
  volume =	270
}
@Article{ApacheII,
 author = "W.~E.~Knaus and E.~A.~Draper and D.~P.~Wagner and J.~E.~Zimmerman",
  title =	"APACHE II: a severity of disease classification system",
  journal =	"Crit Care Med",
  pages =	"818--29",
  year =	"1985",
  volume =	13
}
@Article{ApacheIII,
 author = "W.~E.~Knaus and E.~A.~Draper and D.~P.~Wagner and J.~E.~Zimmerman",
  title =	"The APACHE III prognostic system risk prediction of hospital mortality for critically ill hospitalized patients",
  journal =	"Chest",
  pages =	"1619--36",
  year =	"1991",
  volume =	10
}
@Article{Chang88,
 author = "R.~W.~S.~Chang and S.~Jacobs and B.~Lee",
  title =	"Predicting outcome among intensive care unit patients using computerised trend analysis of daily Apache II scores corrected for organ system failure",
  journal =	"Int Care Med",
  pages =	"558--566",
  year =	"1988",
  volume =	14,
  publisher =	"Springer--Verlag",
  abstract =	"critique of the logistic regression techniques employed by usual severity-of-illness
		 scoring systems such as ApacheII."
}
@Article{Reggia93,
 author = "J.~A.~Reggia",
  title =	"Neural computation in medicine",
  journal = 	"Artificial Intelligence in Medicine",
  pages =	"143--157",
  volume =	5,
  number = 	2,
  year = 	"1993",
  abstract =	"The use of neural networks in the diagnoses of diseases"
}
@Article{Burke94,
 author = "H.~B.~Burke",
  title =	"Artificial neural networks for cancer research: Outcome prediction",
  journal =	"Seminars in Surgical Oncology",
  volume =	10,
  pages =	"73--9",
  year =	1994,
  abstract = "The use of neural networks in the prediction of outcome in tumor stage in oncology"
}
@Article{McGonigal93,
 author = "M.~D.~McGonigal and J.~Cole and C.~W.~Schwab and D.~R.~Kauder and M.~F.~Rotondo and P.~B.~Angood",
  title =	"A new approach to probability of survival scoring for trauma quality assurance",
  journal =	"Journal of Trauma",
  volume =	34,
  number =	6,
  pages =	"863--8",
  year =	"1993",
  abstract = "The use of neural networks in the prediction of outcome after trauma"
}
@Article{Ravdin:Clarke92,
 author = "P.~M.~Ravdin and G.~M.~Clarke",
  title =	"A practical application of neural network analysis for predicting outcome of individual breast cancer patients",
  journal =	"Breast Cancer Research and Treatment",
  volume =	22,
  number =	3,
  year =	"1992",
  pages =	"285--93",
}
@inproceedings{Schank76,
 author = "R.~C.~Schank",
  title =	"The role of memory in language processing",
  year =	1976, 
  booktitle= "The structure of human memory",
  pages = "162--189",
  editor="C.~N.~Cofer",
  address = "San Fransisco",
  publisher="Freeman",
  abstract = "scripts"
}
@inproceedings{Minsky75,
 author = "M.~Minsky",
  title =	"A framework for representing knowledge",
  year =	1975, 
  booktitle= "The psychology of computer vision",
  pages = "211--277",
  editor="P.~H.~Winston",
  address = "New York",
  publisher="McGraw-Hill",
  abstract = "frames"
}
@inproceedings{Rumelhart75,
 author = "D.~E.~Rumelhart",
  title =	"Notes on a schema for stories",
  year =	1975, 
  booktitle= "Representation and understanding",
  pages = "211--236",
  editor="D.~G.~Bobrow and A.~Collins",
  address = "New York",
  publisher="Academic Press",
  abstract = "schemata"
}
@Article{Newell80,
 author = "A.~Newell",
  title =	"Physical Symbol Systems",
  journal =	"Cognitive Science",
  volume =	4,
  year =	1980,
  pages = "135--183",
  abstract = "The Physical Symbol System Hypothesis"
}
@Article{Minsky90,
 author = "M.~Minsky",
  title =	"Logical vs. Analogical or Symbolic vs. Connectionist or Neat vs. Scruffy",
  journal =	"Artificial Intelligence at MIT, Expanding Frontiers",
  volume =	1,
  editor = "P.~H.~Winston",
  year =	1990,
  publisher = "MIT Press",
  abstract = "Minsky's defecation about connectionism and symbolic AI"
}
@Book{Moody93,
 author = "T.~C.~Moody",
  title =	"Philosophy and Artificial Intelligence",
  publisher =	"Prentice Hall",
  year = 1993,
  abstract =	"world acclaimed definitions in AI"
}
@Book{Papert88,
 author = "S.~Papert",
  title =	"One AI or Many?",
  publisher =	"Daedalus",
  year = 1988,
  abstract =	"the snow white tale..."
}
@Article{Penny95,
 author = "S.~Penny",
  title =	"The Darwin Machine: Artificial Life and Interactive Art",
  journal =	"New Formations, UK",
  year =	1996,
  location = 	"UK",
  presented = 	"Fifth Biennale of Art and Technology",
  abstract = 	"It has a few interesting bits about reductionism and emergence
		e.g `Emergence throws reductionism in the trash' and quotes DeLanda92,
		see `http://www-art.cfa.cmu.edu/www-penny/texts/Darwin_Machine_.html'"
}
@Article{DeLanda92,
 author = "M.~DeLanda",
  title =	"Virtual Environments as Intuition Synthesisers",
  journal =	"Cultural diversity in the global village",
  year =	1992,
  publisher = "TISEA Catalog, Australian Network for Art and Technology",
  abstract = 	"If the properties of matter and energy at any given level of organisation
		cannot be explained by the properties of the underlying levels, it follows
		that biology cannot be reduced to physics or anthropology to biology"
}
@Book{Descartes,
 author = "Descartes",
   title = "Discours de la M{\'{e}}thode",
   year = 1637,
   abstract = "Descartes talks about the 4 principles of the scientific method, rules 2 and 3
		talk about reductionism"
}
@Article{Sprecher65,
 author = "D.~A.~Sprecher",
  title =	"On the structure of continuous functions of several variables",
  journal =	"Trans. Am. Math. Soc.",
  year =	1965,
  month = 	mar,
  volume =	115,
  pages =	"340--355",
  abstract =    "An improvement over kolmogorov's 1957 theorem"
}
@Article{PoggioGirosi89,
 author = "T.~Poggio and F.~Girosi",
  title =	"A theory of Networks for Approximation and Learning",
  journal =	"MIT AI Memo No.~1140",
  year =	1989,
  month = 	jul,
  abstract =    "{\em $g$ is at least as complex , in terms of bits needed to represent it, as $f$},
		kolmogorov is irrelevant in a few words."
}
@Article{Kurkova91,
 author = "V.~K{\accent '27 u}rkov{\'a}",
  title =	"Kolmogorov's theorem is relevant",
  journal =	"Neural Computation",
  year =	1991,
  volume =      "3",
  pages =       "617--622",
  abstract =    "kolmogorov is or is not relevant(poggio)???? for fuck's sake"
}
@Article{Geman92,
 author = "S.~Geman and E.~Bienenstock",
  title =	"Neural networks and the bias-variance dilemma",
  journal =	"Neural Computation",
  volume =	4,
  year =	1992,
  pages =	"1--58",
  abstract =	"The bias-variance tradeoff or overfitting"
}
@Article{Vapnik_etal97,
 author = "V.~N.~Vapnik and S.~Golowich and A.~Smola",
  title =	"Support vector method for function approximation, regression, estimation and signal processing",
  journal =	"Advances in Neural Information Processing Systems",
  volume =	9,
  editor = 	"M.~Mozer and M.~Jordan and T.~Petsche",
  year =	1997,
  address =	"Cambridge, MA",
  publisher =	"MIT Press",
  pages =	"281--287",
  abstract =	"Support Vector Machines at ATT Bell Labs"
}
@Article{VapnikLerner63,
 author = "V.~N.~Vapnik and A.~Lerner",
  title =	"Pattern recognition using generalised portrait method",
  journal =	"Automation and Remote Control",
  year =	1963,
  volume =      "24",
  abstract =    "The first attempt to Support Vector Machine in the USSR"
}
@Article{VapnikChervonenkis64,
 author = "V.~N.~Vapnik and A.~Ya.~Chervonenkis",
  title =	"A note on one class of perceptrons",
  journal =	"Automation and Remote Control",
  year =	1964,
  volume =      "25",
  abstract =    "follow-up of VapnikLerner63"
}
@Article{Vapnik71,
 author = "V.~N.~Vapnik and A.~Ya.~Chervonenkis",
  title =	"On the uniform convergence of relative frequencies of events to their probabilities",
  journal =	"Theory of Probability and its Applications",
  year =	1971,
  volume =      "16",
  number = 	"2",
  pages =       "264--280",
  abstract =    "the VC dimension"
}
@Book{VapnikChervonenkis74,
 author = "V.~N.~Vapnik and A.~Ya.~Chervonenkis",
  title =	"Theory of Pattern Recognition [in Russian]",
  publisher =	"Nauka",
  year = 	1974,
  address = 	"USSR",
  abstract =	"Basis of vapnik's work"
}
@Book{Vapnik79,
 author = "V.~N.~Vapnik",
  title =	"Estimation of Dependences Based on Empirical Data [in Russian]",
  publisher =	"Nauka",
  year = 	1979,
  address = 	"USSR",
  abstract =	"more basis, english translation by Springer Verlag, NY, 1982"
}
@Book{Vapnik95,
 author = "V.~N.~Vapnik",
  title =	"The Nature of Statistical Learning Theory",
  publisher =	"Springer",
  year = 	1995,
  address = 	"New York",
  abstract =	"more basis"
}
@Book{Burges98,
 author = "C.~J.~C.~Burges",
  title =	"A tutorial on Support Vector Machines for Pattern Recognition",
  publisher =	"Kluwer Academic Publishers",
  year = 	1998,
  address = 	"Boston",
  abstract =	"a good tutorial on SVM -- mentions numerical precision as a problem for QP solvers"
}
@inproceedings{Blumer86,
 author = "A.~Blumer and A.~Ehrenfeucht and D.~Haussler and M.~Warmuth",
  title =	"Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension",
  year =	1, 
  booktitle= "Proceedings of the $18^{th}$ Annual ACM Symposium on the Theory of Computing",
  address = "New York",
  publisher="The Association for Computing Machinery",
  abstract = "introduction of the VC dimension to computational theory"
}
@Article{Blumer87,
 author = "A.~Blumer and A.~Ehrenfeucht and D.~Haussler and M.~Warmuth",
  title =	"Occam's Razor",
  journal =	"Information Processing Letters",
  year =	1987,
  volume =      "24",
  pages =       "377--380",
  abstract =    "post vapnik2"
}
@Article{Blumer89,
 author = "A.~Blumer and A.~Ehrenfeucht and D.~Haussler and M.~Warmuth",
  title = "Learnability and the Vapnik-Chervonenkis Dimension",
  journal =	"Journal of the ACM",
  year =	1989,
  volume =      "36",
  number = 	"4",
  pages =       "929--965",
  abstract =    "post vapnik2"
}
@Article{Baum89,
 author = "E.~B.~Baum and D.~Haussler",
  title = 	"What size net gives valid generalization?",
  journal =	"Neural Computation",
  year =	1989,
  volume =      "1",
  number = 	"1",
  pages =       "151--160",
  abstract =    "upper bounds on sample length using VC dim, very very pessimistic!"
}
@Article{Judd88,
 author = "J.~S.~Judd",
  title = 	"On the complexity of learning shallow neural networks",
  journal =	"Journal of Complexity",
  year =	1988,
  volume =      "4",
  pages =       "177--192",
  abstract =    "computational complexity issues of neural network training"
}
vapni@Book{Garey79,
 author = "M.~R.~Garey and D.~Johnson",
  title =	"Computers and Intractability: A Guide to the theory of NP-completeness",
  publisher =	"W.H.~Freeman",
  year = 	1979,
  address = 	"San Fransisco",
  abstract =	"a reference book on complexity classes"
}
@Book{Judd90,
 author = "J.~S.~Judd",
  title =	"Neural Network Design and the Complexity of Learning",
  publisher =	"MIT Press",
  year = 1990,
  address = "Cambridge, MA",
  abstract =	"Judd's phd thesis made a book, on the computational complexity of learning in neural nets"
}
@Inproceedings{Blum88,
 author = "A.~Blum and R.~Rivest",
  title = 	"Training a 3-node neural network is NP-complete",
  booktitle =	"Proceedings of the $1^{st}$ Workshop on Computational Learning Theory",
  year =	1988,
  publisher =   "Morgan-Kaufmann",
  abstract =    "computational complexity issues of neural network training"
}
@Article{Sima94,
 author = "J.~$\check{S}$ima",
  title = 	"Loading Deep Networks is Hard",
  journal =	"Neural Computation",
  year =	1994,
  volume =      "6",
  pages = 	"842--850",
  abstract =    "computational complexity issues of neural network training"
}
@Article{Sima96,
 author = "J.~$\check{S}$ima",
  title = 	"Back-propagation is not efficient",
  journal =	"Neural Networks",
  year =	1996,
  volume =      "6",
  abstract =    "computational complexity issues of neural network training"
}
@Article{Hammer97,
 author = "B.~Hammer",
  title =	"A NP-hardness result for a sigmoidal 3-node Neural Network",
  journal =	"Osnabr$\ddot{u}$cker Schriften zur Mathematik, Preprint, no. 196",
  year =	"1997",
  abstract =	"computational complexity issues of neural network training"
}
@Inproceedings{Wiklicky93,
 author = "H.~Wiklicky",
  title = 	"The Neural Network Loading Problem is Undecidable",
  booktitle =	"Proceedings of Euro-COLT",
  publisher =	"Oxford University Press",
  year =	1993,
  abstract =    "computational complexity issues of neural network training (recurrent networks)"
}
@Article{DasGupta95,
 author = "B.~DasGupta and H.~T.~Siegelmann and E.~D.~Sontag",
  title =	"On the complexity of training neural networks with continuous activation",
  journal =	"IEEE Transactions on Neural Networks",
  volume =	6,
  year =	1995,
  abstract =	"computational complexity issues of neural network training (recurrent networks)"
}
@Article{Hoffgen93,
 author = "K.~U.~H$\ddot{o}$ffgen",
  title =	"Computational limitations on training sigmoidal neural networks",
  journal =	"Information Processing Letters",
  volume =	46,
  year =	1993,
  abstract =	"NP-completeness results to the loading problem but with the weights restricted to binary values -1 and 1 !!!!"
}
@Article{Zilinkas87,
 author = "Torn and Zilinkas",
  title =	"Global optimisation",
  journal =	"Lecture Notes in Computer Science",
  year =	1987,
  abstract =	"Global optimisation techniques, as opposed to local optimisation based on gradient descent"
}
@Book{Zhigljavsky91,
 author = "Zhigljavsky",
  title =	"Theory of Global Random Search",
  publisher =	"Kluwer Academic Publishing",
  year = 1991,
  abstract =	"More global optimisation techniques"
}
@Article{Chao91,
 author = "J.~Chao and W.~Ratanasuwan and S.~Tsujii",
  title =	"How to find global minima in finite times of search for multilayer perceptrons training",
  journal =	"International Joint Conference on Neural Networks",
  address =	"Singapore",
  year =	1991,
  month =	nov,
  pages =	"1079--1083",
  publisher =	"IEEE Press",
  abstract =	"The magic hair-brush algorithm with global optimisation"
}
@Article{Wang91,
 author = "S.~Wang and C.~H.~Hsu",
  title =	"Terminal attractor learning algorithms for backpropagation neural networks",
  journal =	"International Joint Conference on Neural Networks",
  address =	"Singapore",
  year =	1991,
  month =	nov,
  pages =	"183--189",
  publisher =	"IEEE Press",
  abstract =	"The magic hair-brush algorithm with global optimisation"
}
@Article{Bianchini97,
 author = "M.~Bianchini and S.~Fanelli and M.~Gori and M.~Maggini",
  title =	"Terminal attractor algorithms: A critical analysis",
  journal =	"Neurocomputing",
  vol =		15,
  year =	1997,
  pages =	"3--13",
  abstract =	"they prove that the terminal attractor techniques of \cite{Wang91} have no theoretical assurance of avoiding local minima"
}
@Article{Bianchini98,
 author = "M.~Bianchini and S.~Frasconi and M.~Gori and M.~Maggini",
  title =	"Optimal learning in artificial neural networks: A review of theoretical results",
  journal =	"Neural Network Systems Techniques and Applications (C. Leondes, ed.)",
  publisher =	"Academic Press",
  year =	1998,
  pages =	"1--51",
  abstract =	"two kind of local minima, spurrious and structural -- thanks"
}
@Article{Valiant84,
 author = "L.~G.~Valiant",
  title =	"A theory of the learnable",
  journal =	"Communications of the ACM",
  year =	1994,
  pages =	"1134--1142",
  number =	11,
  volume =	27,
  abstract =	"PAC Learning"
}
@Article{Efron82,
 author = "B.~Efron",
  title =	"The Jacknife, the Boostrap and Other Resampling Plans",
  journal =	"Society for Industrial and Applied Mathematics",
  year =	1982,
  address = 	"Philadelphia",
  abstract =	"reference to bootstrapping"
}
@InCollection{Lucas97,
 author = "S.~Lucas",
  title =	"Forward-backward building blocks of evolving neural networks with intrinsic learning behaviours",
  booktitle =	"Lecture Notes in Computer Science: Biological and Artificial Computation: From Neuroscience to Technology",
  editor =	"J.~Mira and R.~Moreno-Diaz and J.~Cabestany",
  publisher =	"Springer--Verlag",
  year =	"1997",
  pages =	"723--732",
  abstract =	"Supposed to talk about the derivative of FFNN / he was my second phd examiner, he insisted he had his paper cited."
}
@InCollection{Griewank89,
 author = "A.~Griewank",
  title =	"On automatic differentiation",
  booktitle =	"Mathematical Programming: Recent Developments and Applications",
  editor =	"M.~Iri and K.~Tanabe",
  publisher =	"Kluwer Academic Publishers",
  year =	"1989",
  pages =	"83--107",
  abstract =	"Supposed to talk about the derivative of FFNN too"
}
@inproceedings{tresp1994,
  author    = {Volker Tresp and
               Ralph Neuneier and
               Subutai Ahmad},
  title     = {Efficient Methods for Dealing with Missing Data in Supervised
               Learning},
  booktitle = {NIPS},
  year      = {1994},
  pages     = {689-696},
  ee        = {http://nips.djvuzone.org/djvu/nips07/0689.djvu},
  crossref  = {DBLP:conf/nips/1994},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{pearson2006,
 author = {Ronald K. Pearson},
 title = {The problem of disguised missing data},
 journal = {SIGKDD Explor. Newsl.},
 volume = {8},
 number = {1},
 year = {2006},
 issn = {1931-0145},
 pages = {83--92},
 doi = {http://doi.acm.org/10.1145/1147234.1147247},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@article{schafer2002,
 author = {Joseph L. Schafer and Jown W. Graham},
 title = {Missing Data: Our View of the State of the Art},
 journal = {Psychological Methods},
 volume = {7},
 number = {2},
 year = {2002},
 pages = {147--177},
 }


