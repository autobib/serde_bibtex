%Original file available from http://www.cs.odu.edu/~jbollen/bibliographies/bibtex/cogsci_con.bib
%Last update: Saturday 18 January 2003
%Current number of entries: 25

@BOOK{assoc:hassoun1993,
  editor = {Mohammed H. Hassoun},
  title = {Associative Neural Networks. Theory and Implementation},
  year = 1993,
  publisher = {Oxford University Press},
  address = {New York},
}








@ARTICLE{spread:anderson1983,
  author = {John R. Anderson},
  year = 1983,
  title = {A spreading activation theory of memory},
  journal = {Journal of Verbal Leaning and Verbal Behaviour},
  volume = 22,
  pages = {261--295}
}


@ARTICLE{spread:collins1975,
  author = {A.M. Collins and E.F. Loftus},
  year = 1975,
  title = {A spreading activation theory of semantic processing},
  journal = {Psychological Review},
  volume = 82,
  pages = {407-428}
}


@ARTICLE{facili:meyer1971,
  author = {D.E. Meyer and R.W. Schvaneveldt},
  year = 1971,
  title = {Facilitation in recognition pairs of words: Evidence of a
          dependence between retrieval operations},
  journal = {Journal of Experimental Psychology},
  volume = 90,
  pages = {227--234}
}


@BOOK{struct:klimesch1994,
  author = {W. Klimesch},
  year = 1994,
  title = {The Structure of Long Term Memory: A connectivity Model of Semantic
          Processing},
  publisher = {Lawrence Erlbaum and Associates},
  address = {Hillsdale}
}


@BOOK{associ:findler1979,
editor = {Nicholas V. Findler},
title = {Associative Networks - Representation and use of knowledge by computers},
year = 1979,
publisher = {Academic Press},
address = {New York},
}



@BOOK{associ:kohonen1978,
  author = {T. Kohonen},
  year = 1978,
  title = {Associative Memory: a System-Theoretical Approach},
  publisher = {Springer-Verlag},
  address = {Berlin}
}



@ARTICLE{connec:dienes1992,
  author = {Z. Dienes},
  year = 1992,
  title = {Connectionist and memory-array models of artificial grammar
          learning},
  journal = {Cognitive science},
  volume = 16,
  pages = {41-79}
}


@INCOLLECTION{defens:clark1991,
  author = {Andy Clark},
  editor = {William Ramsey and Stephen P. Stich and David E. Rumelhart},
  year = 1991,
  title = {In Defense of Explicit Rules},
  booktitle = {Philosophy and Connectionist Theory},
  pages = {115-128},
  publisher = {Lawrence Erlbaum Associates},
  address = {Hillsdale, New Jersey},
  abstract = {Connectionist system are adept at a specific type of
             problem-solving, one that is based on the accumulation of data
             and is described by the author as emergentist and example-bound.
             This leads to graceful degradation and the ability to trade off
             multiple soft constraints. In other words, they are able to
             behave as if they encode symbolic knowledge of rules and
             categories. However, they do not really operate on the level of
             symbolic representation and are therefore incapable of a
             specifically human kind of learning: one that involves the
             transfer of knowledge from one domain to another. Since they do
             not encode knowledge in terms of symbolic entities, they are not
             capable of manipulating these as is required for tasks that
             involve the rapid rewiring of rules. E.g. after having learned to
             apply the law of Ohm they are not capable of learning to reverse
             the law if required, unless presented with a multiple of examples
             to demonstrate the new rule. Human subject however are perfectly
             able to do so because they do seem to encode specific symbolic
             entities. Clark mentions a number of experiments from child
             psychology to strengthen this case (draw-a-house vs.
             draw-funny-house-tasks). He concludes by hypothesizing two
             distinct systems might be operating at the same time: one that
             handles explicit, symbolic encodings and another that relies on a
             more connectionist means of learning and representation.}
}


@BOOK{paral1:mcclelland1986,
  author = {David E. Rumelhart and James McClelland},
  year = 1986,
  title = {Parallel Distributed Processing, vol I},
  publisher = {MIT press},
  address = {Cambridge}
}


@BOOK{paral2:mcclelland1986,
  author = {David E. Rumelhart and James McClelland},
  year = 1986,
  title = {Parallel Distributed Processing, vol II},
  publisher = {MIT press},
  address = {Cambridge, MA}
}


@ARTICLE{dynam:hopfield1992,
title = {Dynamic properties of neural networks with adapting synapses},
author = {D. W. Dong and J. J. Hopfield},
year = 1992,
journal = {Network},
volume = 3,
number = 3,
pages = {267 -- 283},
}


@ARTICLE{selfas:palmieri1995,
title = {Self-association and Hebbian learning in linear neural networks},
author = {F. Palmieri and Zhu Jie},
year = 1995,
journal = {{IEEE} Transactions on Neural Networks},
volume = 6,
number = 5,
month = {September},
pages = {1165 -- 1184},
}



@ARTICLE{compar:houselander1990,
title = {Comparing performance of Hebbian- and delta-trained Hopfield networks},
author = {P. K. Houselander and J. T. Taylor},
year = 1990,
journal = {Electronic Letters},
volume = 26,
number = 2,
month = {January},
pages = {85 -- 87},
}



@BOOK{selfor:kohonen1995,
title = {Self-organizing maps},
author = {Teuvo Kohonen},
year = 1995,
publisher = {Springer},
address = {Berlin},
abstract = {Neural networks (Computer science) ; Self-organizing systems.}
}



@ARTICLE{unsupe:deco1995,
title = {Unsupervised learning for Boltzman machines},
author = {G. Deco and L. Parra},
year = 1995,
journal = {Network: Computation in Neural Systems},
volume = 6,
number = 3,
pages = {437 -- 448},
month = {August},
abstract = { 
An unsupervised learning algorithm for a stochastic recurrent neural network based on the
Boltzmann machine architecture is formulated.
The maximization of the mutual information between the stochastic
output neurons and the clamped inputs is used as an unsupervised criterion
for training the network. The resulting learning rule contains two terms
corresponding to Hebbian and anti Hebbian learning. It is interesting that
these two terms are weighted by the amount of information transmitted in
the learning synapse, giving an information theoretic interpretation of
the proportionality constant of Hebb's biological rule. The anti Hebbian
term, which can be interpreted as a forgetting function, supports the
optimal coding. In this way, optimal nonlinear and recurrent
implementations of data compression of Boolean patterns are obtained.
As an example, the encoder problem is simulated and trained in an
unsupervised way in a one layer network. Compression of nonuniform
distributed binary data is included. Unsupervised classification,
even for continuous inputs, is shown for the cases of four overlapping
Gaussian spots and for a real world example of thyroid diagnosis.
In comparison with other techniques, the present model requires an
exponentially smaller number of weights for the classification problem .
}
}




@ARTICLE{comput:hopfield1986,
title = {Computing with Neural Circuits: A Model},
author = {John J. Hopfield and David W. Tank},
journal = {Science},
volume = 233,
number = 4764,
month = {Augustus},
year = {1986},
pages = {625 -- 633},
}



@BOOK{princi:rosenblatt1962,
title = {Principles of neurodynamics; perceptrons and the theory of brain mechanisms},
author = {Rosenblatt, Frank},
year = 1962,
publisher = {Spartan Books},
address = {Washington},
}






@BOOK{parall:hinton1981,
  author = {G. Hinton and J.R. Anderson},
  year = 1981,
  title = {Parallel Models of Associative Memory},
  publisher = {Hillsdale Publishers},
  address = {New Jersey}
}



@BOOK{connec:davis1992,
  author = {Steven Davis},
  year = 1992,
  title = {Connectionism: theory and practice},
  publisher = {Oxford University Press},
  address = {Oxford}
}


@BOOK{neural:ritter1992,
  author = {Helge Ritter and Thomas Martinez and Klaus Schulten},
  year = 1992,
  title = {Neural Computation and Self-Organizing Maps},
  publisher = {Addison-Wesley Publishing Company},
  address = {New York}
}


@BOOK{neural:haykin1999,
  author = {Simon Haykin},
  year = 1999,
  title = {Neural Networks. A Comprehensive Foundation},
  publisher = {Prentice Hall},
  address = {New Jersey, USA}
}








@BOOK{organi:hebb1949,
  author = {Donald O. Hebb},
  year = 1949,
  title = {The Organization of Behavior},
  publisher = {John Wiley},
  address = {New York}
}


@BOOK{mechan:cleeremans1992,
  author = {Axel Cleeremans},
  year = 1992,
  title = {Mechanisms of Implicit Learning: Connectionist models of Sequence
          Processing},
  publisher = {MIT Press},
  address = {Cambridge}
}


@BOOK{cellul:woody1988,
  author = {Charles D. Woordy and Daniel L. Alko and James L. McGaugh},
  year = 1988,
  title = {Cellular Mechanisms of Conditioning and Behavioral Plasticity},
  publisher = {Plenum Press},
  address = {New York}
}


@INCOLLECTION{longte:holger1988,
  author = {Holger Wigstr{\"o}m and Bengt Gustafson and Yan-You Hang},
  editor = {Charles D. Woordy and Daniel L. Alko and James L. McGaugh},
  year = 1988,
  title = {Long-{T}erm Potentiation of Synaptic Transmission in the
          Hippocampus Obeys Hebb's rule for Synaptic Modification},
  booktitle = {Cellular Mechanisms of Conditioning and Behavioral Plasticity},
  publisher = {Plenum Press},
  address = {New York}
}


