% This file was created with JabRef 2.6.
% Encoding: UTF8

@INPROCEEDINGS{Jin2010,
  author = {Zhuo-Jun Jin and Hui Qian and Miao-Liang Zhu},
  title = {Gaussian processes in inverse reinforcement learning},
  booktitle = {Machine Learning and Cybernetics (ICMLC), 2010 International Conference
	on},
  year = {2010},
  volume = {1},
  pages = {225 -230},
  month = {july},
  abstract = {Inverse reinforcement learning (IRL) is the general problem of recovering
	a reward function from demonstrations provided by an expert. By incorporating
	Gaussian process (GP) into IRL, we present an approach to recovering
	both rewards and uncertainty information in continuous state and
	action spaces. To predicate value in every point in spaces, we use
	GP models for value function and reward function separately. Our
	contribution is threefold: First, we extend the existing IRL algorithm
	to the case of continuous spaces. Second, reward GP provides not
	only the reward function with flexible forms, but also uncertainty
	about rewards, which helps the learner make a tradeoff between exploitation
	and exploration. Third, by introducing the kernel function, our approach
	takes sample points in the demonstration as learning features. It
	prevents manually designating features. Experimental results show
	the proposed method works well and demonstrate good learning in a
	traditional learning setting.},
  doi = {10.1109/ICMLC.2010.5581063},
  keywords = {GP;Gaussian processes;IRL;inverse reinforcement learning;kernel function;reward
	function;uncertainty information;value function;Gaussian processes;learning
	(artificial intelligence);}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

